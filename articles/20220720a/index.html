<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <!--
    ███████╗██╗░░░██╗████████╗██╗░░░██╗██████╗░███████╗
    ██╔════╝██║░░░██║╚══██╔══╝██║░░░██║██╔══██╗██╔════╝
    █████╗░░██║░░░██║░░░██║░░░██║░░░██║██████╔╝█████╗░░
    ██╔══╝░░██║░░░██║░░░██║░░░██║░░░██║██╔══██╗██╔══╝░░
    ██║░░░░░╚██████╔╝░░░██║░░░╚██████╔╝██║░░██║███████╗
    ╚═╝░░░░░░╚═════╝░░░░╚═╝░░░░╚═════╝░╚═╝░░╚═╝╚══════╝
    ████████╗███████╗░█████╗░██╗░░██╗
    ╚══██╔══╝██╔════╝██╔══██╗██║░░██║
    ░░░██║░░░█████╗░░██║░░╚═╝███████║
    ░░░██║░░░██╔══╝░░██║░░██╗██╔══██║
    ░░░██║░░░███████╗╚█████╔╝██║░░██║
    ░░░╚═╝░░░╚══════╝░╚════╝░╚═╝░░╚═╝
    ██████╗░██╗░░░░░░█████╗░░██████╗░
    ██╔══██╗██║░░░░░██╔══██╗██╔════╝░
    ██████╦╝██║░░░░░██║░░██║██║░░██╗░
    ██╔══██╗██║░░░░░██║░░██║██║░░╚██╗
    ██████╦╝███████╗╚█████╔╝╚██████╔╝
    ╚═════╝░╚══════╝░╚════╝░░╚═════╝░
    Welcome engineer.
    https://www.future.co.jp/recruit/
  -->
  
  <title>Foursquare - Location Matching 参加記 (7th / 1083) | フューチャー技術ブログ</title>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  
  <meta name="description" content="本記事は「地図・GIS・位置特定に関する連載」二日目の記事です。昨日の「郵便番号・住所・緯度経度の体系について」の記事も、今回の記事とは直接つながってはいませんが、参考になる部分もあるのでぜひご覧ください。 はじめにこんにちは、Strategic AI Group所属の金子です。普段は推薦に関連する実装やデータ分析を行っています。 先日Kaggleで開催された「Foursquare - Locat">
<meta property="og:type" content="article">
<meta property="og:title" content="Foursquare - Location Matching 参加記 (7th &#x2F; 1083) | フューチャー技術ブログ">
<meta property="og:url" content="https://future-architect.github.io/articles/20220720a/index.html">
<meta property="og:site_name" content="フューチャー技術ブログ">
<meta property="og:description" content="本記事は「地図・GIS・位置特定に関する連載」二日目の記事です。昨日の「郵便番号・住所・緯度経度の体系について」の記事も、今回の記事とは直接つながってはいませんが、参考になる部分もあるのでぜひご覧ください。 はじめにこんにちは、Strategic AI Group所属の金子です。普段は推薦に関連する実装やデータ分析を行っています。 先日Kaggleで開催された「Foursquare - Locat">
<meta property="og:locale" content="ja_JP">
<meta property="og:image" content="https://future-architect.github.io/images/20220720a/4sq_overview.png">
<meta property="article:published_time" content="2022-07-19T15:00:00.000Z">
<meta property="article:modified_time" content="2022-07-21T02:31:55.395Z">
<meta property="article:tag" content="Kaggle">
<meta property="article:tag" content="TensorFlow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://future-architect.github.io/images/20220720a/4sq_overview.png">
  
  <link rel="alternate" href="/atom.xml" title="フューチャー技術ブログ" type="application/atom+xml">
  
  <link rel="icon" href="/favicon.ico">
  <link rel="apple-touch-icon" sizes='180x180' href="/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes='57x57' href="/apple-touch-icon-57x57.png">
  <link rel="canonical" href="https://future-architect.github.io/articles/20220720a/">
  <meta content="Kaggle,TensorFlow" name="keywords">
  <meta content="金子剛士" name="author">
  <link rel="preload" as="image" href="/banner.jpg" />
  <link rel='manifest' href='/manifest.webmanifest'/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/css/bootstrap.min.css" integrity="sha384-F3w7mX95PdgyTmZZMECAngseQB83DfGTowi0iMjiWaeVhAn4FJkqJByhZMI3AhiU" crossorigin="anonymous">
  <link rel="stylesheet" href="/metronic/assets/style.css">
  <link rel="stylesheet" href="/css/theme-styles.css">
<meta name="generator" content="Hexo 5.4.2"></head>

<body class="corporate">
  <div class="wrap" itemscope itemtype="https://schema.org/TechArticle">
  <!-- BEGIN HEADER -->
<header class="header">
	<div class="header-overlay">
		<div class="header-menu"></div>
		<div class="header-title"><a href="/">Future Tech Blog</a></div>
		<div class="header-title-sub">フューチャー技術ブログ</div>
	</div>
</header>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li><a href="/articles/">Blog</a></li>
    <li class="active">Post</li>
  </ul>
  <section id="main" class="margin-top-30">
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Infrastructure/">Infrastructureカテゴリ</a>
  </div>


    <h2 itemprop="name" class="article-title">Foursquare - Location Matching 参加記 (7th / 1083)
  
  <a target="_blank" rel="noopener" href="https://github.com/future-architect/tech-blog/edit/master/source/_posts/20220720a_Foursquare_-_Location_Matching_参加記_(7th_／_1083).md" title="Suggest Edits" class="github-edit"><i class="github-edit-icon"></i></a>
  
</h2>

    <div class="row">
  <main class="col-md-9 blog-posts">
    <article id="post-20220720a_Foursquare_-_Location_Matching_参加記_(7th_／_1083)" class="article article-type-post blog-item" itemscope itemprop="blogPost">
      <div class="article-inner">
        
        <header class="article-header">
          <ul class="blog-info">
            <li class="blog-info-item"><a href="/articles/2022/" class="publish-date"><time datetime="2022-07-19T15:00:00.000Z" itemprop="datePublished">2022.07.20</time></a>
</li>
            <li class="blog-info-item"><li><a href="/authors/%E9%87%91%E5%AD%90%E5%89%9B%E5%A3%AB" title="金子剛士さんの記事一覧へ" class="post-author">金子剛士</a></li></li>
            <li class="blog-info-item">
  
    
    <a href="/tags/Kaggle/" title="Kaggleタグの記事へ" class="tag-list-link">Kaggle</a>
  
    
    <a href="/tags/TensorFlow/" title="TensorFlowタグの記事へ" class="tag-list-link">TensorFlow</a>
  

</li>
          </ul>
          </header>
        
        <div class="article-entry" itemprop="articleBody">
          
            <p>本記事は<a href="/articles/20220719a/">「地図・GIS・位置特定に関する連載」</a>二日目の記事です。昨日の<a href="/articles/20220719b/">「郵便番号・住所・緯度経度の体系について」</a>の記事も、今回の記事とは直接つながってはいませんが、参考になる部分もあるのでぜひご覧ください。</p>
<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは、Strategic AI Group所属の金子です。普段は推薦に関連する実装やデータ分析を行っています。</p>
<p>先日Kaggleで開催された<a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/foursquare-location-matching/overview">「Foursquare - Location Matching」コンペ</a>(以下4sqコンペ)に社外の知人共にチームで参加し、1083チーム中7位をとりました。（初の金メダルでKaggle Competitions Masterになりました！)</p>
<p>本記事では参加記として以下の内容を紹介します。</p>
<ul>
<li>4sqコンペ概要</li>
<li>解法のサマリ</li>
<li>解法の詳細</li>
<li>テクニック集</li>
<li>リーク問題について</li>
<li>謝辞</li>
</ul>
<h1 id="4sqコンペ概要"><a href="#4sqコンペ概要" class="headerlink" title="4sqコンペ概要"></a>4sqコンペ概要</h1><h2 id="タスク概要"><a href="#タスク概要" class="headerlink" title="タスク概要"></a>タスク概要</h2><p>Foursquareは位置を共有するSNS等を提供する企業です。現在はあるPOI(Points-of-Interest, 同じ地図上の特定のポイント)について口コミ等を検索する「Foursquare」アプリや、あるPOIにチェックインし、それをシェアすることに特化した「Swarm」アプリなどを公開しています。これらに登録されているPOIはユーザーによって登録されます。</p>
<p>4sqコンペではFoursquareの持つPOIとそれに関連するデータが提供されました。そして、このデータに対し一定の実行環境内で同じPOIのIDをもつ行同士のマッチングを時間内に行うコードを提出することが求められました。</p>
<p>データとしては以下の情報が欠損値を含む状態で渡されました。</p>
<ul>
<li>名称(name)</li>
<li>住所(country, state, city, address)</li>
<li>緯度経度(latitude, longitude)</li>
<li>カテゴリ(categories, 一つのレコードに0~複数個紐づく)</li>
<li>URLや電話番号、郵便番号</li>
</ul>
<p>下記の表は私がつくったデータの見本です。「フューチャー株式会社」・「Future Corporation」・「フューチャー」はすべて同じPOIですが、欠損や表記ゆれを含んだ状態でデータセットの中に散在しています。訓練データは約110万件、テストデータは約60万件あり、テストデータではPOIが隠された状態で渡されていました。提出は各行のIDに対して同じPOIであるIDを連結したmatchesの出力を求められました。<br><img src="/images/20220720a/データの例.png" alt="データの例" width="1200" height="117" loading="lazy"></p>
<p>評価はmatchesに対し (正解のラベルと予測ラベルの積集合の数) &#x2F; (正解のラベルと予測ラベルの和集合の数) で求められるIoUの平均で計算されました。</p>
<h2 id="この問題が解けると何がうれしいか"><a href="#この問題が解けると何がうれしいか" class="headerlink" title="この問題が解けると何がうれしいか"></a>この問題が解けると何がうれしいか</h2><p>今回のコンペのデータは意図的にノイズを加えたデータで、実務のデータとは異なるようでした。しかし、名前や住所・商品名の表記ゆれというのは至る所で発生する問題で、今回のコンペで用いられた手法は実務でこのようなゆれと向き合うにあたって有用であると考えられます。</p>
<h1 id="解法のサマリ"><a href="#解法のサマリ" class="headerlink" title="解法のサマリ"></a>解法のサマリ</h1><p>前回紹介した<a href="https://future-architect.github.io/articles/20220602b/">H&amp;Mコンペ</a>でもそうでしたが、600,000 x 600,000 の組み合わせについてすべて正確に評価することは難しいです。<br>そこで、今回は以下の三つのパートで予測を行いました。</p>
<ul>
<li>全候補から大まかに候補を絞り込むretrieval part</li>
<li>二点間のペアに対して正確な予測を行うpredict part</li>
<li>ペアをグラフとして扱い後処理で精度を上げるpostprocess part</li>
</ul>
<img src="/images/20220720a/4sq_overview.png" alt="4sq_overview" width="851" height="432" loading="lazy">

<h1 id="解法の詳細"><a href="#解法の詳細" class="headerlink" title="解法の詳細"></a>解法の詳細</h1><p>上記の三つのパートに各データの前処理について加え、前処理から順に説明していきます。</p>
<h2 id="前処理パート"><a href="#前処理パート" class="headerlink" title="前処理パート"></a>前処理パート</h2><p>前処理では機械学習モデルがデータを解釈しやすいよう、データをカテゴリ変数とembeddingに変換することを目的にしました。<br>そのために、NNが扱いやすいような形に自然言語を処理し、欠損値を埋め、無数にあるカテゴリを学習できる種類にまで減らすこと意識しました。</p>
<h3 id="自然言語の前処理"><a href="#自然言語の前処理" class="headerlink" title="自然言語の前処理"></a>自然言語の前処理</h3><h4 id="文字の正規化"><a href="#文字の正規化" class="headerlink" title="文字の正規化"></a>文字の正規化</h4><p>nameについてはたくさんの言語が混じっており、かつ日本語・中国語・タイ語のような分かち書きが必要な言語も多く混じっていました。そこでname, addressについては、文字単位で比較する用、単語同士で比較する用、NNに入れる用の三種類に向けた前処理を行いました。</p>
<p>「大崎一丁目2-2 アートヴィレッジ大崎セントラルタワー」であれば</p>
<div class="scroll"><table>
<thead>
<tr>
<th>処理番号</th>
<th>処理の目的</th>
<th>処理内容</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>文字単位の比較用</td>
<td>Unicode正規化</td>
</tr>
<tr>
<td>2</td>
<td>単語同士の比較用</td>
<td>1.に対し分かち書きの実施、小文字化・カタカナ化、数字を表す単語の数字化(e.g. 一丁目→1丁目)、一部記号の除去</td>
</tr>
<tr>
<td>3</td>
<td>NNへの入力用</td>
<td>2.に対し正規表現で[0-9a-z&amp; ]のみが残るようローマ字化</td>
</tr>
</tbody></table></div>
<p>の三種類の処理を行い、</p>
<div class="scroll"><table>
<thead>
<tr>
<th>処理番号</th>
<th>処理結果</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>大崎一丁目2-2 アートヴィレッジ大崎セントラルタワー</td>
</tr>
<tr>
<td>2</td>
<td>オオサキ 1 チョウメ 2 - 2 アート ヴィレッジ オオサキ セントラル タワー</td>
</tr>
<tr>
<td>3</td>
<td>oosaki 1 choume 2 2 aato virejji oosaki sentoraru tawaa</td>
</tr>
</tbody></table></div>
<p>となるように変換しました。</p>
<h4 id="addressの欠損値の補完"><a href="#addressの欠損値の補完" class="headerlink" title="addressの欠損値の補完"></a>addressの欠損値の補完</h4><p>addressについては3.についてのみ、NNモデルに入れるため欠損値の補完を行いました。<br>具体的には全レコードについて、addressがNaNでないものからhaversine距離で近傍3か所のaddressを連結して、embedding学習用の前処理としました。</p>
<h3 id="地名のカテゴリ変数化と前処理"><a href="#地名のカテゴリ変数化と前処理" class="headerlink" title="地名のカテゴリ変数化と前処理"></a>地名のカテゴリ変数化と前処理</h3><p>city, state, countryはカテゴリ変数として扱うことにしました。countryは欠損値を”NAN”で埋めたうえでカテゴリ変数化、cityとstateについては出現回数上位約2000を代表として平均の緯度経度を計算し、欠損値、もしくは上位2000以外のcityとstateを上位2000との近傍で埋めました。</p>
<p>また、cities1000という1000人以上の人口がいる市を集めたデータセットを用いて緯度経度から地名を求め、geo_nameという名前のカテゴリ変数にしました。これもまた出現数上位2000のどれかに割り振られるよう調整を行いました。</p>
<h3 id="categoriesの前処理"><a href="#categoriesの前処理" class="headerlink" title="categoriesの前処理"></a>categoriesの前処理</h3><p>categoriesは一つの列にカンマ区切りで複数のカテゴリが入っていました。そこでカンマ区切りで分割し、RaggedTensorとして扱いました。また、categoriesに何も入っていない場合は”nan”のカテゴリで補完しました。後述のカテゴリ予測モデルを作った後は”nan”の行に予測を行い、カテゴリを一つ追加しました。</p>
<h3 id="URL-x2F-Phoneの正規化"><a href="#URL-x2F-Phoneの正規化" class="headerlink" title="URL&#x2F;Phoneの正規化"></a>URL&#x2F;Phoneの正規化</h3><p>URLについては<a target="_blank" rel="noopener" href="https://docs.python.org/ja/3/library/urllib.parse.html">urllib</a>でネットワーク上の位置を示す部分抽出しました。<br>電話番号は国際通話用の+81等が付いた形式とそうでない形式が混じっていたため、<a target="_blank" rel="noopener" href="https://pypi.org/project/phonenumbers/">phonenumbers</a>を用いて正規化を行い統一しました。</p>
<h3 id="embeddingの作成"><a href="#embeddingの作成" class="headerlink" title="embeddingの作成"></a>embeddingの作成</h3><h4 id="サブワードへの分割"><a href="#サブワードへの分割" class="headerlink" title="サブワードへの分割"></a>サブワードへの分割</h4><p>3で処理したローマ字について<a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">SentencePiece</a>でサブワード分割を学習しました。サブワードは単語をさらに分割したもので、例えば「競プロer」という未知の単語が出てきた際、「競プロ」をする「er」なんだなと解釈できるようになります。単語をすべて[0-9a-z&amp; ]の範囲にしたのもsentence pieceで使える語彙をより有意義なものにするためです。nameとaddressについてそれぞれ32000のサブワードで表すようSentencePieceを別々に学習しました。</p>
<h4 id="embeddingの学習"><a href="#embeddingの学習" class="headerlink" title="embeddingの学習"></a>embeddingの学習</h4><p>学習にはname, address, categoriesと、カテゴリ変数にしたcountry, city, state, geo_nameを用い以下の三つのタスクを行いました。</p>
<ol>
<li>同じname内の単語の共起情報からembeddingを学習するSkip-Gramベースのタスク</li>
<li>categories以外からcategoriesを予測するmetric learningタスク</li>
<li>それぞれのembeddingを<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.09792">ConvMixer</a>のように混ぜてmix embeddingとし、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.08821">SimCSE</a>で自己教師あり対照学習を行うタスク</li>
</ol>
<p>1.と3.のタスクについてはバッチ内の他サンプルを負例とするのほかに、距離の近さを辺の重みとしたrandom walkによるnegative hard samplingによって、難易度の高い負例をサンプルごとに用意しました。これによりembeddingの質が大きく向上しました。</p>
<p>なお、1のSkip-Gramタスクの学習はコンペ中<a target="_blank" rel="noopener" href="https://www.kaggle.com/code/nadare/w2v-haversine-nn-baseline-training-inference">W2V &amp; haversine NN baseline[Training&#x2F;Inference]</a>というノートブックで公開しています。</p>
<h4 id="embeddingの評価"><a href="#embeddingの評価" class="headerlink" title="embeddingの評価"></a>embeddingの評価</h4><p>embeddingの評価としてデータごとに近傍を取得し、precision@16 (≒ maxIoU)を計算して評価を行いました。<br>ベースラインとしてUniversal Sentence Encoderでのコサイン類似度の近傍と、haversine距離の近傍を用意しました。</p>
<div class="scroll"><table>
<thead>
<tr>
<th>近傍の取得方法</th>
<th>precision@16</th>
<th>precision@32</th>
</tr>
</thead>
<tbody><tr>
<td>USE name embedding</td>
<td>0.7582</td>
<td>0.7879</td>
</tr>
<tr>
<td>haversine distance</td>
<td>0.8946</td>
<td>0.9160</td>
</tr>
</tbody></table></div>
<p>でしたが、上記の3つのタスクを解くことにより以下のようなembeddingを得られました。</p>
<div class="scroll"><table>
<thead>
<tr>
<th>近傍の取得方法</th>
<th>precision@16</th>
<th>precision@32</th>
</tr>
</thead>
<tbody><tr>
<td>name embedding</td>
<td>0.7738</td>
<td>0.8061</td>
</tr>
<tr>
<td>address embedding</td>
<td>0.8690</td>
<td>0.8811</td>
</tr>
<tr>
<td>mix embedding</td>
<td>0.8997</td>
<td>0.9120</td>
</tr>
</tbody></table></div>
<p>nameに関しては、Universal Sentence Encoderよりも高いprecisionで、非常に質の高いembeddingを作成することができました。</p>
<h3 id="K-means-amp-Word-Tour"><a href="#K-means-amp-Word-Tour" class="headerlink" title="K-means++ &amp; Word Tour"></a>K-means++ &amp; Word Tour</h3><p>embeddingをLightGBMのようなGBDTが解釈しやすい形にするため、球面K-means++と<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.01954">Word Tour</a>を組み合わせた手法で一次元に落とし込みました。Word Tourはembedding間の距離を元に巡回セールスマン問題(TSP)を解き、その順番でembeddingを並び替えるという手法で、これにより一次元上で距離の近い位置に似たembeddingが並ぶようになります。</p>
<p>これは決定木系の分割手法と相性がよく、<a target="_blank" rel="noopener" href="https://www.kaggle.com/code/nadare/word-tour-experiment/notebook">Food101のデータセットでの検証を行った際</a>はPCAでの圧縮よりもはるかに高パフォーマンスに次元を圧縮することができました。また、Food101のラベルについてWord Tourを実施すると、ラベルは以下のように並ぶため、決定木との相性の良さがわかると思います。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">eggs_benedict</span><br><span class="line">omelette</span><br><span class="line">lasagna</span><br><span class="line">pizza</span><br><span class="line">garlic_bread</span><br><span class="line">grilled_cheese_sandwich</span><br><span class="line">club_sandwich</span><br><span class="line">hamburger</span><br><span class="line">pulled_pork_sandwich</span><br><span class="line">lobster_roll_sandwich</span><br><span class="line">hot_dog</span><br></pre></td></tr></table></figure>

<p>巡回セールスマン問題はNP困難な問題であるのですが、私はこれに対し、K-means++で頂点数を減らしたうえで<a target="_blank" rel="noopener" href="https://developers.google.com/optimization">OR-Tools</a>を用いることで手軽な実装で現実的な時間内にTSPの近似解を求めました。また、K-meansについてはcategoriesやnamesのembeddingだけでなくlatitudeとlongitudeでもK-means++を行いTSPで並び替えました。city, state, geo_nameなどのカテゴリもCountEncodingの他にhaversine距離に基づいてTSPを計算し並び替えを行いました。</p>
<p>K-means系の特徴量としては、Word Tourで並べなおしたK-meansのクラスタラベルと、各クラスタ中心までの距離をデータに紐づけました。</p>
<h2 id="retrieval-パート"><a href="#retrieval-パート" class="headerlink" title="retrieval パート"></a>retrieval パート</h2><h3 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h3><p>retrieval パートではGPU上で全組み合わせの計算ができる高速で簡単な手法で、取りこぼしが無いようモデルを構築しました。</p>
<h3 id="候補生成"><a href="#候補生成" class="headerlink" title="候補生成"></a>候補生成</h3><p>作成したembeddingやhaversine距離を元に一つのサンプルにつき32の候補を作成しLightGBMでの学習・予測に用いました。<br>候補生成は以下の五つの方法を用いました。これらはTensorFlowを用いてGPU上で計算を行ったので、全組み合わせについて愚直に計算することができました。</p>
<div class="scroll"><table>
<thead>
<tr>
<th>番号</th>
<th>処理の種類</th>
<th>取得数</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>二点間のlatitude, longitudeから計算するhaversine距離による近傍</td>
<td>4</td>
</tr>
<tr>
<td>2</td>
<td>haversine距離とembeddingのコサイン類似度を用いた重回帰による近傍</td>
<td>12</td>
</tr>
<tr>
<td>3</td>
<td>nameの単語単位での一致度による近傍</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td>nameの文字単位での一致度による近傍</td>
<td>8</td>
</tr>
<tr>
<td>5</td>
<td>nameのembeddingのコサイン類似度による近傍</td>
<td>4</td>
</tr>
</tbody></table></div>
<h4 id="haversine距離とembeddingのコサイン類似度を用いた重回帰による近傍"><a href="#haversine距離とembeddingのコサイン類似度を用いた重回帰による近傍" class="headerlink" title="haversine距離とembeddingのコサイン類似度を用いた重回帰による近傍"></a>haversine距離とembeddingのコサイン類似度を用いた重回帰による近傍</h4><p>2についてはhaversine距離の対数と各embeddingのコサイン類似度から重回帰を行いました。重回帰の学習はロジスティック回帰で行うよりも、正例がより高いスコアになるようランク学習を行うことでよりよい重回帰の係数を得ることができました。</p>
<h4 id="Bag-of-Words一致度による近傍"><a href="#Bag-of-Words一致度による近傍" class="headerlink" title="Bag of Words一致度による近傍"></a>Bag of Words一致度による近傍</h4><p>3, 4については単語単位、文字単位でのBag of Wordベクトルを作成し、コサイン類似度・precision・recallをもとめました。<br>precision・recallについては「フューチャー株式会社」をクエリ、「フューチャー」をターゲットとして文字単位で比較した際、<br>共通部分は「フューチャー」なので、以下のようになります。</p>
<ul>
<li>文字単位でのprecisionは len(フューチャー) &#x2F; len(フューチャー株式会社)で0.6、</li>
<li>文字単位でのrecallは len(フューチャー) &#x2F; len(フューチャー)で1.0</li>
</ul>
<p>このような手法を用いたのは、POIのペアとして「〇〇コンビニ」と「〇〇コンビニ　XXX店」のような組み合わせを多く見たからです。<br>Bag of Wordsベクトルをl2正規化した際のコサイン類似度と、precision, recallの大きい順に候補を取得し、同率の場合は重回帰のスコアで並べなおして上位を取得しました。</p>
<h4 id="候補生成の精度"><a href="#候補生成の精度" class="headerlink" title="候補生成の精度"></a>候補生成の精度</h4><p>この5つの手法で非対称な候補生成を行った結果、</p>
<div class="scroll"><table>
<thead>
<tr>
<th>近傍の取得方法</th>
<th>maxIoU(≒precision@32)</th>
</tr>
</thead>
<tbody><tr>
<td>retrievalのみ</td>
<td>0.9778</td>
</tr>
<tr>
<td>retrieval+postprocess</td>
<td>0.9935</td>
</tr>
</tbody></table></div>
<p>まで高めることができました。</p>
<h2 id="predict-パート"><a href="#predict-パート" class="headerlink" title="predict パート"></a>predict パート</h2><h3 id="概要-1"><a href="#概要-1" class="headerlink" title="概要"></a>概要</h3><p>predict パートでは、ある地点(query)とその候補(candidate)の1:1の間の特徴量を追加し、LightGBMで二値分類を行いました。<br>今回のデータはPOIのペアを持たないデータも多く、False Positiveが悪影響を与えやすかったので、それらを防ぐ工夫も検討しました。</p>
<h3 id="特徴量生成"><a href="#特徴量生成" class="headerlink" title="特徴量生成"></a>特徴量生成</h3><h4 id="query-candidateのそれぞれのカテゴリとword-tourの一次元の距離"><a href="#query-candidateのそれぞれのカテゴリとword-tourの一次元の距離" class="headerlink" title="query, candidateのそれぞれのカテゴリとword tourの一次元の距離"></a>query, candidateのそれぞれのカテゴリとword tourの一次元の距離</h4><p>IDごとにそれぞれのカテゴリやクラスタを計算し、queryとcandidateの両方のIDとマージしました。<br>また、Word Tourで求めたクラスタラベルについては一次元上での距離を計算しました。</p>
<h4 id="name-addressについてのゲシュタルトマッチング、レーベンシュタイン距離、ジャロ・ウィンクラー距離"><a href="#name-addressについてのゲシュタルトマッチング、レーベンシュタイン距離、ジャロ・ウィンクラー距離" class="headerlink" title="name, addressについてのゲシュタルトマッチング、レーベンシュタイン距離、ジャロ・ウィンクラー距離"></a>name, addressについてのゲシュタルトマッチング、レーベンシュタイン距離、ジャロ・ウィンクラー距離</h4><p>これらは文字列の類似度を計算する古典的な手法で、python内蔵の<a target="_blank" rel="noopener" href="https://docs.python.org/ja/3/library/difflib.html">difflib</a>や、<a target="_blank" rel="noopener" href="https://github.com/ztane/python-Levenshtein">Levenshtein</a>といったライブラリで計算することができます。CPUでの計算なので時間はかかりますが、有効な特徴量であったため、3種類の方法で加工したname, addressとname, addressの数字部分だけを抽出したものをこれらの手法で類似度を計算しました。</p>
<h4 id="name-addressについてのROUGE-N-ROUGE-L"><a href="#name-addressについてのROUGE-N-ROUGE-L" class="headerlink" title="name, addressについてのROUGE-N, ROUGE-L"></a>name, addressについてのROUGE-N, ROUGE-L</h4><p>ROUGEは文章要約タスクの良しあしを測るのにつかわれることが多い手法で、文章同士について一定の分割をした後、共通部分のprecision, recall, F値を計算します。ROUGE-NはN-gram、ROUGE-LはLCSを用いてROUGEを計算します。前者はTensorFlowのRaggedTensorを活用、後者はtensorflow-textにあるrouge_l関数を用いてGPU上で高速に計算しました。</p>
<h3 id="学習・予測"><a href="#学習・予測" class="headerlink" title="学習・予測"></a>学習・予測</h3><h4 id="学習データ"><a href="#学習データ" class="headerlink" title="学習データ"></a>学習データ</h4><p>学習はLightGBMを用い、特徴量の評価時はpidで分割した5foldでの計算、提出時は全データを用いてiteration数を決め打ちで学習を行いました。</p>
<h4 id="sample-weight"><a href="#sample-weight" class="headerlink" title="sample weight"></a>sample weight</h4><p>sample weightは他のPOIのペアをすべて当てられたうえで予測を間違えたときのIoUの損失をweightとしました。これは、前述のとおりTrue NegativeよりもFalse Positiveの方がスコアに対する悪影響が大きいからです。weightは正例で平均して0.8、負例で1.0になりました。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dev_data_df[<span class="string">&quot;weight&quot;</span>] = np.where(dev_data_df[<span class="string">&quot;label&quot;</span>],</span><br><span class="line">                                 <span class="number">1</span> - (dev_data_df[<span class="string">&quot;true_count&quot;</span>] - <span class="number">1</span>) / dev_data_df[<span class="string">&quot;true_count&quot;</span>],</span><br><span class="line">                                 <span class="number">1</span> - (dev_data_df[<span class="string">&quot;true_count&quot;</span>]) / (dev_data_df[<span class="string">&quot;true_count&quot;</span>]+<span class="number">1</span>))</span><br><span class="line">dev_data_df[<span class="string">&quot;weight&quot;</span>] = dev_data_df[<span class="string">&quot;weight&quot;</span>] / dev_data_df[<span class="string">&quot;weight&quot;</span>].mean()</span><br></pre></td></tr></table></figure>

<h4 id="LightGBMのハイパーパラメータ"><a href="#LightGBMのハイパーパラメータ" class="headerlink" title="LightGBMのハイパーパラメータ"></a>LightGBMのハイパーパラメータ</h4><p>LightGBMの基本的なハイパーパラメータはnum_leavesが2^12が最適で、学習率は0.1と高く、2000iterationsまで学習を行いました。これでもpidで分割したバリデーションデータでのAUCが上昇し続けました。</p>
<p>細かいパラメータとして、”max_bin_by_feature”を設定しました。LightGBMは学習の前に連続値をヒストグラムに変換し、最大でも255のbinにしてしまうのでそれ以上のカテゴリ数があると押しつぶされてしまいます。そこで、K-meansのラベルとcategoriesのラベルは255より大きな値になるように一部のカテゴリのmax_binを緩和するよう設定しました。”bin_construct_sample_cnt”は初期のヒストグラムを作るときのパラメータで、これを小さくすると精度が少し下がる代わりに学習前のヒストグラム構築におけるメモリと時間を節約できます。学習環境によってこれを変更しました。すべてのパラメータは以下の通りです。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">lgb_params = &#123;</span><br><span class="line">    <span class="string">&quot;objective&quot;</span> : <span class="string">&quot;binary&quot;</span>,</span><br><span class="line">    <span class="string">&quot;metric&quot;</span> : <span class="string">&quot;auc&quot;</span>,</span><br><span class="line">    <span class="string">&quot;boosting&quot;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">    <span class="string">&quot;max_depth&quot;</span> : -<span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;num_leaves&quot;</span> : <span class="number">2</span>**<span class="number">12</span> - <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span> : <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">&quot;bagging_freq&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;is_unbalance&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&quot;max_bin_by_feature&quot;</span>: max_bin_by_feature,</span><br><span class="line">    <span class="string">&quot;bin_construct_sample_cnt&quot;</span>: <span class="number">200000</span>,</span><br><span class="line">    <span class="string">&quot;lambda_l1&quot;</span>: <span class="number">1.</span>,</span><br><span class="line">    <span class="string">&quot;lambda_l2&quot;</span>: <span class="number">1.</span>,</span><br><span class="line">    <span class="string">&quot;bagging_fraction&quot;</span> : <span class="number">0.9</span>,</span><br><span class="line">    <span class="string">&quot;feature_fraction&quot;</span> : <span class="number">0.6</span>,</span><br><span class="line">    <span class="string">&quot;seed&quot;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>

<h4 id="予測"><a href="#予測" class="headerlink" title="予測"></a>予測</h4><p>予測は500iterationのモデルを用いた時点で予測時に合計1時間以上かかることが分かったため、<a target="_blank" rel="noopener" href="https://docs.rapids.ai/api/cuml/stable/api.html#cuml.ForestInference">cumlのForestInference</a>を活用しGPU上での予測を行いました。これにより100倍近くの高速化がされ、2000, 3000iterationのモデルを用いても実行時間内に予測を終えられました。LightGBMはfloat64で境界値やleaf valueを持つ一方、ForestInferenceはfloat32で計算を行うので若干の精度低下はあるものの、それ以上の高速化の恩恵を受けたため採用しました。</p>
<h2 id="Postprocess-パート"><a href="#Postprocess-パート" class="headerlink" title="Postprocess パート"></a>Postprocess パート</h2><p>Postpeocessパートでは、グラフとして予測されたペアをつなげることで拾いこぼしを拾って精度を上げました。</p>
<h3 id="概要-2"><a href="#概要-2" class="headerlink" title="概要"></a>概要</h3><p>ペア同士の予測値を出した後は、一定の閾値を元にUnionFindで頂点同士を連結しグラフを構築しました。<br>各グラフに対して、NetworkXを用い、媒介中心性を元にした辺の排除を行った後、頂点間の距離が2以内の頂点のみを予測のペアとして出力を行いました。</p>
<h1 id="テクニック集"><a href="#テクニック集" class="headerlink" title="テクニック集"></a>テクニック集</h1><h2 id="メモリ増加のテクニック"><a href="#メモリ増加のテクニック" class="headerlink" title="メモリ増加のテクニック"></a>メモリ増加のテクニック</h2><p>Kaggleにコードを提出する際、実行には以下の二つの環境を選べます。</p>
<ul>
<li>4CPU 16GBRAM 9時間以内</li>
<li>2CPU 13GBRAM 1GPU 16GBRAM 9時間以内</li>
</ul>
<p>今回のコンペにとってはメモリが少なく、OOMを起こしやすい実行環境でした。<br>そこで私は以下の二つの工夫をしました。</p>
<ul>
<li>予測は10000行単位で特徴量生成→予測の流れで行う。</li>
<li>BoWの行列はTensorFlowのRaggedTensorやSparseTensorに変換し、embeddingと一緒にGPU RAMに配置する。</li>
</ul>
<p>embeddingをGPUに配置することで実質29GBのメモリを使えることになり余裕のある推論ができました。</p>
<h2 id="高速化のテクニック"><a href="#高速化のテクニック" class="headerlink" title="高速化のテクニック"></a>高速化のテクニック</h2><p>また、embeddingのコサイン類似度やROUGEの計算はGPUで行い、lgbmの推論もForestInferenceによるGPUでの推論を活用することで高速化できました。これのおかげで提出から結果が出るまでの時間はおよそ5時間で、4時間の余裕がありました。これを有効活用できなかったのは残念ですが、余裕をもって特徴量生成に集中することができました。</p>
<h2 id="各言語処理のテクニック"><a href="#各言語処理のテクニック" class="headerlink" title="各言語処理のテクニック"></a>各言語処理のテクニック</h2><p>中国語の分かち書きには<a target="_blank" rel="noopener" href="https://tfhub.dev/google/zh_segmentation/1">zh_segmentation</a>、タイ語の分かち書き・ローマ字変換には<a target="_blank" rel="noopener" href="https://pythainlp.github.io/">PyThaiNLP</a>を用いました。特にPyThaiNLPは機能とドキュメントが充実しており、タイ語の処理にはとても使いやすいなと感じました。<br>日本語の分かち書き・読み方の取得・ローマ字化は<a target="_blank" rel="noopener" href="https://github.com/WorksApplications/SudachiPy">Sudachi</a>と<a target="_blank" rel="noopener" href="https://github.com/miurahr/pykakasi">PyKakasi</a>を用いていて、特にSudachiについては日本語の表記ゆれの正規化まで取得できたのは利点でした。また、今回のタスクではSentencePieceの学習とSudachiのA mode(UniDic単位相当)の分割が相性良かったです。</p>
<h2 id="試したが効かなかったもの"><a href="#試したが効かなかったもの" class="headerlink" title="試したが効かなかったもの"></a>試したが効かなかったもの</h2><ul>
<li>Universal Sentence Encoderを用いたembedding特徴量の追加(LBが悪くなった)</li>
<li>Sentencepieceについてname, addressを同時に学習(precisionが下がった)</li>
<li>name, address embeddingへの畳み込みの追加(precisionが下がり、かつ遅くなった)</li>
<li>city, stateなどあまり質の高くないembeddingへのWord Tour(意味のある並びを得られなかった)<ul>
<li>Word Tourがうまくいくかはembeddingの質に大きく左右されます。</li>
</ul>
</li>
<li>転置インデックスを用いた候補生成(Pure Python実装だと遅かった)</li>
<li>LightGBMのTensorFlow実装(ForestInferenceを使う方がはるかに効率的だった)</li>
</ul>
<h1 id="リーク問題について"><a href="#リーク問題について" class="headerlink" title="リーク問題について"></a>リーク問題について</h1><p>今回のコンペは参加者が推論を行うコードを提出すると、参加者が直接見ることのできないtestデータで評価を行われPublicとPrivateのリーダーボードが更新されました。しかし、コンペ終了後運営のミスによってtestデータの67%がtrainデータと一致していた可能性が参加者から指摘されました。(trainデータのnameと緯度経度が完全一致するレコードについてLB上で検証が行われました。)7&#x2F;19時点で全提出について重複を排除したデータについて再評価が行われ、一部のチームに追加の賞金が支払われることが決まりました。</p>
<p>このリークにより金圏付近までの解法の良しあしの比較が困難になってしまいました。ただ、リークがあったにしろ上位の解法は納得のできるもので、私自身も自身の解法は他にも活用できる自信を持っています。このリークによって上位の解法の価値がなくなったわけではないことについて、理解が広まればいいなと考えています。</p>
<h1 id="謝辞"><a href="#謝辞" class="headerlink" title="謝辞"></a>謝辞</h1><p>今回のコンペは<a target="_blank" rel="noopener" href="https://www.kaggle.com/takanobu0210">takapyさん</a>、<a target="_blank" rel="noopener" href="https://www.kaggle.com/imazekishota">Shotaさん</a>、<a target="_blank" rel="noopener" href="https://www.kaggle.com/matsumotoyuki">visionさん</a>、<a target="_blank" rel="noopener" href="https://www.kaggle.com/koichirokamada">Kurutonさん</a>と一緒に参加しました。チームで協力してディスカッションやコードの整備、励ましあいを行ったおかげで、今回金メダルを獲得できたと思っています。まずはチームメンバーに強く感謝したいと思っています。</p>
<p>また、今回の解法に用いた技術やライブラリ、例えばSentencepieceやOR-Toolsは会社の勉強会等で教わり、SimCSEやWord Tourは日本語の勉強会で発表されたものを聞いて理解を深めていました。自分も積極的に発表を続け恩返しをしたいと思っています。</p>
<p>最後に、今回のコンペで一緒に戦い、ディスカッションを行ってくれたライバルたちにも感謝を込めて、本記事の終わりとさせていただきます。<br>連載の次の記事は 澁川さんの<a href="/articles/20220721a/">Redisのジオメトリ機能</a>です。お楽しみに！</p>
<h1 id="リンク"><a href="#リンク" class="headerlink" title="リンク"></a>リンク</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/foursquare-location-matching/discussion/335800">7th place solution(discussion)</a>: コンペ終了後に投稿したdiscussion、解法について質問があればこちらのdiscussionへどうぞ</li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/code/nadare/7th-place-solution-inference">7th place solution inference(inference notebook)</a>: コンペで提出を行った推論用notebook</li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/foursquare-location-matching/discussion/336148">Let’s discuss how to correspond to the name and address of each language!</a>: 各言語ごとの自然言語の前処理についてより詳しく説明したdiscussion</li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/code/nadare/w2v-haversine-nn-baseline-training-inference">W2V &amp; haversine NN baseline[Training&#x2F;Inference]</a>: コンペ中に公開したsentencepieceを用いた候補生成のnotebook</li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/code/nadare/word-tour-experiment">word tour experiment</a>: word tourをFood101で実験したnotebook</li>
</ul>

          
        </div>
        <footer>
          <section class="social-area">
          <!-- シェアボタン START -->
  <ul class="social-button">
    
    <!-- Twitter -->
    <li>
      <a class="social-btn twitter-btn" target="_blank" href="https://twitter.com/share?url=https://future-architect.github.io/articles/20220720a/&related=twitterapi%2Ctwitter&text=Foursquare%20-%20Location%20Matching%20%E5%8F%82%E5%8A%A0%E8%A8%98%20(7th%20/%201083)%20%7C%20%E3%83%95%E3%83%A5%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E6%8A%80%E8%A1%93%E3%83%96%E3%83%AD%E3%82%B0" rel="nofollow noopener">
        <i></i><span class="social-btn-label">54</span>
      </a>
    </li>
    <!-- Facebook -->
    <li>
      <a class="social-btn fb-btn" target="_blank" href="http://www.facebook.com/share.php?u=https://future-architect.github.io/articles/20220720a/&t=Foursquare%20-%20Location%20Matching%20%E5%8F%82%E5%8A%A0%E8%A8%98%20(7th%20/%201083)" rel="nofollow noopener">
        <i></i><span class="social-btn-label">シェア</span>
      </a>
    </li>
    <!-- hatebu -->
    <li>
      <a class="social-btn hatebu-btn" target="_blank" href="https://b.hatena.ne.jp/entry/s/future-architect.github.io/articles/20220720a/" rel="nofollow noopener">
        <i></i><span class="social-btn-label">はてな</span>
      </a>
    </li>
    <!-- pocket -->
    <li>
      <a class="social-btn pocket-btn" target="_blank" href="https://getpocket.com/save?url=https://future-architect.github.io/articles/20220720a/" rel="nofollow noopener">
        <i></i><span class="social-btn-label">2</span>
      </a>
    </li>
    
  </ul>
<!-- シェアボタン END -->

          </section>
          <aside>
            <section class="related-post margin-bottom-40 nav">
              <h2 id="related"><a href="#related" class="headerlink" title="関連記事"></a>関連記事</h2>
              
  <div class="widget">
    <ul class="nav related-post-link"><li class="related-posts-item"><span>2022.06.02</span><span class="snscount">&#9825;19</span><a href=/articles/20220602b/ title="Strategic AI Group所属の金子です。普段は推薦に関連する実装やデータ分析を行っています。先日Kaggleで開催された[H&M Personalized Fashion Recommendations]コンペに単独で参加し、2952チーム中46位をとりました。今回の参加記では以下の内容を紹介します。">H&M Personalized Fashion Recommendations 参加記 (46th/2952)</a></li><li class="related-posts-item"><span>2022.06.13</span><span class="snscount">&#9825;11</span><a href=/articles/20220613a/ title="Future Tech Night #17「embeddingの活用」と「MLOps」のAI勉強会を開催し、「embeddingを用いた分析・検索・推薦の技術」というタイトルで発表しました。当日の勉強会の様子は[YouTubeで公開しており...">Future Tech Night #17 embeddingを用いた分析・検索・推薦の技術</a></li><li class="related-posts-item"><span>2021.03.25</span><span class="snscount">&#9825;17</span><a href=/articles/20210325/ title="自然言語処理でよく使われるWord2VecやTransformerをログデータやテーブルデータの予測・分析に活用するためのオレオレベースラインの紹介を行います。対象読者は既にWord2VecやTransformerについて知識があり、その上自身で改造を行いたい人や...">Transformerを用いた表現学習・推薦の実装</a></li><li class="related-posts-item"><span>2022.03.21</span><span class="snscount">&#9825;26</span><a href=/articles/20220321a/ title="初めまして、2022年中途入社でTIG所属の岸下です。FlutterとTensorFlow Liteを使ったモバイル画像識別について執筆させて頂きます。TensorFlow Liteとは...">TensorFlow Liteを使ったFlutterによるモバイル画像識別器を作ってみた</a></li><li class="related-posts-item"><span>2021.10.26</span><span class="snscount">&#9825;13</span><a href=/articles/20211026b/ title="先日10月18日に発売された[Software Design 2021年11月号]の第一特集、「Kaggleで知る機械学習 前処理から学習モデルの構築，スコアの上げ方までわかる」をフューチャーの農見、玉木、金子が担当しました。数日経ってしまいましたが、簡単に紹介させていただきます。">Software Design 2021年11月号「Kaggleで知る機械学習」を寄稿しました</a></li><li class="related-posts-item"><span>2021.09.01</span><span class="snscount">&#9825;70</span><a href=/articles/20210901a/ title="こんにちは！Strategic AI Groupの金子です。夏の自由研究ブログ連載2021として医薬品副作用データベースにWord2Vecを適用し性能を評価、医薬品-原疾患-有害事象の可視化を行いました。本記事で作成したプログラムは医薬品の情報を扱っていますが、医療機器には該当せず人の疾病の診断、治療、予防を目的としておりません。本記事の内容に基づいて医学的判断は行わないようお願いします。">医薬品副作用データベースから医薬品同士の関係を学習・評価・可視化する</a></li></ul>
  </div>
            </section>
            <section class="reference-post margin-bottom-40 nav">
              
  <div class="card">
    <div id="reference" class="reference-lede"><a href="#reference" class="headerlink" title="参照されている記事"></a>この記事を参照している記事</div>
    <ul class="reference-post-link"><li class="reference-posts-item"><a href=/articles/20220719b/ title="こんにちは。TIG DXユニット所属の今泉です。郵便番号・住所・緯度経度について調べる機会があり、自分なりに整理したものを記事にしてみます。本記事ではシステム開発において、仕様レベルでの間違いを防ぐため「知っておいた方がいいだろうな」と思った内容をピックアップして紹介します。">郵便番号・住所・緯度経度の体系について</a></li><li class="reference-posts-item"><a href=/articles/20220719a/ title="「地図・GIS・住所・位置特定」周りをテーマにした企画を始めます。">地図・GIS・位置特定に関する連載を始めます</a></li></ul>
  </div>
            </section>
          </aside>
        </footer>
      </div>
    </article>
  </main>
  <aside class="col-md-3 blog-sidebar">
    <!-- START SIDEBAR  -->


<section class="toc-section">
  <h2 class="margin-top-30">目次</h2>
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB"><span class="toc-text">はじめに</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4sq%E3%82%B3%E3%83%B3%E3%83%9A%E6%A6%82%E8%A6%81"><span class="toc-text">4sqコンペ概要</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E3%82%BF%E3%82%B9%E3%82%AF%E6%A6%82%E8%A6%81"><span class="toc-text">タスク概要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E3%81%93%E3%81%AE%E5%95%8F%E9%A1%8C%E3%81%8C%E8%A7%A3%E3%81%91%E3%82%8B%E3%81%A8%E4%BD%95%E3%81%8C%E3%81%86%E3%82%8C%E3%81%97%E3%81%84%E3%81%8B"><span class="toc-text">この問題が解けると何がうれしいか</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E3%81%AE%E3%82%B5%E3%83%9E%E3%83%AA"><span class="toc-text">解法のサマリ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E6%B3%95%E3%81%AE%E8%A9%B3%E7%B4%B0"><span class="toc-text">解法の詳細</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E5%87%A6%E7%90%86%E3%83%91%E3%83%BC%E3%83%88"><span class="toc-text">前処理パート</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86"><span class="toc-text">自然言語の前処理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E5%AD%97%E3%81%AE%E6%AD%A3%E8%A6%8F%E5%8C%96"><span class="toc-text">文字の正規化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#address%E3%81%AE%E6%AC%A0%E6%90%8D%E5%80%A4%E3%81%AE%E8%A3%9C%E5%AE%8C"><span class="toc-text">addressの欠損値の補完</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%B0%E5%90%8D%E3%81%AE%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA%E5%A4%89%E6%95%B0%E5%8C%96%E3%81%A8%E5%89%8D%E5%87%A6%E7%90%86"><span class="toc-text">地名のカテゴリ変数化と前処理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#categories%E3%81%AE%E5%89%8D%E5%87%A6%E7%90%86"><span class="toc-text">categoriesの前処理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#URL-x2F-Phone%E3%81%AE%E6%AD%A3%E8%A6%8F%E5%8C%96"><span class="toc-text">URL&#x2F;Phoneの正規化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#embedding%E3%81%AE%E4%BD%9C%E6%88%90"><span class="toc-text">embeddingの作成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%82%B5%E3%83%96%E3%83%AF%E3%83%BC%E3%83%89%E3%81%B8%E3%81%AE%E5%88%86%E5%89%B2"><span class="toc-text">サブワードへの分割</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#embedding%E3%81%AE%E5%AD%A6%E7%BF%92"><span class="toc-text">embeddingの学習</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#embedding%E3%81%AE%E8%A9%95%E4%BE%A1"><span class="toc-text">embeddingの評価</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means-amp-Word-Tour"><span class="toc-text">K-means++ &amp; Word Tour</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#retrieval-%E3%83%91%E3%83%BC%E3%83%88"><span class="toc-text">retrieval パート</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%A6%81"><span class="toc-text">概要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%80%99%E8%A3%9C%E7%94%9F%E6%88%90"><span class="toc-text">候補生成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#haversine%E8%B7%9D%E9%9B%A2%E3%81%A8embedding%E3%81%AE%E3%82%B3%E3%82%B5%E3%82%A4%E3%83%B3%E9%A1%9E%E4%BC%BC%E5%BA%A6%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E9%87%8D%E5%9B%9E%E5%B8%B0%E3%81%AB%E3%82%88%E3%82%8B%E8%BF%91%E5%82%8D"><span class="toc-text">haversine距離とembeddingのコサイン類似度を用いた重回帰による近傍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Bag-of-Words%E4%B8%80%E8%87%B4%E5%BA%A6%E3%81%AB%E3%82%88%E3%82%8B%E8%BF%91%E5%82%8D"><span class="toc-text">Bag of Words一致度による近傍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%80%99%E8%A3%9C%E7%94%9F%E6%88%90%E3%81%AE%E7%B2%BE%E5%BA%A6"><span class="toc-text">候補生成の精度</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#predict-%E3%83%91%E3%83%BC%E3%83%88"><span class="toc-text">predict パート</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%A6%81-1"><span class="toc-text">概要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%B4%E9%87%8F%E7%94%9F%E6%88%90"><span class="toc-text">特徴量生成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#query-candidate%E3%81%AE%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E3%81%AE%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA%E3%81%A8word-tour%E3%81%AE%E4%B8%80%E6%AC%A1%E5%85%83%E3%81%AE%E8%B7%9D%E9%9B%A2"><span class="toc-text">query, candidateのそれぞれのカテゴリとword tourの一次元の距離</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#name-address%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E3%82%B2%E3%82%B7%E3%83%A5%E3%82%BF%E3%83%AB%E3%83%88%E3%83%9E%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0%E3%80%81%E3%83%AC%E3%83%BC%E3%83%99%E3%83%B3%E3%82%B7%E3%83%A5%E3%82%BF%E3%82%A4%E3%83%B3%E8%B7%9D%E9%9B%A2%E3%80%81%E3%82%B8%E3%83%A3%E3%83%AD%E3%83%BB%E3%82%A6%E3%82%A3%E3%83%B3%E3%82%AF%E3%83%A9%E3%83%BC%E8%B7%9D%E9%9B%A2"><span class="toc-text">name, addressについてのゲシュタルトマッチング、レーベンシュタイン距離、ジャロ・ウィンクラー距離</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#name-address%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AEROUGE-N-ROUGE-L"><span class="toc-text">name, addressについてのROUGE-N, ROUGE-L</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E7%BF%92%E3%83%BB%E4%BA%88%E6%B8%AC"><span class="toc-text">学習・予測</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF"><span class="toc-text">学習データ</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sample-weight"><span class="toc-text">sample weight</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LightGBM%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%91%E3%83%BC%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF"><span class="toc-text">LightGBMのハイパーパラメータ</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%88%E6%B8%AC"><span class="toc-text">予測</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Postprocess-%E3%83%91%E3%83%BC%E3%83%88"><span class="toc-text">Postprocess パート</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%A6%81-2"><span class="toc-text">概要</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF%E9%9B%86"><span class="toc-text">テクニック集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E3%83%A1%E3%83%A2%E3%83%AA%E5%A2%97%E5%8A%A0%E3%81%AE%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF"><span class="toc-text">メモリ増加のテクニック</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%AE%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF"><span class="toc-text">高速化のテクニック</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%81%AE%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF"><span class="toc-text">各言語処理のテクニック</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A9%A6%E3%81%97%E3%81%9F%E3%81%8C%E5%8A%B9%E3%81%8B%E3%81%AA%E3%81%8B%E3%81%A3%E3%81%9F%E3%82%82%E3%81%AE"><span class="toc-text">試したが効かなかったもの</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%83%AA%E3%83%BC%E3%82%AF%E5%95%8F%E9%A1%8C%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">リーク問題について</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AC%9D%E8%BE%9E"><span class="toc-text">謝辞</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%83%AA%E3%83%B3%E3%82%AF"><span class="toc-text">リンク</span></a></li></ol>
</section>

<section class="category">
<h2 class="margin-top-30">カテゴリー</h2>
<div class="widget">
  <ul class="nav sidebar-categories margin-bottom-40">
  
  <li class=""><a href="/categories/Programming/">Programming (340)</a></li>
<li class=""><a href="/categories/Infrastructure/">Infrastructure (198)</a></li>
<li class=""><a href="/categories/Culture/">Culture (84)</a></li>
<li class=""><a href="/categories/DataScience/">DataScience (44)</a></li>
<li class=""><a href="/categories/IoT/">IoT (31)</a></li>
<li class=""><a href="/categories/DB/">DB (20)</a></li>
<li class=""><a href="/categories/Business/">Business (19)</a></li>
<li class=""><a href="/categories/%E8%AA%8D%E8%A8%BC%E8%AA%8D%E5%8F%AF/">認証認可 (18)</a></li>
<li class=""><a href="/categories/Management/">Management (13)</a></li>
<li class=""><a href="/categories/VR/">VR (12)</a></li>
<li class=""><a href="/categories/DevOps/">DevOps (12)</a></li>
<li class=""><a href="/categories/Design/">Design (11)</a></li>
<li class=""><a href="/categories/Security/">Security (6)</a></li>

  </ul>
</div>

</section>
<section class="podcast-link">
<h2 class="margin-top-30">Tech Cast</h2>

  <div class="class="widget-wrap">
  <div class="widget">
    <ul class="nav techcast">
      <li><a href="https://anchor.fm/futuretechcast/episodes/35-MLOps-e1qe4st" title="フューチャーがお届けするポッドキャストです。#35 MLOpsエンジニアって何やるの？（後編）" target="_blank" rel="noopener"><span class="newitem">NEW</span> #35 MLOpsエンジニアって何やるの？（後編）</a></li>
<li><a href="https://anchor.fm/futuretechcast/episodes/34-MLOps-e1polbj" title="フューチャーがお届けするポッドキャストです。#34 MLOpsエンジニアって何やるの？（前編）" target="_blank" rel="noopener"> #34 MLOpsエンジニアって何やるの？（前編）</a></li>
<li><a href="https://anchor.fm/futuretechcast/episodes/33-IT-e1pcaon" title="フューチャーがお届けするポッドキャストです。#33 ヘルスケアグループリーダーの中元さんと語る「医療業界におけるITコンサルとビジネスイノベーション」（後編）" target="_blank" rel="noopener"> #33 ヘルスケアグループリーダーの中元さんと語る「医療業界におけるITコンサルとビジネスイノベーション」（後編）</a></li>
    </ul>
  </div>
  </div>
  
</section>
<section class="advent-calendar">
<h2 class="margin-top-30">アドベントカレンダー</h2>
<div class="widget">
  <ul class="nav-flex">
    <li><a href="http://qiita.com/advent-calendar/2022/future" title="フューチャー Advent Calendar 2022 #Qiita" target="_blank" rel="noopener">2022年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2021/future" title="フューチャー Advent Calendar 2021 #Qiita" target="_blank" rel="noopener">2021年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2020/future" title="フューチャー Advent Calendar 2020 #Qiita" target="_blank" rel="noopener">2020年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2019/future" title="フューチャー Advent Calendar 2019 #Qiita" target="_blank" rel="noopener">2019年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2018/future" title="フューチャー Advent Calendar 2018 #Qiita" target="_blank" rel="noopener">2018年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2017/future" title="フューチャー Advent Calendar 2017 #Qiita" target="_blank" rel="noopener">2017年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2016/future" title="フューチャー Advent Calendar 2016 #Qiita" target="_blank" rel="noopener">2016年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2015/future" title="フューチャー Advent Calendar 2015 #Qiita" target="_blank" rel="noopener">2015年</a></li>
  </ul>
</div>

</section>
<!-- END SIDEBAR -->

  </aside>
</div>

  </section>
</div>

      <!-- BEGIN PRE-FOOTER -->
    <footer>
      <div class="pre-footer">
        <div class="container">
          <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-6 col-6 pre-footer-col">
              <h2>About Us</h2>
              <p>経営とITをデザインする、フューチャーの技術ブログです。業務で利用している幅広い技術について紹介します。<br /><br /><a target="_blank" rel="noopener" href="http://www.future.co.jp/">http://www.future.co.jp/</a></p>
              <div class="social-btn twitter-btn twitter-follow-btn">
                <a href="https://twitter.com/intent/follow?screen_name=future_techblog " target="_blank" rel="nofollow noopener">
                  <i></i><span class="tw-btn-label">フューチャー技術ブログをフォロー</span>
                </a>
              </div>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-4 col-4 pre-footer-col">
              <h2>Contact</h2>
              <address class="margin-bottom-40">
                <a href="https://www.future.co.jp/recruit/recruit/rec-fresh/" title="新卒採用" target="_blank" rel="noopener">新卒採用</a><br>
                <a href="https://www.future.co.jp/recruit/recruit/rec-career/" title="キャリア採用" target="_blank" rel="noopener">キャリア採用</a><br>
                <a href="https://www.future.co.jp/contact_us/" title="お問い合わせページ" target="_blank" rel="noopener">お問い合わせ</a><br>
                <a href="https://www.future.co.jp/architect/socialmediapolicy/" title="ソーシャルメディアポリシー" target="_blank" rel="noopener">メディアポリシー</a><br><br>
                <a href="mailto:techblog@future.co.jp">techblog@future.co.jp</a>
              </address>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6 col-6 pre-footer-col">
              <h2>Contents</h2>
              <a href="https://future-architect.github.io/coding-standards/" title="Future Enterprise Coding Standards" target="_blank" rel="noopener">コーディング規約</a><br>
              <a href="https://future-architect.github.io/typescript-guide/" title="仕事ですぐに使えるTypeScript" target="_blank" rel="noopener">仕事ですぐに使えるTypeScript</a><br>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-3 col-3 pre-footer-col">
              <h2>Event</h2>
              <a href="https://future.connpass.com/" title="経営とITをデザインするフューチャーの勉強会です" target="_blank" rel="noopener">connpass</a><br>
              <a href="https://www.future.co.jp/futureinsightseminar/" title="フューチャーインサイトセミナー" target="_blank" rel="noopener">Webセミナー</a><br>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-3 col-3 pre-footer-col">
              <h2>SNS</h2>
              <a href="https://github.com/future-architect" title="Future's official open source repositories" target="_blank" rel="noopener">GitHub</a><br>
              <a href="https://qiita.com/organizations/future" title="フューチャーのQiita Organizationです" target="_blank" rel="noopener">Qiita</a><br>
              <a href="https://note.future.co.jp/" title="フューチャーの公式note" target="_blank" rel="noopener">未来報</a><br>
              <a href="https://www.youtube.com/channel/UCJUSwYYd0CkGgmEKAW7QVpw" title="フューチャーYoutubeチャネル" target="_blank" rel="noopener">Youtube</a>
            </div>
          </div>
        </div>
      </div>
      <div class="footer">
        <div class="container">
          <div class="row">
            <div class="col-md-6 col-sm-6 padding-top-10">
              &copy; 2022 フューチャー技術ブログ<br>
            </div>
          </div>
        </div>
      </div>
    </footer>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X1C28R8H0M"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-X1C28R8H0M');
  gtag('config', 'UA-74047147-1'); // 過渡期対応
</script>

  </div>
</body>
</html>
