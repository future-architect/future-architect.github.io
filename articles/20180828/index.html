<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <!--
    ███████╗██╗░░░██╗████████╗██╗░░░██╗██████╗░███████╗
    ██╔════╝██║░░░██║╚══██╔══╝██║░░░██║██╔══██╗██╔════╝
    █████╗░░██║░░░██║░░░██║░░░██║░░░██║██████╔╝█████╗░░
    ██╔══╝░░██║░░░██║░░░██║░░░██║░░░██║██╔══██╗██╔══╝░░
    ██║░░░░░╚██████╔╝░░░██║░░░╚██████╔╝██║░░██║███████╗
    ╚═╝░░░░░░╚═════╝░░░░╚═╝░░░░╚═════╝░╚═╝░░╚═╝╚══════╝
    ████████╗███████╗░█████╗░██╗░░██╗
    ╚══██╔══╝██╔════╝██╔══██╗██║░░██║
    ░░░██║░░░█████╗░░██║░░╚═╝███████║
    ░░░██║░░░██╔══╝░░██║░░██╗██╔══██║
    ░░░██║░░░███████╗╚█████╔╝██║░░██║
    ░░░╚═╝░░░╚══════╝░╚════╝░╚═╝░░╚═╝
    ██████╗░██╗░░░░░░█████╗░░██████╗░
    ██╔══██╗██║░░░░░██╔══██╗██╔════╝░
    ██████╦╝██║░░░░░██║░░██║██║░░██╗░
    ██╔══██╗██║░░░░░██║░░██║██║░░╚██╗
    ██████╦╝███████╗╚█████╔╝╚██████╔╝
    ╚═════╝░╚══════╝░╚════╝░░╚═════╝░
    Welcome engineer.
    https://www.future.co.jp/recruit/
  -->
  
  <title>5TB/日 のデータをAWS Glueでさばくためにやったこと（概要編 | フューチャー技術ブログ</title>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  
  <meta name="description" content="みなさん、初めまして、お久しぶりです、こんにちは。フューチャーアーキテクト2018年新卒入社、1年目エンジニアのTIG（Technology Innovation Group）所属の澤田周吾です。大学では機械航空工学を専攻しており、学生時代のインターンなどがキッカケで入社を決意しました。 実は、本記事でフューチャーテックブログの2記事目となります。インターン時代も ジャガイモARの記事  を書">
<meta property="og:type" content="article">
<meta property="og:title" content="5TB&#x2F;日 のデータをAWS Glueでさばくためにやったこと（概要編 | フューチャー技術ブログ">
<meta property="og:url" content="https://future-architect.github.io/articles/20180828/index.html">
<meta property="og:site_name" content="フューチャー技術ブログ">
<meta property="og:description" content="みなさん、初めまして、お久しぶりです、こんにちは。フューチャーアーキテクト2018年新卒入社、1年目エンジニアのTIG（Technology Innovation Group）所属の澤田周吾です。大学では機械航空工学を専攻しており、学生時代のインターンなどがキッカケで入社を決意しました。 実は、本記事でフューチャーテックブログの2記事目となります。インターン時代も ジャガイモARの記事  を書">
<meta property="og:locale" content="ja_JP">
<meta property="og:image" content="https://future-architect.github.io/images/20180828/photo_20180828_01.jpg">
<meta property="og:image" content="https://future-architect.github.io/images/20180828/photo_20180828_02.png">
<meta property="og:image" content="https://future-architect.github.io/images/20180828/photo_20180828_03.png">
<meta property="article:published_time" content="2018-08-28T04:27:14.000Z">
<meta property="article:modified_time" content="2022-06-09T01:03:49.333Z">
<meta property="article:tag" content="AWS">
<meta property="article:tag" content="データレイク">
<meta property="article:tag" content="Glue">
<meta property="article:tag" content="データエンジニアリング">
<meta property="article:tag" content="ETL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://future-architect.github.io/images/20180828/photo_20180828_01.jpg">
  
  <link rel="alternate" href="/atom.xml" title="フューチャー技術ブログ" type="application/atom+xml">
  
  <link rel="icon" href="/favicon.ico">
  <link rel="apple-touch-icon" sizes='180x180' href="/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes='57x57' href="/apple-touch-icon-57x57.png">
  <link rel="canonical" href="https://future-architect.github.io/articles/20180828/">
  <meta content="AWS,データレイク,Glue,データエンジニアリング,ETL" name="keywords">
  <meta content="澤田周吾" name="author">
  <link rel="preload" as="image" href="/banner.jpg" />
  <link rel='manifest' href='/manifest.webmanifest'/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/css/bootstrap.min.css" integrity="sha384-F3w7mX95PdgyTmZZMECAngseQB83DfGTowi0iMjiWaeVhAn4FJkqJByhZMI3AhiU" crossorigin="anonymous">
  <link rel="stylesheet" href="/metronic/assets/style.css">
  <link rel="stylesheet" href="/css/theme-styles.css">
<meta name="generator" content="Hexo 5.4.2"></head>

<body class="corporate">
  <div class="wrap" itemscope itemtype="https://schema.org/TechArticle">
  <!-- BEGIN HEADER -->
<header class="header">
	<div class="header-overlay">
		<div class="header-menu"></div>
		<div class="header-title"><a href="/">Future Tech Blog</a></div>
		<div class="header-title-sub">フューチャー技術ブログ</div>
	</div>
</header>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li><a href="/articles/">Blog</a></li>
    <li class="active">Post</li>
  </ul>
  <section id="main" class="margin-top-30">
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Infrastructure/">Infrastructureカテゴリ</a>
  </div>


    <h2 itemprop="name" class="article-title">5TB/日 のデータをAWS Glueでさばくためにやったこと（概要編
  
  <a target="_blank" rel="noopener" href="https://github.com/future-architect/tech-blog/edit/master/source/_posts/20180828-gluw.md" title="Suggest Edits" class="github-edit"><i class="github-edit-icon"></i></a>
  
</h2>

    <div class="row">
  <main class="col-md-9 blog-posts">
    <article id="post-20180828-gluw" class="article article-type-post blog-item" itemscope itemprop="blogPost">
      <div class="article-inner">
        
        <header class="article-header">
          <ul class="blog-info">
            <li class="blog-info-item"><a href="/articles/2018/" class="publish-date"><time datetime="2018-08-28T04:27:14.000Z" itemprop="datePublished">2018.08.28</time></a>
</li>
            <li class="blog-info-item"><li><a href="/authors/%E6%BE%A4%E7%94%B0%E5%91%A8%E5%90%BE" title="澤田周吾さんの記事一覧へ" class="post-author">澤田周吾</a></li></li>
            <li class="blog-info-item">
  
    
    <a href="/tags/AWS/" title="AWSタグの記事へ" class="tag-list-link">AWS</a>
  
    
    <a href="/tags/データレイク/" title="データレイクタグの記事へ" class="tag-list-link">データレイク</a>
  
    
    <a href="/tags/Glue/" title="Glueタグの記事へ" class="tag-list-link">Glue</a>
  
    
    <a href="/tags/データエンジニアリング/" title="データエンジニアリングタグの記事へ" class="tag-list-link">データエンジニアリング</a>
  
    
    <a href="/tags/ETL/" title="ETLタグの記事へ" class="tag-list-link">ETL</a>
  

</li>
          </ul>
          </header>
        
        <div class="article-entry" itemprop="articleBody">
          
            <img src="/images/20180828/photo_20180828_01.jpg" alt="">

<p>みなさん、初めまして、お久しぶりです、こんにちは。<br>フューチャーアーキテクト2018年新卒入社、1年目エンジニアのTIG（Technology Innovation Group）所属の澤田周吾です。大学では機械航空工学を専攻しており、学生時代のインターンなどがキッカケで入社を決意しました。</p>
<p>実は、本記事でフューチャーテックブログの2記事目となります。インターン時代も <a href="/articles/20170421/">ジャガイモARの記事</a>  を書かせて頂きました。入社してからもこうして業務で学んだIT技術を記事に書くという機会を貰え、なんだか懐かしいやら感慨深いやらの思いで一杯です。</p>
<p>さて、3ヶ月の新人研修後にすぐに配属されたプロジェクトで、AWSを使ったビックデータ分析のための基盤構築をお手伝いしています。わたしは分析のための前処理であるETL（Extract、Transform、Load）処理部分をちょっと変わった性格の先輩方と一緒に開発しており、今回はそれに用いているサービスであるAWS Glueについて紹介いたします。</p>
<p>※記事は2回にわけて発信していきたいと考えています。<br>第一弾として、題名の大規模データを処理するために行った様々な工夫を説明する前に、Glueの概要や開発Tips、制約について書かせていただきます</p>
<p>第二弾は<a href="/articles/20181205/">こちら</a>をどうぞ。</p>
<h1 id="AWS-Glueとは"><a href="#AWS-Glueとは" class="headerlink" title="AWS Glueとは"></a>AWS Glueとは</h1><p>ご存知の方も多いかと思いますが、簡単にGlueについての説明です。</p>
<blockquote>
<p>AWS Glue は抽出、変換、ロード (ETL) を行う完全マネージド型のサービスで、お客様の分析用データの準備とロードを簡単にします。AWS マネジメントコンソールで数回クリックするだけで、ETL ジョブを作成および実行できます。<br><a target="_blank" rel="noopener" href="https://aws.amazon.com/jp/glue/">引用:AWS公式サイト</a></p>
</blockquote>
<p>簡単に言うと、「データ処理を行うサービス」です。<br>公式サイトにも書かれていますが、Glueの特徴として、5点挙げられます。</p>
<ol>
<li>AWSの一つであること</li>
<li>ETL処理を行うサービスであること</li>
<li>完全マネージド型であること</li>
<li>Scala、Python、Apache Spark を使用できること</li>
<li>並立分散処理ができること</li>
</ol>
<h1 id="今回実現したいこと"><a href="#今回実現したいこと" class="headerlink" title="今回実現したいこと"></a>今回実現したいこと</h1><p>S3やDynamoDBに配備された入力データを、少々複雑な加工ロジックが入ったETL処理を何度か繰り返し、蓄積用のDynamoDBと、分析用のS3に出力することです。<br>入力のマスタデータは日次程度の洗い替えでOK、入力データは10分毎にzip圧縮後で35GB程度がDataLakeに供給され、それらを逐次バッチ的に処理します。ETLの処理ウインドウ時間は10分以内となり、1日では合計5TBに及びます。</p>
<img src="/images/20180828/photo_20180828_02.png" loading="lazy">

<p>データ量が多いため、Glueが利用できる前だとSpark on EMRで処理することを検討していたと思います。EMRも良いサービスだと認識していますが、10分毎に処理する要件だと、EMRクラスタを常時立ち上げざる得ないため、EMRの保守運用を考えるとマネージドでSparkを扱えるGlueを採用したほうが良いのでは？という判断がなされました。他にもAWS Athenaなども候補に上がりましたが、読み込み時のパーティションは可能なものの、2018.08時点ではクエリ結果をS3に書き込む際に、DynamicPartitionができないという点がネックで採用には至りませんでした。</p>
<p>ETL処理の中身を簡単に言うと…</p>
<ol>
<li>処理対象のフィルター（例: 異常値の排除など）</li>
<li>コンテンツへのエンリッチメント（例: マスタデータと結合し非正規化処理など）</li>
<li>多様な分析軸でのグルーピング（例: ユーザID軸、ユーザの属性軸など）</li>
<li>逆ジオコーディングのために外部サービスにアクセスが必要</li>
<li>k-meansライクなクラスタリング処理が必要</li>
</ol>
<p>などがあります。<br>特に4,5は少し毛色が変わっており、処理特性の違いからETLのパイプラインを当初より少し多めに分割する必要性がでてきました。今回は4つのステップに分割しました。そのため、各ステップは10分よりずっと短い時間で処理を完了させる必要があります。</p>
<p>また、今回の要件だとワークフローは複雑な分岐や待ち合わせが存在せず、前のジョブAが終わったら素直に後ろのジョブBを起動すれば良いだけだったため、StepFunctionなどを導入せずGlueで完結して構築しています。</p>
<h1 id="EMR-と-Glue-比較"><a href="#EMR-と-Glue-比較" class="headerlink" title="EMR と Glue 比較"></a>EMR と Glue 比較</h1><p>EMRとGlueですが、アプリケーションの実装としてはどちらもSparkを利用する以上は差が出ないため、インフラレベルで比較した表となります。どうやら、Glueは内部的にEMRを起動させているようなので、GlueはSparkクラスタを構築せずジョブが実行できるといった仕組みと捉えたほうが理解しやすいかと思います。</p>
<p>EMRの方が細かくチューニングが可能ですが、先に述べたように保守運用性の観点からGlueを採用しました。</p>
<div class="scroll"><table>
<thead>
<tr>
<th>#</th>
<th>EMR</th>
<th>Glue</th>
</tr>
</thead>
<tbody><tr>
<td>Pros</td>
<td>ブートストラップアクション/ステップ処理を通じてOSレベルからの設定変更が可能</td>
<td>ランタイム環境がフルマネージドで提供されるため、クラスタの管理が不要</td>
</tr>
<tr>
<td></td>
<td>コアノード/タスクノード数を調整することでシステムリソース量の調整が可能</td>
<td>サービスとしての単一障害点がない</td>
</tr>
<tr>
<td></td>
<td>Spark以外のツールを利用可能</td>
<td>データカタログを他AWSサービスと共有可能</td>
</tr>
<tr>
<td>Cons</td>
<td>マスタノードが単一障害点（特に常駐起動させておく場合にネック）</td>
<td>ランタイム環境がフルマネージドで提供されるため、OSレベル・クラスタレベルでの設定変更が不可能(システムリソースは調整可能)</td>
</tr>
<tr>
<td></td>
<td>EMRクラスタの設定や起動処理の設計・実装が必要</td>
<td>ー</td>
</tr>
</tbody></table></div>
<h1 id="Glueで行えること"><a href="#Glueで行えること" class="headerlink" title="Glueで行えること"></a>Glueで行えること</h1><p>具体的なイメージが湧きにくいと思いますので、早速ですが、コードベースでどういうことができるかいくつか例示していきたいと思います。<br>今回、コードはPythonで説明していきます。</p>
<h2 id="S3上のファイルの読み書き"><a href="#S3上のファイルの読み書き" class="headerlink" title="S3上のファイルの読み書き"></a>S3上のファイルの読み書き</h2><p>以下のコードでS3に対して読み込み・書き込みが行えます。<br>ファイル形式を変更することで、CSV、JSON、Parquetなどの形式に対応できます。</p>
<p>Glueで定義されたデータ構造のDynamicFrameを使っていきます。<br>使い方はSparkのDataFrameのように扱うことができます。</p>
<figure class="highlight python"><figcaption><span>S3からCSVファイルの読み込み処理</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = glueContext.create_dynamic_frame.from_options(</span><br><span class="line">    connection_type=<span class="string">&quot;s3&quot;</span>,</span><br><span class="line">    connection_options=&#123;</span><br><span class="line">        <span class="string">&quot;paths&quot;</span>: [<span class="string">&quot;s3://&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;バケット名&quot;</span>)]&#125;,</span><br><span class="line">    <span class="built_in">format</span>=<span class="string">&quot;csv&quot;</span>,  <span class="comment"># ファイル形式指定 json, parquet等に変更可</span></span><br><span class="line">    format_options=&#123;<span class="string">&quot;withHeader&quot;</span>: <span class="literal">True</span>&#125;  <span class="comment"># 1行目をスキーマ名として認識True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><figcaption><span>DynamicFrame(df)をS3にcsv形式で出力処理</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">datasink = glueContext.write_dynamic_frame.from_options(</span><br><span class="line">        frame=df,  <span class="comment"># 出力するDynamicFrameを指定</span></span><br><span class="line">        connection_type=<span class="string">&quot;s3&quot;</span>,</span><br><span class="line">        connection_options=&#123;</span><br><span class="line">            <span class="string">&quot;path&quot;</span>: [<span class="string">&quot;s3://&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;バケット名&quot;</span>)],</span><br><span class="line">            <span class="string">&quot;partitionKeys&quot;</span>: <span class="string">&quot;パーティションを切るキー名&quot;</span>&#125;,</span><br><span class="line">        <span class="built_in">format</span>=<span class="string">&quot;csv&quot;</span>  <span class="comment"># ファイル形式指定</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<p>他のファイル形式については<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-programming-etl-format.html">AWS Glue の ETL 出力用の形式オプション
</a> を参考ください。CSVであれば区切り文字やヘッダ行出力の有無もオプションで指定できます。</p>
<h2 id="DaynamoDBからの読み込み、書き込み"><a href="#DaynamoDBからの読み込み、書き込み" class="headerlink" title="DaynamoDBからの読み込み、書き込み"></a>DaynamoDBからの読み込み、書き込み</h2><p>DynamoDBへのアクセスはAWS SDK for Pythonなboto3を利用します。<br>2018.08時点では標準のコネクタは存在しないようです。</p>
<figure class="highlight python"><figcaption><span>DynamoDB初期化</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dynamo_region=<span class="string">&quot;AWSリージョン名&quot;</span></span><br><span class="line">dynamodb = boto3.resource(</span><br><span class="line">        <span class="string">&#x27;dynamodb&#x27;</span>,</span><br><span class="line">        region_name=dynamo_region,</span><br><span class="line">        endpoint_url=<span class="string">&#x27;http://dynamodb.&#x27;</span> + dynamo_region + <span class="string">&#x27;.amazonaws.com&#x27;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<p>あとは素直にget, put すれば読み書きできます。</p>
<figure class="highlight python"><figcaption><span>DynamoDBからデータベースの読み込み</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">table = dynamodb.Table(<span class="string">&quot;テーブル名&quot;</span>)</span><br><span class="line">response = table.get_item(</span><br><span class="line">        Key=&#123; <span class="string">&#x27;xxx&#x27;</span>: xxx, <span class="string">&#x27;yyy&#x27;</span>: yyy &#125;</span><br><span class="line">    )</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><figcaption><span>DynamoDBへデータ出力</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">table = dynamodb.Table(<span class="string">&quot;テーブル名&quot;</span>)</span><br><span class="line">response = table.put_item(</span><br><span class="line">    Item=&#123;<span class="string">&#x27;xxx&#x27;</span>: xxx, <span class="string">&#x27;yyy&#x27;</span>: yyy&#125;</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<p>もし、DynamoDBへのR/Wを行う場合は、Read/Writeのキャパシティーユニットを確認するとともに、レスポンスでスループット超過時のエラーハンドリングもお忘れないように注意ください。</p>
<h2 id="加工処理"><a href="#加工処理" class="headerlink" title="加工処理"></a>加工処理</h2><p>入力で取得したデータは例えば以下のようにSQLクエリを用いて加工することができます。</p>
<figure class="highlight python"><figcaption><span>SQLを利用した加工処理</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DynamicFrameをDataFrameに変換</span></span><br><span class="line">dataFrame = df.toDF()</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataFrameにテーブル名を割り当て</span></span><br><span class="line">dataFrame.registerTempTable(<span class="string">&#x27;table_name&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SparkSQL文にてデータ加工</span></span><br><span class="line">select_table = spark.sql(<span class="string">&#x27;SELECT * FROM table_name&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>今回の開発では情報量が多いことと開発チームメンバーのスキルセットからDataFrameに変換後にSQLで加工する手法を使いました。</p>
<h2 id="ジョブのワークフロー"><a href="#ジョブのワークフロー" class="headerlink" title="ジョブのワークフロー"></a>ジョブのワークフロー</h2><p>GlueのTriggerを利用することで、Glue内でジョブのワークフローを作ることができます。<br>また、起動を制御するためのTriggerは3種類用意されています。</p>
<ol>
<li>Triggerの開始をタイマーで行う ＝ <strong>スケジュール</strong></li>
<li>ジョブイベントが監視対象リストに一致した場合に行う ＝ <strong>ジョブイベント</strong></li>
<li>手動で開始させる ＝ <strong>オンデマンド</strong></li>
</ol>
<p>1のスケジュールトリガー、3のオンデマンドトリガーについてはイメージがつくと思います。<br>2のジョブイベントトリガーについて補足していきます。</p>
<p>ジョブイベントトリガーは、ジョブXが終わったら次のジョブYを起動する、といった依存関係を設定することができます。<br>具体的にはジョブイベントトリガー作成時には以下の項目を選択することができます。</p>
<ul>
<li>監視対象ジョブ（複数可）</li>
<li>トリガーするジョブ（複数可）</li>
<li>「成功、失敗、停止、タイムアウト」の４つのジョブステータス</li>
<li>監視対象ジョブとステータスが全一致でトリガーするか、部分一致でトリガーするか</li>
<li>起動時に渡すパラメータ（セキュリティ設定、ブックマーク、タイムアウト、キー/値）</li>
</ul>
<p>例：ジョブイベントトリガーを利用して以下の様なフローを３つのジョブイベントトリガーを設定することで実現することができます</p>
<img src="/images/20180828/photo_20180828_03.png" loading="lazy">

<ul>
<li>トリガー1はジョブAが成功したらジョブB, Cを起動</li>
<li>トリガー2はジョブBが成功したらジョブDを起動</li>
<li>トリガー3はジョブC, Dが成功したらジョブEを起動</li>
</ul>
<h1 id="Glue開発Tips"><a href="#Glue開発Tips" class="headerlink" title="Glue開発Tips"></a>Glue開発Tips</h1><p>この1ヶ月で学んだGlueで開発を行う上でのコツをお伝えします</p>
<h2 id="Tips1-Glueデバックについて"><a href="#Tips1-Glueデバックについて" class="headerlink" title="Tips1. Glueデバックについて"></a>Tips1. Glueデバックについて</h2><p>Glueの開発・デバッグには、開発エンドポイントを利用すると便利です。</p>
<p>ローカルのコンソール上から開発エンドポイントへSSH接続することで、Glueに対しpythonやscalaのREPLを使用できます。</p>
<p>エンドポイント作成はGlueのDPU数を指定し、SSH用の鍵を設定するのみです。わずか数クリック、1~2分で完了できます。ただし、エンドポイント作成後は裏でGlue(Spark)のクラスタ構築が行われるため、実際に使用可能となるのはその完了後（約15分ほどかかりました）です。</p>
<p>作成したエンドポイントへApache Zeppelin ノートブックを接続し、ノートブックでの開発も可能なようですが、今回は必要でなかったため使用しませんでした。ノートブックはローカルでもEC2上でも利用可能なようです。詳細は以下をご覧ください。<br><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/dev-endpoint.html">https://docs.aws.amazon.com/ja_jp/glue/latest/dg/dev-endpoint.html</a></p>
<p>また開発エンドポイントも裏ではGlueのクラスタが上がっているため、通常通りのGlue料金が請求されます。開発エンドポイントのDPU数はデフォルトで5、料金は1DPUあたり$0.44/時かかります。(公式ドキュメントには$0.44/秒と誤記されてますが、そんな高くないです)。</p>
<p>仮に終業時に開発エンドポイントを落とし忘れた場合、翌出社までに以下の金額がかかります。<br>　　5 * $0.44 * 14時間(20時退社、10時出社) = $30.8<br>1回の飲み代程度です。一晩にしてはなかなかです。自動で落とす方法もちょっと調べてみましたが見つけられず…。<br>忘れずに落とすようにしましょう！</p>
<h3 id="※開発エンドポイントを使わない場合※"><a href="#※開発エンドポイントを使わない場合※" class="headerlink" title="※開発エンドポイントを使わない場合※"></a>※開発エンドポイントを使わない場合※</h3><p>開発開始直後は開発エンドポイントの存在を知らず、Glueコンソール上でソースを編集し実行することで開発をしていました。<br>その当時の開発スタイルの状況も悪い例として記載します。<strong>興味が無い場合はスキップください。</strong></p>
<p><strong>（※開発エンドポインを利用すれば解決できる内容です。開発エンドポイントをぜひ利用しましょう！）</strong></p>
<ul>
<li><p>ジョブ実行に時間かかる</p>
<ul>
<li>Glueジョブは実行の都度リソースを確保しクラスタの構成を行います。そのため純粋なコンピューティング以外で毎回10分ほど待たされます</li>
<li>ソースを編集 → 実行(10分以上かかる) → 結果を確認、ソースを修正 → 実行(10分以上かかる) → …</li>
</ul>
</li>
<li><p>不要なログが多く目的のログに辿り着けない</p>
<ul>
<li>Glueの実行ログはCloudWatch上から確認可能ですが、実行スクリプトのログとSparkのログが同一のログストリーム上に出力されます<ul>
<li>そのため大量のSparkのログに目的のスクリプトログが埋もれます</li>
<li>CloudWatchから目的のログに辿り着けるよう、ログにプレフィクスなどをつけるなど工夫が必要でした</li>
</ul>
</li>
<li>ソースを編集 → 実行(10分以上かかる) → CloudWatchのログストリーム表示 → プレフィクスで目的のログ検索 → 結果を確認 → ソースを修正 → 実行(10分以上かかる) → …</li>
</ul>
</li>
<li><p>ソース修正、実行のための画面遷移が多い</p>
<ul>
<li>ジョブの一覧画面からスクリプトを参照することはできますが、編集するには専用の編集画面で行う必要があります。そのため編集の都度画面遷移が必要です</li>
<li>また、編集画面にはジョブの実行ボタンが存在しますが、このボタンが反応せずほとんど実行開始してくれません(原因は不明)。そのため実行の都度またジョブ一覧画面へと遷移する必要があります</li>
<li>ソースを編集 → 編集画面から実行画面へ → 実行(10分以上かかる) → CloudWatchのログストリーム表示 → プレフィクスで目的のログ検索 → 結果を確認 → 実行画面から編集画面へ → ソースを修正 → 編集画面から実行画面へ → 実行(10分以上かかる) → …</li>
</ul>
</li>
</ul>
<p>どうでしょう？壮絶な開発状況を想像していただけたでしょうか？<br>エンジニアたるもの、あるものは利用して賢く効率よく働きたいと、改めて思いました…</p>
<p>これらの苦労は <strong>開発エンドポイントを利用すれば</strong> その多くが回避できます。ぜひ利用しましょう！</p>
<h2 id="Tips2-AWS-Athenaで簡易的にデータ確認"><a href="#Tips2-AWS-Athenaで簡易的にデータ確認" class="headerlink" title="Tips2. AWS Athenaで簡易的にデータ確認"></a>Tips2. AWS Athenaで簡易的にデータ確認</h2><p>Glueのテーブルを使用する場合は、Athenaのクエリで中身を確認できるため開発が捗りました。</p>
<p>Athenaからテーブルに対して、 <code>SELECT * FROM TABLE</code> などのクエリを投げても良いですし、Glueコンソールのテーブル一覧画面から「アクション」→「データの確認」を選択しても良いです。後者の場合は自動でAthenaから <code>SELECT * FROM TABLE limit 10</code> というクエリを投げてくれます。どちらの場合もAthenaの料金が発生するため、読み取りデータ量には注意が必要です。</p>
<p>また、開発にSparkSQLを用いる場合はAthenaも同じSQLであるため、AthenaでSQLを開発してからSparkへ移植という使い方が可能です。ただし、AthenaはPrestoベース、SparkSQLはHiveSQLのスタイルをベースに開発されており、利用できる構文に微妙な差異がるため注意が必要です。<br>Athenaで開発したSQLをそのまま移植しようとした時に少しハマりもしました。</p>
<p>例えば文字列結合の場合、以下のようなSQLはAthenaでは利用できてSparkSQLでは利用できません。</p>
<figure class="highlight sql"><figcaption><span>AthenaSQLとSparkSQL</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- AthenaではOK、SparkSQLではNG</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;str1&#x27;</span> <span class="operator">||</span> <span class="string">&#x27;str2&#x27;</span> <span class="operator">||</span> <span class="string">&#x27;str3&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- SparkSQLでOK</span></span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(<span class="string">&#x27;str1&#x27;</span>, <span class="string">&#x27;str2&#x27;</span>, <span class="string">&#x27;str3&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>SparkSQLの詳細については、GlueのVersionが2018.08月時点では2.1.1ですので、下記のガイドを参考ください。<br><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/2.1.1/sql-programming-guide.html">https://spark.apache.org/docs/2.1.1/sql-programming-guide.html</a></p>
<h2 id="Tips3-Glueのカタログデータについて"><a href="#Tips3-Glueのカタログデータについて" class="headerlink" title="Tips3. Glueのカタログデータについて"></a>Tips3. Glueのカタログデータについて</h2><p>Glueといえばカタログデータ、という印象がありましたが実はカタログが未登録でもETLジョブは実行可能です。</p>
<p>GlueのデータカタログはApache Hive メタストアとの互換性がありますが、EMR以外にもAthenaやRedshift Spectrum でも利用できます。</p>
<p>開発Tips2であるように一部のS3バケットに対してはAthenaのクエリを発行したかったためデータカタログを設定しましたが、ETL処理に閉じて見た場合に恩恵が無いように感じられたため最終的にはデータカタログを利用しませんでした。</p>
<h2 id="Tips4-DataFrameとDynamicFrameについて"><a href="#Tips4-DataFrameとDynamicFrameについて" class="headerlink" title="Tips4. DataFrameとDynamicFrameについて"></a>Tips4. DataFrameとDynamicFrameについて</h2><p>Glueでは2種類のDataFrameを利用することができます。<br>SparkのDataFrameと、Glueで独自に定義されたDynamicFrameです。</p>
<p>両者ともテーブルの構造でデータを持ち、データ操作を行えるという点は共通していますが、DynamicFrameはchoice型を扱うという点で差異があります。choice型とは、同一列に複数のデータ型を持つことができる型です。</p>
<p>例えば、同一列にstringとdoubleを含むデータをDynamicFrameに読み込んだ場合、以下のようなイメージとなります。</p>
<p>取り込み元データ</p>
<div class="scroll"><table>
<thead>
<tr>
<th align="left">col1</th>
<th align="left">col2</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">str</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">20.3</td>
</tr>
</tbody></table></div>
<p>取り込み後DynamicFrame</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line">┣- col1: int</span><br><span class="line">┣- col2: choice</span><br><span class="line">┃┣- string</span><br><span class="line">┃┣- double</span><br></pre></td></tr></table></figure>

<p>col2は2種類の型のデータが存在するためchoice型となり、stringとdouble両方を保持します。<br>様々なデータ取り込みに対応可能とするため、このような構造になっているのでしょう。</p>
<p>ただchoice型はこのままでは扱いにくいため、resolveChoice関数によって扱いやすい形へ変換してあげるとよいです。<br>resolveChoice関数では以下のことができます。</p>
<ul>
<li>choice列を任意の型にcastする。(choice列を、例えばstring列へ変換する)</li>
<li>choice列に含まれる型別に、新しく列を生成する。(stringとdoubleの2列を生成する)</li>
<li>choice列に含まれる型を保持できる構造体の列を生成する。(stringとdoubleを保持できる構造体列を1列生成する)</li>
<li>choice列を任意の型にcastした列を生成する。(例えばstring列を1列生成する)</li>
</ul>
<p>今回は、調査時の情報量が圧倒的にSparkのDataFrameの方が多く使いやすいため、データの取り込み後choice列は早々にstringへ変換し、かつSparkのDataFrameへ変換して使用しています。</p>
<p>データの取り込みはDynamicFrameで行い、本格的なデータの加工はSparkのDataFrameで行う、という使い分けが良いかと思います。</p>
<p>DynamicFrameやresolveChoiceの詳細は以下を参考ください。<br><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html">https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame.html</a> (edited)</p>
<h1 id="Glueの注意点"><a href="#Glueの注意点" class="headerlink" title="Glueの注意点"></a>Glueの注意点</h1><p>Glueを利用して感じた注意点をまとめます。</p>
<h2 id="注意1-既存データに対するUpdate"><a href="#注意1-既存データに対するUpdate" class="headerlink" title="注意1. 既存データに対するUpdate"></a>注意1. 既存データに対するUpdate</h2><p>Glueではカラムの加工、テーブルの新規作成（SQLでいうCreate As Select）、テーブルのJoinなどETL処理ができます。またその特性上、中間データはS3上に配備されることが多いと思います。</p>
<p>しかしS3上にある既存カラムの <strong>Updateはできません</strong> ので注意が必要です。<br>これは裏側で動くSparkがあくまでS3へ追記しか行っていないからでしょう。<br>どうしてもUpdateしたいときは以下で代用できないかなど追加の検討が必要です。</p>
<ol>
<li>Delete &amp; Insert でテーブルやパーティション自体を再作成する</li>
<li>既存データの更新せずデータを追記し、抽出時にDistinctするロジックを追加する</li>
</ol>
<p>どちらにしても、書き込みや読み込みに余分な処理が発生するため処理コストが多くかかってしまいます。<br>最終的な利用元である分析に対して、どれくらいのデータ鮮度が求められるか、費用対効果で考える必要があると思います。</p>
<p>※ちなみに、DynamoDBに対しては書き換えたい情報だけに絞り込んでInsertすることで、実質的にUpdate処理が可能となりますが、DynamoDBのRCU/WCUの費用を考えると利用したいユースケースは少なそうです。</p>
<h2 id="注意2-C言語に依存するパッケージ（Pandas等）が利用不可"><a href="#注意2-C言語に依存するパッケージ（Pandas等）が利用不可" class="headerlink" title="注意2. C言語に依存するパッケージ（Pandas等）が利用不可"></a>注意2. C言語に依存するパッケージ（Pandas等）が利用不可</h2><p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/aws-glue-programming-python-libraries.html">リファレンスにも記載</a>がありますが、Glueの仕様でC言語依存パッケージを使うことができません。<br>Scikit_learnを使いたかったのですが、内部パッケージにpandasが使われているため起動できず、Scikit_learnの処理は違うアーキテクチャ（ECS）に切り分けました。すでに使いたいものが決まっている場合は注意してください。</p>
<p>もともとは、PySparkのUDFで処理可能と想定していましたが、Glueのこの制約を見逃していて、半日潰してしまいました。</p>
<p>C言語依存パッケージがGlueで使えない理由としては、コンパイルが絡んでいるのではないかと考えています。今後のGlueの機能拡張で使えるようになってくれると便利さが増しますね。</p>
<h2 id="注意3-ジョブブックマークが対応していない入力"><a href="#注意3-ジョブブックマークが対応していない入力" class="headerlink" title="注意3. ジョブブックマークが対応していない入力"></a>注意3. ジョブブックマークが対応していない入力</h2><p>Glueの機能にジョブブックマークというすでに処理されたデータかどうかを判定し、処理済みであれば次のジョブでは入力データに含めないという機能があります。<br>2018.08時点ではJSON、CSVなどには対応しているものの、zipファイルやParquestには対応していませんでした。<br><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html">https://docs.aws.amazon.com/ja_jp/glue/latest/dg/monitor-continuations.html</a></p>
<p>そのため、もしジョブブックマーク非対応の入力に対しては、手動でオフセット管理する必要があります。<br>今回、わたしたしは入力ディレクトリに処理済みかどうかのフラグファイルを配備し、Glueジョブ上でその有無を確認することで処理対象とするか判定するロジックを追加しました。</p>
<h2 id="注意4-S3上のソースファイルの実行"><a href="#注意4-S3上のソースファイルの実行" class="headerlink" title="注意4. S3上のソースファイルの実行"></a>注意4. S3上のソースファイルの実行</h2><p>S3にソースファイルを配置する際に複数ファイルの場合は、zip圧縮する必要があります。<br>地味ですが忘れると動かないのでご注意を。</p>
<h2 id="注意5-並立分散処理"><a href="#注意5-並立分散処理" class="headerlink" title="注意5. 並立分散処理"></a>注意5. 並立分散処理</h2><p>Sparkの設定にちょっとした工夫が必要です。<br>第2回目の記事で詳しく説明したいと思います。</p>
<h2 id="注意6-料金について"><a href="#注意6-料金について" class="headerlink" title="注意6. 料金について"></a>注意6. 料金について</h2><p>Glueの料金計算はやや特殊でDPU (Data Processing Unit) という数に基づいて時間（1秒）ごとに課金が発生します。2018.08時点では1DPUでは4vCPU・16GBメモリが提供されます。<br>2018.08時点では <strong>10分の最小期間が設定</strong> されているため、処理時間が10分以下のミニバッチを連続的に起動させたい場合にはコスト的には不利になってしまいます。</p>
<p><a target="_blank" rel="noopener" href="https://aws.amazon.com/jp/glue/pricing/">https://aws.amazon.com/jp/glue/pricing/</a></p>
<p>これを避けるために分析部門にとってはデータの鮮度は下がるものの、20-30分単になどに処理頻度を変更する余地が無いか、費用対効果から見た全体最適の視点で検討中です。</p>
<h2 id="注意7-リソースの確保について"><a href="#注意7-リソースの確保について" class="headerlink" title="注意7. リソースの確保について"></a>注意7. リソースの確保について</h2><p>（2018.08時点、東京リージョンで発生した事象です）Glueのリソースは先に述べたDPUという単位でコンピューティングされます。これを性能検証のために、数十DPUといった比較的大きめに確保しようとするとリソースが確保できず起動できなかったことが何度かありました。<br>2018.08時点ではGlueリソースをリザーブド化することもできず、設定レベルでの回避が難しい状態です。</p>
<p>東京リージョンでGlueが利用可能になったのは<a target="_blank" rel="noopener" href="https://aws.amazon.com/jp/about-aws/whats-new/2017/12/aws-glue-is-now-available-in-the-asia-pacific-tokyo-aws-region/">2017.12</a> と比較的新しく、今後も継続的にリソースの増強などが期待されるため、改善に向かうと予想しています。現時点では実行タイミングによっては確保が難しい場合があるようです。人気のサービスであるという証拠なのかもしれませんね。</p>
<p>他の時間帯・日本国外リージョンなどを試すことや、処理粒度をある程度細かくし急激に大きなDPUを確保しないようにするなどの工夫が必要になってきます。また、どうしても確実に実行できないと困る！という場合は、リザーブドインスタンスでEMRを利用するしか無いようです。</p>
<h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>Glue（直訳：のり）とはよく名を付けたものだと感じています。<br>粗削りで膨大なデータを、使いやすい形に成形してあげる。つまり、データと後続のシステムをうまくつなぎ合わせることができるものがGlueです。</p>
<p>以下にあてはまる方はGlueの導入を考えてみたらどうでしょうか。</p>
<ul>
<li>ビッグデータの処理が必要</li>
<li>起動時間は常時ではなく短い</li>
<li>サーバーを立てる余裕がない</li>
<li>運用、保守する余裕がない</li>
<li>パイオニア精神がある</li>
</ul>
<p>実はGlueの記事はネット上にはまだ多くない状態です。<br>そのため、Glue開発を導いていきたいというパイオニア精神ある方におすすめの領域だと思います。</p>
<h1 id="次回のGlueの記事について"><a href="#次回のGlueの記事について" class="headerlink" title="次回のGlueの記事について"></a>次回のGlueの記事について</h1><p>次回の内容はGlueを用いた性能改善です。</p>
<ul>
<li><a href="https://future-architect.github.io/articles/20181205/">https://future-architect.github.io/articles/20181205/</a></li>
</ul>
<p>皆さんの参考になれば光栄です。</p>
<p>Glueを検討の方はご気軽にご連絡ください。</p>

          
        </div>
        <footer>
          <section class="social-area">
          <!-- シェアボタン START -->
  <ul class="social-button">
    
    <!-- Twitter -->
    <li>
      <a class="social-btn twitter-btn" target="_blank" href="https://twitter.com/share?url=https://future-architect.github.io/articles/20180828/&related=twitterapi%2Ctwitter&text=5TB/%E6%97%A5%20%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92AWS%20Glue%E3%81%A7%E3%81%95%E3%81%B0%E3%81%8F%E3%81%9F%E3%82%81%E3%81%AB%E3%82%84%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8%EF%BC%88%E6%A6%82%E8%A6%81%E7%B7%A8%20%7C%20%E3%83%95%E3%83%A5%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E6%8A%80%E8%A1%93%E3%83%96%E3%83%AD%E3%82%B0" rel="nofollow noopener">
        <i></i><span class="social-btn-label">1</span>
      </a>
    </li>
    <!-- Facebook -->
    <li>
      <a class="social-btn fb-btn" target="_blank" href="http://www.facebook.com/share.php?u=https://future-architect.github.io/articles/20180828/&t=5TB/%E6%97%A5%20%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92AWS%20Glue%E3%81%A7%E3%81%95%E3%81%B0%E3%81%8F%E3%81%9F%E3%82%81%E3%81%AB%E3%82%84%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8%EF%BC%88%E6%A6%82%E8%A6%81%E7%B7%A8" rel="nofollow noopener">
        <i></i><span class="social-btn-label">32</span>
      </a>
    </li>
    <!-- hatebu -->
    <li>
      <a class="social-btn hatebu-btn" target="_blank" href="https://b.hatena.ne.jp/entry/s/future-architect.github.io/articles/20180828/" rel="nofollow noopener">
        <i></i><span class="social-btn-label">87</span>
      </a>
    </li>
    <!-- pocket -->
    <li>
      <a class="social-btn pocket-btn" target="_blank" href="https://getpocket.com/save?url=https://future-architect.github.io/articles/20180828/" rel="nofollow noopener">
        <i></i><span class="social-btn-label">77</span>
      </a>
    </li>
    
  </ul>
<!-- シェアボタン END -->

          </section>
          <aside>
            <section class="related-post margin-bottom-40 nav">
              <h2 id="related"><a href="#related" class="headerlink" title="関連記事"></a>関連記事</h2>
              
  <div class="widget">
    <ul class="nav related-post-link"><li class="related-posts-item"><span>2022.04.28</span><span class="snscount">&#9825;9</span><a href=/articles/20220428a/ title="2021年の記事でもAWSの公式のDockerイメージを使って環境構築をする内容の記事があるのですが、Glue3.0の公式のDockerイメージがリリースされていたので、そちらを使って再度Glueのローカルでの開発環境構築の記事を書いてみようと思います。せっかくなので昨年の記事と少しコードを変えようと思い、AWSの公式ドキュメント[^2]に書かれたコードを基に解説します。">AWS Glueの開発環境の構築(2022)</a></li><li class="related-posts-item"><span>2021.11.12</span><span class="snscount">&#9825;2</span><a href=/articles/20211112a/ title="TIGの伊藤真彦です。先日AWS Certified Data Analytics - Specialtyに合格しました。これで持っているAWS認定資格は10個になりました。">AWS Certified Data Analytics - Specialty合格体験記</a></li><li class="related-posts-item"><span>2021.10.11</span><span class="snscount">&#9825;13</span><a href=/articles/20211011a/ title="PySparkを使用したGlueジョブ開発のお話をします。ETLツールとして使用されるAWS Glueですが、業務バッチで行うような複雑な処理も実行できます。また、処理はGlueジョブとして、Apache Spark分散・並列処理のジョブフローに簡単に乗せることができます！">AWS Glueで複雑な処理を開発するときのTips</a></li><li class="related-posts-item"><span>2021.10.06</span><span class="snscount">&#9825;7</span><a href=/articles/20211006a/ title="PySparkで予定しておりましたが、PySpark関連として、Glueを題材にさせていただきます。Glueといっても大きく下記の３種類、処理系をいれると4種類に分かれると思っていますが、それぞれ全く別のプロダクトという理解をしています。">AWS Glue Data CatalogでCSVを扱う</a></li><li class="related-posts-item"><span>2021.05.21</span><span class="snscount">&#9825;14</span><a href=/articles/20210521a/ title="Glueの環境構築は以前の記事（[AWS Glueの単体テスト環境の構築手順、AWS Glueの開発エンドポイントがそこそこお高いのでローカル開発環境を用意しました）にあるのですが、公式のDocker imageが案内されているので改めて、構築してみます。なお、Glueの公式イメージでもJupyter Notebookは利用できるのですが、使い勝手を考慮し、Jupyterlabに差し替えています。">AWS Glueの開発環境の構築(2021)</a></li><li class="related-posts-item"><span>2021.04.03</span><span class="snscount">&#9825;11</span><a href=/articles/20210403/ title="DynamoDBを頻繁に利用しており、連日DynamoDBコンソール画面と睨めっこをしています。DynamoDBのコンソール画面は特定のデータをピンポイントで探すには優秀ですが、データ集計には全く向いていません。">DynamoDBをS3へExportして、Glue+AthenaでSQLを実行する</a></li></ul>
  </div>
            </section>
            <section class="reference-post margin-bottom-40 nav">
              
  <div class="card">
    <div id="reference" class="reference-lede"><a href="#reference" class="headerlink" title="参照されている記事"></a>この記事を参照している記事</div>
    <ul class="reference-post-link"><li class="reference-posts-item"><a href=/articles/20191101/ title="AWS Glue利用していますか？ETL処理をする上で大変便利ですよね。しかしながら開発に必要不可欠な開発エンドポイントが少々お高く、もう少し安価に利用できればなーと思っていたところ、さすがAWSさん素敵なリリースをしてくれました。">AWS Glueの開発エンドポイントがそこそこお高いのでローカル開発環境を用意しました</a></li></ul>
  </div>
            </section>
          </aside>
        </footer>
      </div>
    </article>
  </main>
  <aside class="col-md-3 blog-sidebar">
    <!-- START SIDEBAR  -->


<section class="toc-section">
  <h2 class="margin-top-30">目次</h2>
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AWS-Glue%E3%81%A8%E3%81%AF"><span class="toc-text">AWS Glueとは</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8A%E5%9B%9E%E5%AE%9F%E7%8F%BE%E3%81%97%E3%81%9F%E3%81%84%E3%81%93%E3%81%A8"><span class="toc-text">今回実現したいこと</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#EMR-%E3%81%A8-Glue-%E6%AF%94%E8%BC%83"><span class="toc-text">EMR と Glue 比較</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Glue%E3%81%A7%E8%A1%8C%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8"><span class="toc-text">Glueで行えること</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#S3%E4%B8%8A%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%AE%E8%AA%AD%E3%81%BF%E6%9B%B8%E3%81%8D"><span class="toc-text">S3上のファイルの読み書き</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DaynamoDB%E3%81%8B%E3%82%89%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%80%81%E6%9B%B8%E3%81%8D%E8%BE%BC%E3%81%BF"><span class="toc-text">DaynamoDBからの読み込み、書き込み</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E5%B7%A5%E5%87%A6%E7%90%86"><span class="toc-text">加工処理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E3%82%B8%E3%83%A7%E3%83%96%E3%81%AE%E3%83%AF%E3%83%BC%E3%82%AF%E3%83%95%E3%83%AD%E3%83%BC"><span class="toc-text">ジョブのワークフロー</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Glue%E9%96%8B%E7%99%BATips"><span class="toc-text">Glue開発Tips</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Tips1-Glue%E3%83%87%E3%83%90%E3%83%83%E3%82%AF%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">Tips1. Glueデバックについて</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%80%BB%E9%96%8B%E7%99%BA%E3%82%A8%E3%83%B3%E3%83%89%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%82%92%E4%BD%BF%E3%82%8F%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88%E2%80%BB"><span class="toc-text">※開発エンドポイントを使わない場合※</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tips2-AWS-Athena%E3%81%A7%E7%B0%A1%E6%98%93%E7%9A%84%E3%81%AB%E3%83%87%E3%83%BC%E3%82%BF%E7%A2%BA%E8%AA%8D"><span class="toc-text">Tips2. AWS Athenaで簡易的にデータ確認</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tips3-Glue%E3%81%AE%E3%82%AB%E3%82%BF%E3%83%AD%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">Tips3. Glueのカタログデータについて</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tips4-DataFrame%E3%81%A8DynamicFrame%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">Tips4. DataFrameとDynamicFrameについて</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Glue%E3%81%AE%E6%B3%A8%E6%84%8F%E7%82%B9"><span class="toc-text">Glueの注意点</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F1-%E6%97%A2%E5%AD%98%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8BUpdate"><span class="toc-text">注意1. 既存データに対するUpdate</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F2-C%E8%A8%80%E8%AA%9E%E3%81%AB%E4%BE%9D%E5%AD%98%E3%81%99%E3%82%8B%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%EF%BC%88Pandas%E7%AD%89%EF%BC%89%E3%81%8C%E5%88%A9%E7%94%A8%E4%B8%8D%E5%8F%AF"><span class="toc-text">注意2. C言語に依存するパッケージ（Pandas等）が利用不可</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F3-%E3%82%B8%E3%83%A7%E3%83%96%E3%83%96%E3%83%83%E3%82%AF%E3%83%9E%E3%83%BC%E3%82%AF%E3%81%8C%E5%AF%BE%E5%BF%9C%E3%81%97%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84%E5%85%A5%E5%8A%9B"><span class="toc-text">注意3. ジョブブックマークが対応していない入力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F4-S3%E4%B8%8A%E3%81%AE%E3%82%BD%E3%83%BC%E3%82%B9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%AE%E5%AE%9F%E8%A1%8C"><span class="toc-text">注意4. S3上のソースファイルの実行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F5-%E4%B8%A6%E7%AB%8B%E5%88%86%E6%95%A3%E5%87%A6%E7%90%86"><span class="toc-text">注意5. 並立分散処理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F6-%E6%96%99%E9%87%91%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">注意6. 料金について</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F7-%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%AE%E7%A2%BA%E4%BF%9D%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">注意7. リソースの確保について</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%81%BE%E3%81%A8%E3%82%81"><span class="toc-text">まとめ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%AC%A1%E5%9B%9E%E3%81%AEGlue%E3%81%AE%E8%A8%98%E4%BA%8B%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><span class="toc-text">次回のGlueの記事について</span></a></li></ol>
</section>

<section class="category">
<h2 class="margin-top-30">カテゴリー</h2>
<div class="widget">
  <ul class="nav sidebar-categories margin-bottom-40">
  
  <li class=""><a href="/categories/Programming/">Programming (376)</a></li>
<li class=""><a href="/categories/Infrastructure/">Infrastructure (233)</a></li>
<li class=""><a href="/categories/Culture/">Culture (88)</a></li>
<li class=""><a href="/categories/DataScience/">DataScience (53)</a></li>
<li class=""><a href="/categories/IoT/">IoT (32)</a></li>
<li class=""><a href="/categories/DB/">DB (23)</a></li>
<li class=""><a href="/categories/Business/">Business (21)</a></li>
<li class=""><a href="/categories/%E8%AA%8D%E8%A8%BC%E8%AA%8D%E5%8F%AF/">認証認可 (20)</a></li>
<li class=""><a href="/categories/DevOps/">DevOps (19)</a></li>
<li class=""><a href="/categories/Management/">Management (15)</a></li>
<li class=""><a href="/categories/VR/">VR (12)</a></li>
<li class=""><a href="/categories/Security/">Security (12)</a></li>
<li class=""><a href="/categories/Design/">Design (11)</a></li>

  </ul>
</div>

</section>
<section class="podcast-link">
<h2 class="margin-top-30">Tech Cast</h2>

  <div class="class="widget-wrap">
  <div class="widget">
    <ul class="nav techcast">
      <li><a href="https://podcasters.spotify.com/pod/show/futuretechcast/episodes/38-AIAI-e22h1v0" title="フューチャーがお届けするポッドキャストです。#38 AIグループリーダー加藤さんに聞く「AIチームのミッションと展望」" target="_blank" rel="noopener"> #38 AIグループリーダー加藤さんに聞く「AIチームのミッションと展望」</a></li>
<li><a href="https://podcasters.spotify.com/pod/show/futuretechcast/episodes/37-e227p84" title="フューチャーがお届けするポッドキャストです。#37 自然言語処理を使った文書検索エンジンシステム開発と新規サービス検討（後編）" target="_blank" rel="noopener"> #37 自然言語処理を使った文書検索エンジンシステム開発と新規サービス検討（後編）</a></li>
<li><a href="https://podcasters.spotify.com/pod/show/futuretechcast/episodes/36-e1rdbcu" title="フューチャーがお届けするポッドキャストです。#36 自然言語処理を使った文書検索エンジンシステム開発と新規サービス検討（前編）" target="_blank" rel="noopener"> #36 自然言語処理を使った文書検索エンジンシステム開発と新規サービス検討（前編）</a></li>
    </ul>
  </div>
  </div>
  
</section>
<section class="advent-calendar">
<h2 class="margin-top-30">アドベントカレンダー</h2>
<div class="widget">
  <ul class="nav-flex">
    <li><a href="http://qiita.com/advent-calendar/2022/future" title="フューチャー Advent Calendar 2022 #Qiita" target="_blank" rel="noopener">2022年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2021/future" title="フューチャー Advent Calendar 2021 #Qiita" target="_blank" rel="noopener">2021年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2020/future" title="フューチャー Advent Calendar 2020 #Qiita" target="_blank" rel="noopener">2020年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2019/future" title="フューチャー Advent Calendar 2019 #Qiita" target="_blank" rel="noopener">2019年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2018/future" title="フューチャー Advent Calendar 2018 #Qiita" target="_blank" rel="noopener">2018年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2017/future" title="フューチャー Advent Calendar 2017 #Qiita" target="_blank" rel="noopener">2017年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2016/future" title="フューチャー Advent Calendar 2016 #Qiita" target="_blank" rel="noopener">2016年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2015/future" title="フューチャー Advent Calendar 2015 #Qiita" target="_blank" rel="noopener">2015年</a></li>
  </ul>
</div>

</section>
<!-- END SIDEBAR -->

  </aside>
</div>

  </section>
</div>

      <!-- BEGIN PRE-FOOTER -->
    <footer>
      <div class="pre-footer">
        <div class="container">
          <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-6 col-6 pre-footer-col">
              <h2>About Us</h2>
              <p>経営とITをデザインする、フューチャーの技術ブログです。業務で利用している幅広い技術について紹介します。<br /><br /><a target="_blank" rel="noopener" href="http://www.future.co.jp/">http://www.future.co.jp/</a></p>
              <div class="social-btn twitter-btn twitter-follow-btn">
                <a href="https://twitter.com/intent/follow?screen_name=future_techblog " target="_blank" rel="nofollow noopener">
                  <i></i><span class="tw-btn-label">フューチャー技術ブログをフォロー</span>
                </a>
              </div>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-4 col-4 pre-footer-col">
              <h2>Contact</h2>
              <address class="margin-bottom-40">
                <a href="https://www.future.co.jp/recruit/recruit/rec-fresh/" title="新卒採用" target="_blank" rel="noopener">新卒採用</a><br>
                <a href="https://www.future.co.jp/recruit/recruit/rec-career/" title="キャリア採用" target="_blank" rel="noopener">キャリア採用</a><br>
                <a href="https://www.future.co.jp/contact_us/" title="お問い合わせページ" target="_blank" rel="noopener">お問い合わせ</a><br>
                <a href="https://www.future.co.jp/architect/socialmediapolicy/" title="ソーシャルメディアポリシー" target="_blank" rel="noopener">メディアポリシー</a><br><br>
                <a href="mailto:techblog@future.co.jp">techblog@future.co.jp</a>
              </address>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6 col-6 pre-footer-col">
              <h2>Contents</h2>
              <a href="https://future-architect.github.io/coding-standards/" title="Future Enterprise Coding Standards" target="_blank" rel="noopener">コーディング規約</a><br>
              <a href="https://future-architect.github.io/typescript-guide/" title="仕事ですぐに使えるTypeScript" target="_blank" rel="noopener">仕事ですぐに使えるTypeScript</a><br>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-3 col-3 pre-footer-col">
              <h2>Event</h2>
              <a href="https://future.connpass.com/" title="経営とITをデザインするフューチャーの勉強会です" target="_blank" rel="noopener">connpass</a><br>
              <a href="https://www.future.co.jp/futureinsightseminar/" title="フューチャーインサイトセミナー" target="_blank" rel="noopener">Webセミナー</a><br>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-3 col-3 pre-footer-col">
              <h2>SNS</h2>
              <a href="https://github.com/future-architect" title="Future's official open source repositories" target="_blank" rel="noopener">GitHub</a><br>
              <a href="https://qiita.com/organizations/future" title="フューチャーのQiita Organizationです" target="_blank" rel="noopener">Qiita</a><br>
              <a href="https://note.future.co.jp/" title="フューチャーの公式note" target="_blank" rel="noopener">未来報</a><br>
              <a href="https://www.youtube.com/channel/UCJUSwYYd0CkGgmEKAW7QVpw" title="フューチャーYoutubeチャネル" target="_blank" rel="noopener">Youtube</a>
            </div>
          </div>
        </div>
      </div>
      <div class="footer">
        <div class="container">
          <div class="row">
            <div class="col-md-6 col-sm-6 padding-top-10">
              &copy; 2023 フューチャー技術ブログ<br>
            </div>
          </div>
        </div>
      </div>
    </footer>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X1C28R8H0M"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-X1C28R8H0M');
  gtag('config', 'UA-74047147-1'); // 過渡期対応
</script>

  </div>
</body>
</html>
