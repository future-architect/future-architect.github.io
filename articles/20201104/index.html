<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <!--
    ███████╗██╗░░░██╗████████╗██╗░░░██╗██████╗░███████╗
    ██╔════╝██║░░░██║╚══██╔══╝██║░░░██║██╔══██╗██╔════╝
    █████╗░░██║░░░██║░░░██║░░░██║░░░██║██████╔╝█████╗░░
    ██╔══╝░░██║░░░██║░░░██║░░░██║░░░██║██╔══██╗██╔══╝░░
    ██║░░░░░╚██████╔╝░░░██║░░░╚██████╔╝██║░░██║███████╗
    ╚═╝░░░░░░╚═════╝░░░░╚═╝░░░░╚═════╝░╚═╝░░╚═╝╚══════╝
    ████████╗███████╗░█████╗░██╗░░██╗
    ╚══██╔══╝██╔════╝██╔══██╗██║░░██║
    ░░░██║░░░█████╗░░██║░░╚═╝███████║
    ░░░██║░░░██╔══╝░░██║░░██╗██╔══██║
    ░░░██║░░░███████╗╚█████╔╝██║░░██║
    ░░░╚═╝░░░╚══════╝░╚════╝░╚═╝░░╚═╝
    ██████╗░██╗░░░░░░█████╗░░██████╗░
    ██╔══██╗██║░░░░░██╔══██╗██╔════╝░
    ██████╦╝██║░░░░░██║░░██║██║░░██╗░
    ██╔══██╗██║░░░░░██║░░██║██║░░╚██╗
    ██████╦╝███████╗╚█████╔╝╚██████╔╝
    ╚═════╝░╚══════╝░╚════╝░░╚═════╝░
    Welcome engineer.
    https://www.future.co.jp/recruit/
  -->
  
  <title>人工知能と神経科学 | フューチャー技術ブログ</title>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  
  <meta name="description" content="2020年4月新卒入社、フューチャーアーキテクトの戸田です。 この記事は秋のブログ週間連載の第5弾です。他の秋のブログ週間連載と毛色が多少異なりますが、楽しんで貰えると幸いです。 秋の夜長に合う読み物、ということだったので、最近では身近になった「人工知能」とその隣人である「神経科学」について書こうと思います。私事ですが、筆者の学生時代の専門が「神経科学」であり、情報系ではなく生物系出身や色々な">
<meta property="og:type" content="article">
<meta property="og:title" content="人工知能と神経科学 | フューチャー技術ブログ">
<meta property="og:url" content="https://future-architect.github.io/articles/20201104/index.html">
<meta property="og:site_name" content="フューチャー技術ブログ">
<meta property="og:description" content="2020年4月新卒入社、フューチャーアーキテクトの戸田です。 この記事は秋のブログ週間連載の第5弾です。他の秋のブログ週間連載と毛色が多少異なりますが、楽しんで貰えると幸いです。 秋の夜長に合う読み物、ということだったので、最近では身近になった「人工知能」とその隣人である「神経科学」について書こうと思います。私事ですが、筆者の学生時代の専門が「神経科学」であり、情報系ではなく生物系出身や色々な">
<meta property="og:locale" content="ja_JP">
<meta property="og:image" content="https://future-architect.github.io/images/20201104/brain-2029391_1280.png">
<meta property="article:published_time" content="2020-11-03T15:00:00.000Z">
<meta property="article:modified_time" content="2022-07-04T14:47:53.151Z">
<meta property="article:tag" content="DeepLearning">
<meta property="article:tag" content="強化学習">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://future-architect.github.io/images/20201104/brain-2029391_1280.png">
  
  <link rel="alternate" href="/atom.xml" title="フューチャー技術ブログ" type="application/atom+xml">
  
  <link rel="icon" href="/favicon.ico">
  <link rel="apple-touch-icon" sizes='180x180' href="/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes='57x57' href="/apple-touch-icon-57x57.png">
  <link rel="canonical" href="https://future-architect.github.io/articles/20201104/">
  <meta content="DeepLearning,強化学習" name="keywords">
  <meta content="戸田聖人" name="author">
  <link rel="preload" as="image" href="/banner.jpg" />
  <link rel='manifest' href='/manifest.webmanifest'/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/css/bootstrap.min.css" integrity="sha384-F3w7mX95PdgyTmZZMECAngseQB83DfGTowi0iMjiWaeVhAn4FJkqJByhZMI3AhiU" crossorigin="anonymous">
  <link rel="stylesheet" href="/metronic/assets/style.css">
  <link rel="stylesheet" href="/css/theme-styles.css">
<meta name="generator" content="Hexo 5.4.2"></head>

<body class="corporate">
  <div class="wrap" itemscope itemtype="https://schema.org/TechArticle">
  <!-- BEGIN HEADER -->
<header class="header">
	<div class="header-overlay">
		<div class="header-menu"></div>
		<div class="header-title"><a href="/">Future Tech Blog</a></div>
		<div class="header-title-sub">フューチャー技術ブログ</div>
	</div>
</header>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li><a href="/articles/">Blog</a></li>
    <li class="active">Post</li>
  </ul>
  <section id="main" class="margin-top-30">
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScienceカテゴリ</a>
  </div>


    <h2 itemprop="name" class="article-title">人工知能と神経科学
  
  <a target="_blank" rel="noopener" href="https://github.com/future-architect/tech-blog/edit/master/source/_posts/20201104_人工知能と神経科学.md" title="Suggest Edits" class="github-edit"><i class="github-edit-icon"></i></a>
  
</h2>

    <div class="row">
  <main class="col-md-9 blog-posts">
    <article id="post-20201104_人工知能と神経科学" class="article article-type-post blog-item" itemscope itemprop="blogPost">
      <div class="article-inner">
        
        <header class="article-header">
          <ul class="blog-info">
            <li class="blog-info-item"><a href="/articles/2020/" class="publish-date"><time datetime="2020-11-03T15:00:00.000Z" itemprop="datePublished">2020.11.04</time></a>
</li>
            <li class="blog-info-item"><li><a href="/authors/%E6%88%B8%E7%94%B0%E8%81%96%E4%BA%BA" title="戸田聖人さんの記事一覧へ" class="post-author">戸田聖人</a></li></li>
            <li class="blog-info-item">
  
    
    <a href="/tags/DeepLearning/" title="DeepLearningタグの記事へ" class="tag-list-link">DeepLearning</a>
  
    
    <a href="/tags/強化学習/" title="強化学習タグの記事へ" class="tag-list-link">強化学習</a>
  

</li>
          </ul>
          </header>
        
        <div class="article-entry" itemprop="articleBody">
          
            <img src="/images/20201104/brain-2029391_1280.png" class="img-middle-size" alt="" title="OpenClipart-VectorsによるPixabayからの画像">

<p>2020年4月新卒入社、フューチャーアーキテクトの戸田です。</p>
<p>この記事は<a href="/articles/20201026/">秋のブログ週間連載</a>の第5弾です。他の秋のブログ週間連載と毛色が多少異なりますが、楽しんで貰えると幸いです。</p>
<p>秋の夜長に合う読み物、ということだったので、最近では身近になった「人工知能」とその隣人である「神経科学」について書こうと思います。私事ですが、筆者の学生時代の専門が「神経科学」であり、情報系ではなく生物系出身や色々な人がフューチャーに在籍しているよ、と伝えたく筆を取りました。</p>
<h2 id="1-神経科学（Neuroscience）とは"><a href="#1-神経科学（Neuroscience）とは" class="headerlink" title="1. 神経科学（Neuroscience）とは"></a>1. 神経科学（Neuroscience）とは</h2><p>名前の通り、生き物の体に張り巡らされる「神経（Neuro）」について研究を行う自然「科学（Sciense）」の一分野です。非常に簡単に言うと、生き物が感じ・考え・動くことを調べる分野のことを指します。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">どのようにして私たちはものを見たり，聞いたりするのだろうか。</span><br><span class="line">快く感じることもあれば苦痛に感じることもあるのはなぜだろうか。</span><br><span class="line">どのようにして私たちは体を動かすのだろうか。</span><br><span class="line">また， どのようにして私たちは推論し，学習し記憶し，そして忘れるのだろうか。</span><br><span class="line">怒りや狂気の本質は何だろうか。 このようなことに興味を抱くのは人間として自然である。</span><br><span class="line">これらの謎を基礎的な神経科学の見地から解明する研究が始まっている。</span><br><span class="line">そして，これらの研究の成果が本書の主題である。</span><br></pre></td></tr></table></figure>
<p>（M.F.ベアー. ベアー・コノーズ・パラディーソ 神経科学：脳の探求 カラー版 より <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>）</p>
<p>しかし、そんな生き物に関わる研究が、どのようにして情報系の分野である「人工知能」に影響を及ぼしたのか、同時に影響を及ぼされたのかを簡単にですが説明していこうと思います。</p>
<h2 id="2-「人工知能」と「神経科学」の歴史"><a href="#2-「人工知能」と「神経科学」の歴史" class="headerlink" title="2.「人工知能」と「神経科学」の歴史"></a>2.「人工知能」と「神経科学」の歴史</h2><p>AIという言葉が使われ、その歴史が始まったのは1956年のダートマス会議 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>のことですが、そこからすべての「人工知能（Artificial intelligence; AI）」の歴史についてここに記す事はできないため、「神経科学」とそれに関わりの深い「深層学習」に絞って話をしていきます。</p>
<h3 id="2-0-「深層学習」が脚光を浴びてから"><a href="#2-0-「深層学習」が脚光を浴びてから" class="headerlink" title="2.0. 「深層学習」が脚光を浴びてから"></a>2.0. 「深層学習」が脚光を浴びてから</h3><p>ご存じの方も多いでしょうが、「深層学習」は2012年のNIPS会議においてヒントンら <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>が画像解析での圧倒的な性能を示して以来、画像認識を始めとして、言語処理、音声認識など様々な分野において活躍を残しています <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。</p>
<p>その「深層学習」において用いられる、「ニューラルネットワーク（Neural Network; NN）」は、日本語に無理やり直せば「神経回路網」となります。名前の通り、現在活躍する人工知能に関する手法の起源は神経科学にあります <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。</p>
<p>それでは、「深層学習」と「神経科学」の歴史を辿っていきましょう。</p>
<h3 id="2-1-「形式ニューロン」と「全か無かの法則」"><a href="#2-1-「形式ニューロン」と「全か無かの法則」" class="headerlink" title="2.1. 「形式ニューロン」と「全か無かの法則」"></a>2.1. 「形式ニューロン」と「全か無かの法則」</h3><p>一番初めのNNモデルは1943年に、ピッツとマッカロック <sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>が発表した「形式ニューロン」と呼ばれるものです。これは、神経科学において発見された「全か無かの法則」を数理的に表現したものでした。</p>
<p>「全か無かの法則」は、神経細胞（Neuron）の活動に関する法則で、神経細胞に一定上の入力がある場合には活動し、一定以下の入力には活動しないという法則です。つまり、「形式ニューロン」も入力値が一定を超えた場合に”1”を、超えなかった場合に”0”を出します(出力する値は定義次第ですが、今回はTrueとFalseを意識して1,0としました)。この「形式ニューロン」でどんな事ができるかというと、例えば、論理演算のANDを表現することが可能です。</p>
<h3 id="2-2-教師なし学習としての「ヘッブ則」"><a href="#2-2-教師なし学習としての「ヘッブ則」" class="headerlink" title="2.2.教師なし学習としての「ヘッブ則」"></a>2.2.教師なし学習としての「ヘッブ則」</h3><p>1949年にはヘッブが神経細胞間の関係について仮設を唱えました <sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>。俗に「ヘッブ則」と呼ばれる法則です。「ヘッブ則」は、神経科学にも大きな影響を与えましたが、人工知能の分野にも大きな影響を与えました。</p>
<p>ヘッブは、その法則を以下のように表現しています。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">「細胞Aの軸索が細胞Bを発火させるのに十分近くにあり、</span><br><span class="line">繰り返しあるいは絶え間なくその発火に参加するとき、</span><br><span class="line">いくつかの成長過程あるいは代謝変化が一方あるいは両方の細胞に起こり、</span><br><span class="line">細胞Bを発火させる細胞の1つとして細胞Aの効率が増加する。」</span><br></pre></td></tr></table></figure>
<p>（高橋 直矢, 池谷裕二, 松木則夫. ヘブ則. 脳科学辞典 より <sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>)</p>
<p>ここで、<code>発火</code>は神経細胞、すなわちニューロンの活動のことを指し、<code>細胞Aの軸索が細胞Bを発火させるのに十分近くにあり</code>というのは細胞Aと細胞Bとの活動に関連があること、すなわち、ニューロン間に入力の関係があることを指します。</p>
<p>要約すれば、<code>ニューロンAの活動がニューロンBの活動を引き起こすと、ニューロンAの活動がニューロンBを活動させやすくなる</code>となります。これはつまり、教師となる外部の信号なしに、ニューロン同士の関係を変化させる、教師なし学習に関する最初のアイデア <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>でした。</p>
<h3 id="2-3-「形式ニューロン」をつなげた「パーセプトロン」"><a href="#2-3-「形式ニューロン」をつなげた「パーセプトロン」" class="headerlink" title="2.3. 「形式ニューロン」をつなげた「パーセプトロン」"></a>2.3. 「形式ニューロン」をつなげた「パーセプトロン」</h3><p>1958年にはローゼンブラッドがNNモデルである「パーセプトロン」を発表しました <sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup>。節名の通り、「パーセプトロン」は「形式ニューロン」を複数つなげたものであり、一つの「形式ニューロン」で論理演算が可能であるのならば、複数個「形式ニューロン」をつなげればより複雑な入出力の関係を表現できるだろう、というアイデアでした。このときローゼンブラッドがパーセプトロンの学習則として使った方法が、前に説明したヘッブ則でした。</p>
<p>本筋とは関係ありませんが、この「パーセプトロン」では線形分離が出来ない問題が解けないということで下火になっていきました <sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>。</p>
<p>実はさらに「形式ニューロン」をつなげる、つまり、層を増やせば線形分離が出来ない問題も解くことができることはわかっていましたが、ヘッブ則では層を増やした「パーセプトロン」を学習させることが出来ないことが問題でした。</p>
<h3 id="2-4-バックプロパゲーションの開発とその後の深層学習"><a href="#2-4-バックプロパゲーションの開発とその後の深層学習" class="headerlink" title="2.4.バックプロパゲーションの開発とその後の深層学習"></a>2.4.バックプロパゲーションの開発とその後の深層学習</h3><p>1986年に、前節で話した多層のパーセプトロンを学習させられない、という問題を解決できる「バックプロパゲーション」をランメルハルトらが発表しました <sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup>。彼らは、並列分散処理モデルの研究していた神経科学と認知科学者のグループでした <sup id="fnref:12"><a href="#fn:12" rel="footnote">12</a></sup>。さらに、その後ランメルハルトとともに「バックプロパゲーション」を発表した、ヒントンが研究を続け、2012年のNIPS会議へとつながっていきます。</p>
<p>並列分散処理モデルは、コネクショニズムとも呼ばれ、神経細胞群を抽象化された処理の単位（ユニット）とし、それのネットワークを用いて認知メカニズムを理解しようとするアプローチであり、現在のNNモデルと共通点も多くあります <sup id="fnref:13"><a href="#fn:13" rel="footnote">13</a></sup>。</p>
<p>並列分散処理モデルと神経科学は、人工知能の研究に色々なアイデアを提供しました <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。現在の機械翻訳における、単語や文を分解して（ベクトルとして）表現できるという概念 <sup id="fnref:14"><a href="#fn:14" rel="footnote">14</a></sup>や、視覚情報を処理する脳領域に関する実験 <sup id="fnref:15"><a href="#fn:15" rel="footnote">15</a></sup>から発想を得た、畳み込みニューラルネットワークに見られる非線形変換・分割正規化・最大プーリング <sup id="fnref:16"><a href="#fn:16" rel="footnote">16</a></sup>などが例として挙げられます。</p>
<p>また、トレーニングデータに過剰に適合してしまう、過学習を防ぐために行われる正則化であるドロップアウトの開発も、ポワソン分布で活動する神経細胞の存在に動機づけられました <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>, <sup id="fnref:17"><a href="#fn:17" rel="footnote">17</a></sup>。さらに、強化学習も動物心理学における動物実験の研究に触発されています <sup id="fnref:18"><a href="#fn:18" rel="footnote">18</a></sup>。</p>
<p>一方で、強化学習の手法であるTD学習（Temporal difference learning）から得られた結果と生物の脳から計測された神経の活動はよく似ており、生物の脳がTD学習と類似した方法を用いていることが示唆されています <sup id="fnref:19"><a href="#fn:19" rel="footnote">19</a></sup>, <sup id="fnref:20"><a href="#fn:20" rel="footnote">20</a></sup>。</p>
<p>深層学習による、神経科学への影響はアルゴリズムに限りません。近年では、神経科学において処理するデータ量が飛躍的に増加しており解析手法として深層学習が用いられることも多いです。</p>
<h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><ul>
<li>「神経科学」とは、脳などの神経について研究を行う分野のことである。</li>
<li>「人工知能」と関係する「神経科学」という分野がある。</li>
<li>歴史的に「人工知能」と「神経科学」は影響を与えあってきた。</li>
</ul>
<p>過去から現在まで、簡単かつ駆け足ではありますが「人工知能」と「神経科学」の関係を書きました。</p>
<p>込み入った話を含めれば、さらに色々書くことはありますが、「神経科学」の知識がないと理解が難しいため比較的理解しやすいものを書いてみました。また機会があれば、現在の話やこれからの話についても書けたらいいなと考えています。</p>
<p>本記事は、ハサビスらの論文 <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>とシュミットフーバーの論文 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>を中軸として書いたので気になる方は、原著も読んでみてください。</p>
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="vertical-align: top; padding-right: 10px;">1.</span><span style="vertical-align: top;">加藤宏司, et al. &quot;ベアー コノーズ パラディーソ神経科学: 脳の探求: カラー版.&quot; (2007).</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="vertical-align: top; padding-right: 10px;">2.</span><span style="vertical-align: top;">McCarthy, John, et al. &quot;A proposal for the dartmouth summer research project on artificial intelligence, august 31, 1955.&quot; AI magazine 27.4 (2006): 12-12.</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="vertical-align: top; padding-right: 10px;">3.</span><span style="vertical-align: top;">Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. &quot;ImageNet classification with deep convolutional neural networks.&quot; NIPS'12: Proceedings of the 25th International Conference on Neural Information Processing Systems(2012): 1097–1105.</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="vertical-align: top; padding-right: 10px;">4.</span><span style="vertical-align: top;">Schmidhuber, Jürgen. &quot;Deep learning in neural networks: An overview.&quot; Neural networks 61 (2015): 85-117.</span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="vertical-align: top; padding-right: 10px;">5.</span><span style="vertical-align: top;">Hassabis, Demis, et al. &quot;Neuroscience-inspired artificial intelligence.&quot; Neuron 95.2 (2017): 245-258.</span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="vertical-align: top; padding-right: 10px;">6.</span><span style="vertical-align: top;">McCulloch, Warren S., and Walter Pitts. &quot;A logical calculus of the ideas immanent in nervous activity.&quot; The bulletin of mathematical biophysics 5.4 (1943): 115-133.</span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="vertical-align: top; padding-right: 10px;">7.</span><span style="vertical-align: top;">Hebb, Donald Olding. &quot;The organization of behavior: a neuropsychological theory.&quot; J. Wiley; Chapman &amp; Hall, 1949.</span><a href="#fnref:7" rev="footnote"> ↩</a></li><li id="fn:8"><span style="vertical-align: top; padding-right: 10px;">8.</span><span style="vertical-align: top;">高橋 直矢, 池谷裕二, 松木則夫. &quot;ヘブ則&quot;. 脳科学辞典(2012), アクセス日 2020/11/04, <a target="_blank" rel="noopener" href="https://bsd.neuroinf.jp/wiki/%E3%83%98%E3%83%96%E5%89%87">https://bsd.neuroinf.jp/wiki/ヘブ則</a></span><a href="#fnref:8" rev="footnote"> ↩</a></li><li id="fn:9"><span style="vertical-align: top; padding-right: 10px;">9.</span><span style="vertical-align: top;">Rosenblatt, Frank. &quot;The perceptron: a probabilistic model for information storage and organization in the brain.&quot; Psychological review 65.6 (1958): 386.</span><a href="#fnref:9" rev="footnote"> ↩</a></li><li id="fn:10"><span style="vertical-align: top; padding-right: 10px;">10.</span><span style="vertical-align: top;">Minsky, Marvin L., and Seymour A. Papert. &quot;Perceptrons: expanded edition.&quot; (1988).</span><a href="#fnref:10" rev="footnote"> ↩</a></li><li id="fn:11"><span style="vertical-align: top; padding-right: 10px;">11.</span><span style="vertical-align: top;">Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. &quot;Learning representations by back-propagating errors.&quot; nature 323.6088 (1986): 533-536.</span><a href="#fnref:11" rev="footnote"> ↩</a></li><li id="fn:12"><span style="vertical-align: top; padding-right: 10px;">12.</span><span style="vertical-align: top;">Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. Learning internal representations by error propagation. No. ICS-8506. California Univ San Diego La Jolla Inst for Cognitive Science, 1985.</span><a href="#fnref:12" rev="footnote"> ↩</a></li><li id="fn:13"><span style="vertical-align: top; padding-right: 10px;">13.</span><span style="vertical-align: top;">都築誉史. &quot;コネクショニズム.&quot; 認知科学 8.3 (2001): 225-237.</span><a href="#fnref:13" rev="footnote"> ↩</a></li><li id="fn:14"><span style="vertical-align: top; padding-right: 10px;">14.</span><span style="vertical-align: top;">John, Mark F. St, and James L. McClelland. &quot;Learning and applying contextual constraints in sentence comprehension.&quot; Artificial intelligence 46.1-2 (1990): 217-257.</span><a href="#fnref:14" rev="footnote"> ↩</a></li><li id="fn:15"><span style="vertical-align: top; padding-right: 10px;">15.</span><span style="vertical-align: top;">Hubel, David H., and Torsten N. Wiesel. &quot;Receptive fields of single neurones in the cat's striate cortex.&quot; The Journal of physiology 148.3 (1959): 574.</span><a href="#fnref:15" rev="footnote"> ↩</a></li><li id="fn:16"><span style="vertical-align: top; padding-right: 10px;">16.</span><span style="vertical-align: top;">Yamins, Daniel LK, and James J. DiCarlo. &quot;Using goal-driven deep learning models to understand sensory cortex.&quot; Nature neuroscience 19.3 (2016): 356-365.</span><a href="#fnref:16" rev="footnote"> ↩</a></li><li id="fn:17"><span style="vertical-align: top; padding-right: 10px;">17.</span><span style="vertical-align: top;">Hinton, Geoffrey E., et al. &quot;Improving neural networks by preventing co-adaptation of feature detectors.&quot; arXiv preprint arXiv:1207.0580 (2012).</span><a href="#fnref:17" rev="footnote"> ↩</a></li><li id="fn:18"><span style="vertical-align: top; padding-right: 10px;">18.</span><span style="vertical-align: top;">Sutton, Richard S., and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.</span><a href="#fnref:18" rev="footnote"> ↩</a></li><li id="fn:19"><span style="vertical-align: top; padding-right: 10px;">19.</span><span style="vertical-align: top;">O'Doherty, John P., et al. &quot;Temporal difference models and reward-related learning in the human brain.&quot; Neuron 38.2 (2003): 329-337.</span><a href="#fnref:19" rev="footnote"> ↩</a></li><li id="fn:20"><span style="vertical-align: top; padding-right: 10px;">20.</span><span style="vertical-align: top;">Schultz, Wolfram, Peter Dayan, and P. Read Montague. &quot;A neural substrate of prediction and reward.&quot; Science 275.5306 (1997): 1593-1599.</span><a href="#fnref:20" rev="footnote"> ↩</a></li></ol></div></div>
          
        </div>
        <footer>
          <section class="social-area">
          <!-- シェアボタン START -->
  <ul class="social-button">
    
    <!-- Twitter -->
    <li>
      <a class="social-btn twitter-btn" target="_blank" href="https://twitter.com/share?url=https://future-architect.github.io/articles/20201104/&related=twitterapi%2Ctwitter&text=%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%E3%81%A8%E7%A5%9E%E7%B5%8C%E7%A7%91%E5%AD%A6%20%7C%20%E3%83%95%E3%83%A5%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E6%8A%80%E8%A1%93%E3%83%96%E3%83%AD%E3%82%B0" rel="nofollow noopener">
        <i></i><span class="social-btn-label">ツイート</span>
      </a>
    </li>
    <!-- Facebook -->
    <li>
      <a class="social-btn fb-btn" target="_blank" href="http://www.facebook.com/share.php?u=https://future-architect.github.io/articles/20201104/&t=%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%E3%81%A8%E7%A5%9E%E7%B5%8C%E7%A7%91%E5%AD%A6" rel="nofollow noopener">
        <i></i><span class="social-btn-label">シェア</span>
      </a>
    </li>
    <!-- hatebu -->
    <li>
      <a class="social-btn hatebu-btn" target="_blank" href="https://b.hatena.ne.jp/entry/s/future-architect.github.io/articles/20201104/" rel="nofollow noopener">
        <i></i><span class="social-btn-label">はてな</span>
      </a>
    </li>
    <!-- pocket -->
    <li>
      <a class="social-btn pocket-btn" target="_blank" href="https://getpocket.com/save?url=https://future-architect.github.io/articles/20201104/" rel="nofollow noopener">
        <i></i><span class="social-btn-label">Pocket</span>
      </a>
    </li>
    
  </ul>
<!-- シェアボタン END -->

          </section>
          <aside>
            <section class="related-post margin-bottom-40 nav">
              <h2 id="related"><a href="#related" class="headerlink" title="関連記事"></a>関連記事</h2>
              
  <div class="widget">
    <ul class="nav related-post-link"><li class="related-posts-item"><span>2022.04.20</span><span class="snscount">&#9825;13</span><a href=/articles/20220420a/ title=" 「新人のときに知っておきたかったこと」として、自分が新人だったときに周りの強いお兄さんたちから学んだことを書いていこうと思います。">強いお兄さん達に囲まれて</a></li><li class="related-posts-item"><span>2017.05.26</span><span class="snscount">&#9825;154</span><a href=/articles/20170526/ title="AI(機械学習・Deep Learning等)を用いて、 **大量にある顔画像の中から同一人物をクラスタリングし、頻出する顔画像の抽出** を行い、常連さんの判定を行いたいと思います。">AIを使って顔画像から「常連さん」を判定しよう！</a></li></ul>
  </div>
            </section>
            <section class="reference-post margin-bottom-40 nav">
              
  <div class="card">
    <div id="reference" class="reference-lede"><a href="#reference" class="headerlink" title="参照されている記事"></a>この記事を参照している記事</div>
    <ul class="reference-post-link"><li class="reference-posts-item"><a href=/articles/20201026/ title="今回は秋のブログ週間連載と銘打って連載を開始します。期間は後述しますが、全9回の連載になります。秋の読書週間は公益社団法人 読書推進運動協議会が制定しており、期間は10/27〜11/9の2週間を読書を推進する行事として毎年開催されています。目的としては、読書することへの推進や活字を読む機会の増進などとなります。皆さんも小学生の時にこの読書週間があったことを覚えている方もいるのではないでしょうか？この読書週間に合わせて今回この連載を開催しております。">秋のブログ週間連載をはじめます</a></li></ul>
  </div>
            </section>
          </aside>
        </footer>
      </div>
    </article>
  </main>
  <aside class="col-md-3 blog-sidebar">
    <!-- START SIDEBAR  -->


<section class="toc-section">
  <h2 class="margin-top-30">目次</h2>
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%A5%9E%E7%B5%8C%E7%A7%91%E5%AD%A6%EF%BC%88Neuroscience%EF%BC%89%E3%81%A8%E3%81%AF"><span class="toc-text">1. 神経科学（Neuroscience）とは</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E3%80%8C%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%E3%80%8D%E3%81%A8%E3%80%8C%E7%A5%9E%E7%B5%8C%E7%A7%91%E5%AD%A6%E3%80%8D%E3%81%AE%E6%AD%B4%E5%8F%B2"><span class="toc-text">2.「人工知能」と「神経科学」の歴史</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-0-%E3%80%8C%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%8D%E3%81%8C%E8%84%9A%E5%85%89%E3%82%92%E6%B5%B4%E3%81%B3%E3%81%A6%E3%81%8B%E3%82%89"><span class="toc-text">2.0. 「深層学習」が脚光を浴びてから</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E3%80%8C%E5%BD%A2%E5%BC%8F%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%AD%E3%83%B3%E3%80%8D%E3%81%A8%E3%80%8C%E5%85%A8%E3%81%8B%E7%84%A1%E3%81%8B%E3%81%AE%E6%B3%95%E5%89%87%E3%80%8D"><span class="toc-text">2.1. 「形式ニューロン」と「全か無かの法則」</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%95%99%E5%B8%AB%E3%81%AA%E3%81%97%E5%AD%A6%E7%BF%92%E3%81%A8%E3%81%97%E3%81%A6%E3%81%AE%E3%80%8C%E3%83%98%E3%83%83%E3%83%96%E5%89%87%E3%80%8D"><span class="toc-text">2.2.教師なし学習としての「ヘッブ則」</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E3%80%8C%E5%BD%A2%E5%BC%8F%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%AD%E3%83%B3%E3%80%8D%E3%82%92%E3%81%A4%E3%81%AA%E3%81%92%E3%81%9F%E3%80%8C%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3%E3%80%8D"><span class="toc-text">2.3. 「形式ニューロン」をつなげた「パーセプトロン」</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E9%96%8B%E7%99%BA%E3%81%A8%E3%81%9D%E3%81%AE%E5%BE%8C%E3%81%AE%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92"><span class="toc-text">2.4.バックプロパゲーションの開発とその後の深層学習</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E3%81%BE%E3%81%A8%E3%82%81"><span class="toc-text">まとめ</span></a></li></ol>
</section>

<section class="category">
<h2 class="margin-top-30">カテゴリー</h2>
<div class="widget">
  <ul class="nav sidebar-categories margin-bottom-40">
  
  <li class=""><a href="/categories/Programming/">Programming (342)</a></li>
<li class=""><a href="/categories/Infrastructure/">Infrastructure (198)</a></li>
<li class=""><a href="/categories/Culture/">Culture (84)</a></li>
<li class=""><a href="/categories/DataScience/">DataScience (44)</a></li>
<li class=""><a href="/categories/IoT/">IoT (31)</a></li>
<li class=""><a href="/categories/DB/">DB (20)</a></li>
<li class=""><a href="/categories/Business/">Business (19)</a></li>
<li class=""><a href="/categories/%E8%AA%8D%E8%A8%BC%E8%AA%8D%E5%8F%AF/">認証認可 (18)</a></li>
<li class=""><a href="/categories/Management/">Management (13)</a></li>
<li class=""><a href="/categories/VR/">VR (12)</a></li>
<li class=""><a href="/categories/DevOps/">DevOps (12)</a></li>
<li class=""><a href="/categories/Design/">Design (11)</a></li>
<li class=""><a href="/categories/Security/">Security (6)</a></li>

  </ul>
</div>

</section>
<section class="podcast-link">
<h2 class="margin-top-30">Tech Cast</h2>

  <div class="class="widget-wrap">
  <div class="widget">
    <ul class="nav techcast">
      <li><a href="https://anchor.fm/futuretechcast/episodes/35-MLOps-e1qe4st" title="フューチャーがお届けするポッドキャストです。#35 MLOpsエンジニアって何やるの？（後編）" target="_blank" rel="noopener"><span class="newitem">NEW</span> #35 MLOpsエンジニアって何やるの？（後編）</a></li>
<li><a href="https://anchor.fm/futuretechcast/episodes/34-MLOps-e1polbj" title="フューチャーがお届けするポッドキャストです。#34 MLOpsエンジニアって何やるの？（前編）" target="_blank" rel="noopener"> #34 MLOpsエンジニアって何やるの？（前編）</a></li>
<li><a href="https://anchor.fm/futuretechcast/episodes/33-IT-e1pcaon" title="フューチャーがお届けするポッドキャストです。#33 ヘルスケアグループリーダーの中元さんと語る「医療業界におけるITコンサルとビジネスイノベーション」（後編）" target="_blank" rel="noopener"> #33 ヘルスケアグループリーダーの中元さんと語る「医療業界におけるITコンサルとビジネスイノベーション」（後編）</a></li>
    </ul>
  </div>
  </div>
  
</section>
<section class="advent-calendar">
<h2 class="margin-top-30">アドベントカレンダー</h2>
<div class="widget">
  <ul class="nav-flex">
    <li><a href="http://qiita.com/advent-calendar/2022/future" title="フューチャー Advent Calendar 2022 #Qiita" target="_blank" rel="noopener">2022年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2021/future" title="フューチャー Advent Calendar 2021 #Qiita" target="_blank" rel="noopener">2021年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2020/future" title="フューチャー Advent Calendar 2020 #Qiita" target="_blank" rel="noopener">2020年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2019/future" title="フューチャー Advent Calendar 2019 #Qiita" target="_blank" rel="noopener">2019年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2018/future" title="フューチャー Advent Calendar 2018 #Qiita" target="_blank" rel="noopener">2018年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2017/future" title="フューチャー Advent Calendar 2017 #Qiita" target="_blank" rel="noopener">2017年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2016/future" title="フューチャー Advent Calendar 2016 #Qiita" target="_blank" rel="noopener">2016年</a></li>
    <li><a href="http://qiita.com/advent-calendar/2015/future" title="フューチャー Advent Calendar 2015 #Qiita" target="_blank" rel="noopener">2015年</a></li>
  </ul>
</div>

</section>
<!-- END SIDEBAR -->

  </aside>
</div>

  </section>
</div>

      <!-- BEGIN PRE-FOOTER -->
    <footer>
      <div class="pre-footer">
        <div class="container">
          <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-6 col-6 pre-footer-col">
              <h2>About Us</h2>
              <p>経営とITをデザインする、フューチャーの技術ブログです。業務で利用している幅広い技術について紹介します。<br /><br /><a target="_blank" rel="noopener" href="http://www.future.co.jp/">http://www.future.co.jp/</a></p>
              <div class="social-btn twitter-btn twitter-follow-btn">
                <a href="https://twitter.com/intent/follow?screen_name=future_techblog " target="_blank" rel="nofollow noopener">
                  <i></i><span class="tw-btn-label">フューチャー技術ブログをフォロー</span>
                </a>
              </div>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-4 col-4 pre-footer-col">
              <h2>Contact</h2>
              <address class="margin-bottom-40">
                <a href="https://www.future.co.jp/recruit/recruit/rec-fresh/" title="新卒採用" target="_blank" rel="noopener">新卒採用</a><br>
                <a href="https://www.future.co.jp/recruit/recruit/rec-career/" title="キャリア採用" target="_blank" rel="noopener">キャリア採用</a><br>
                <a href="https://www.future.co.jp/contact_us/" title="お問い合わせページ" target="_blank" rel="noopener">お問い合わせ</a><br>
                <a href="https://www.future.co.jp/architect/socialmediapolicy/" title="ソーシャルメディアポリシー" target="_blank" rel="noopener">メディアポリシー</a><br><br>
                <a href="mailto:techblog@future.co.jp">techblog@future.co.jp</a>
              </address>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-6 col-6 pre-footer-col">
              <h2>Contents</h2>
              <a href="https://future-architect.github.io/coding-standards/" title="Future Enterprise Coding Standards" target="_blank" rel="noopener">コーディング規約</a><br>
              <a href="https://future-architect.github.io/typescript-guide/" title="仕事ですぐに使えるTypeScript" target="_blank" rel="noopener">仕事ですぐに使えるTypeScript</a><br>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-3 col-3 pre-footer-col">
              <h2>Event</h2>
              <a href="https://future.connpass.com/" title="経営とITをデザインするフューチャーの勉強会です" target="_blank" rel="noopener">connpass</a><br>
              <a href="https://www.future.co.jp/futureinsightseminar/" title="フューチャーインサイトセミナー" target="_blank" rel="noopener">Webセミナー</a><br>
            </div>
            <div class="col-lg-2 col-md-4 col-sm-3 col-3 pre-footer-col">
              <h2>SNS</h2>
              <a href="https://github.com/future-architect" title="Future's official open source repositories" target="_blank" rel="noopener">GitHub</a><br>
              <a href="https://qiita.com/organizations/future" title="フューチャーのQiita Organizationです" target="_blank" rel="noopener">Qiita</a><br>
              <a href="https://note.future.co.jp/" title="フューチャーの公式note" target="_blank" rel="noopener">未来報</a><br>
              <a href="https://www.youtube.com/channel/UCJUSwYYd0CkGgmEKAW7QVpw" title="フューチャーYoutubeチャネル" target="_blank" rel="noopener">Youtube</a>
            </div>
          </div>
        </div>
      </div>
      <div class="footer">
        <div class="container">
          <div class="row">
            <div class="col-md-6 col-sm-6 padding-top-10">
              &copy; 2022 フューチャー技術ブログ<br>
            </div>
          </div>
        </div>
      </div>
    </footer>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X1C28R8H0M"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-X1C28R8H0M');
  gtag('config', 'UA-74047147-1'); // 過渡期対応
</script>

  </div>
</body>
</html>
