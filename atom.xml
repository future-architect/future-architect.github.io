<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Future Tech Blog - フューチャーアーキテクト</title>
  
  <subtitle>フューチャーアーキテクト開発者ブログ</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://future-architect.github.io/"/>
  <updated>2019-08-25T23:44:00.179Z</updated>
  <id>https://future-architect.github.io/</id>
  
  <author>
    <name>Future Architect Consultants</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ソフトとハードの垣根を越えろ - IoTハードウェアの開発をソフト屋視点で解説します</title>
    <link href="https://future-architect.github.io/articles/20190826/"/>
    <id>https://future-architect.github.io/articles/20190826/</id>
    <published>2019-08-25T23:30:52.000Z</published>
    <updated>2019-08-25T23:44:00.179Z</updated>
    
    <content type="html"><![CDATA[<p>はじめまして。筒井と申します。</p><p>簡単に自己紹介をさせていただくと、新卒でフューチャーに入社後に<a href="https://www.future.co.jp/company_profile/future_group/" target="_blank" rel="noopener">フューチャーグループ</a>のTrexEdgeへ出向しました。現在は右手に半田ごて、左手にHHKBでハード・ソフトにこだわらず仕事をしています。</p><p>TrexEdgeでは、「スマートビレッジ」という言葉をキーとして、テクノロジーを用いて地方の価値を最大化することを目指しています。</p><p>具体的には、地方における主産業である「農業」に目を向け、農業経営を支援するアプリ「Agrion」の運営をメインの事業としています。</p><p><a href="https://www.agri-on.com/" target="_blank" rel="noopener">https://www.agri-on.com/</a></p><p>今回は農業の話ではなく、また別の地方特有の課題を技術で解決しようとしている話をさせていただきます。</p><h2 id="獣害問題"><a href="#獣害問題" class="headerlink" title="獣害問題"></a>獣害問題</h2><p>獣害問題と言っても都会の方にはあまり馴染みのない話かもしれません。イノシシやシカを見かけるのはジビエ料理店くらいでしょうか。</p><p>しかし農村部では、多くの農家が獣害に頭を悩ませており、その被害額は年間160億円以上との報告も出ています。<br><a href="http://www.maff.go.jp/j/seisan/tyozyu/higai/h_zyokyo2/h29/181026.html" target="_blank" rel="noopener">http://www.maff.go.jp/j/seisan/tyozyu/higai/h_zyokyo2/h29/181026.html</a></p><p>そのため獣害被害は農家にとってはとても大きな問題なのですが、この対処を行う猟友会員（ハンター）もまた、高齢化というまた別の問題に直面しています。</p><p>今回紹介する京都府の与謝野町という街においても、猟友会の平均年齢は毎年1歳ずつ高くなっている状況です。</p><h2 id="害獣檻センサーについて"><a href="#害獣檻センサーについて" class="headerlink" title="害獣檻センサーについて"></a>害獣檻センサーについて</h2><p>害獣の管理捕獲の方法には銃猟、網猟、わな猟とあるのですが、TrexEdgeではわな猟に用いる箱罠に取り付けるセンサー端末を開発しました。</p><p>与謝野町は海と山に囲まれた風光明媚な土地なのですが、イノシシやシカを捕らえる箱罠は、彼らが人里へ降りてこないよう山中に設置されています。</p><p>これがまた、四駆の軽トラじゃないと入っていけないような、すごいところに設置されています。</p><img src="/images/20190826/photo_20190826_01.jpeg"><p>こんなすごいところに設置している訳ですから獣がかかっているかどうかの見回りもまた一苦労で、この負担を軽減するために、箱罠にセンサーを設置することになりました。<br>（ここはまだ舗装されているのでマシな方だったりします。）</p><h2 id="センサー端末の開発方法"><a href="#センサー端末の開発方法" class="headerlink" title="センサー端末の開発方法"></a>センサー端末の開発方法</h2><p>「ここはテックブログだぞ」という天の声が聞こえてきましたので、前置きはここまでにして、ここからは技術の話をします。</p><p>さて、「ハードウェアを作る」という目的を持ったとき、その実現方法は多種多様です。</p><p>ものすごくざっくりですが、IoTセンサー端末の構成要素は主に以下の四つになります。</p><ol><li>センサー<br>箱罠の作動を検知するセンサー類です。今回は開閉センサー（マグネット式）を使いました。</li><li>バッテリー<br>電源が確保出来る場所ならば不要ですが、今回は山林部への設置なのでバッテリーが必要です。</li><li>基板<br>無線のコントローラーや、制御用のマイコンを載せる基板です。</li><li>筐体<br>上記を収めるケースですね。</li></ol><p>これらの要素をそれぞれ揃えていく必要があるのですが、ここで「自分で作る」と「買ってくる」という選択肢が出てきます。<br>フルスクラッチで作るか、何らかのパッケージ等を導入するかといったところです。</p><p>非常に悩ましい二択ですが、仕様を満たせるかどうか、コストはどうかという観点で決めていきます。</p><h3 id="センサー、バッテリー"><a href="#センサー、バッテリー" class="headerlink" title="センサー、バッテリー"></a>センサー、バッテリー</h3><p>センサーを自分で作ることはなかなか難しい話です。バッテリーは言わずもがなでございます。</p><p>レモン数個に銅板と亜鉛板でリチウムイオン電池並の性能が出ればとってもエコなのですが。</p><p>開閉センサーは、<a href="http://akizukidenshi.com/catalog/g/gP-04209/" target="_blank" rel="noopener">リードスイッチ</a>と永久磁石を買ってきて構成することも可能ではありますが、出来合いの開閉センサーが特別高いものでもなく、またこれらを組み立てる手間のほうが高コストとなるので、買ってきて済ませることにしました。</p><h3 id="筐体"><a href="#筐体" class="headerlink" title="筐体"></a>筐体</h3><p>筐体を「自分で作る」ことにした場合、金型を起こす、3Dプリンタでプリントする、切削加工で作る…などまた様々な選択肢が現れます。</p><p>一方「買ってくる」ことにした場合は、筐体メーカーさんのプリメイドなケースを購入し、目的に合わせて追加工を施すことになります。</p><p>3Dプリンタは、意匠性の高い筐体を1点から気楽に作れることがメリットです。<br>一方で、イニシャルコストが低い代わりに多量生産するとそのコストメリットが薄れます。<br>また安価なFDM方式では寸法精度や強度を出すことが難しいという問題もあります。</p><p>金型は、ほぼ3Dプリンタの逆です。<br>イニシャルコストは非常に高くなりますが、量産時のコストはとても安くなります。</p><p>最後に買ってきて追加工をするパターンですが、出来合いのものを買うためケースの大きさ・見た目に自由は効かなくなりますが、ひとつあたりのコストも安く、お手軽です。</p><p>今回の害獣檻センサーでは、防水性が求められるために3Dプリンタでは製作が難しいこと、また現時点で金型への投資を回収するだけの製造数を予定していないことから、<a href="https://www.takachi-el.co.jp/" target="_blank" rel="noopener">タカチ電機工業</a>さんのケースを購入しました。</p><h3 id="基板"><a href="#基板" class="headerlink" title="基板"></a>基板</h3><p>さて、今回の主題となる基板についてすが、これもまた、買ってくるのか、自分で作るのかが選べます。あ、よく間違えている方がいるので書いておきますが、「基盤」では無く「基板」です。基板がCircuit Boardで、基盤はInfrastructureです。</p><p>基板を買ってくる場合は、Arduinoを始めとするマイコンボードに、<a href="https://www.seeedstudio.com/category/Grove-c-1003.html" target="_blank" rel="noopener">Grove</a>のような各種モジュールを組み合わせて使うことが考えられます。このパターンでは、初期投資を小さく抑えて、素早くプロトタイピング、機能の検証が行えるのが魅力です。</p><p>一方で、Arduinoは万人に使いやすいように作られているために、特定の目的で性能・コストを突き詰めようとした場合には小回りが利かなくなってきます。その最たるところのひとつが消費電力です。Arduinoは常時点灯する電源LEDやUSBシリアル変換ICなどが搭載されているため、消費電力は大きくなってしまっています。</p><p>今回の害獣檻センサーは見回りの負担軽減が目的ですので、バッテリー交換の頻度も極力抑えることが求められます。そのため、低消費電力化はひとつの大きな課題であり、基板を作ることに決めました。基板を自分で作るとなった場合には、プリント基板を製作するか、<a href="https://www.murata.com/ja-jp/campaign/ads/japan/elekids/ele/craft/knack/universal" target="_blank" rel="noopener">ユニバーサル基板に手半田で回路を作成する</a>か、といった選択肢が現れます。</p><p>ユニバーサル基板のメリットは、基板をすぐに作り始められること、初期コストが小さく済むことです。プリント基板を製作するとなった場合には、（自前で製造設備を持っている方は別ですが）外部に基板を発注することになるため、製造のための時間がかかってしまいます。また回路にミスがあって修正をいれる場合にも、修正→再製造とさらに時間・お金がかかってしまいますが、その点ユニバーサル基板では配線の修正も容易です。ソフトウェアの開発に無理やり例えれば、「デバッグ・デプロイが容易なスクリプト言語」と言ったところでしょうか。</p><p>一方ユニバーサル基板のデメリットは、製造に技量が求められること、一点あたりの製造時間が長いこと、複数台の製造時に品質を安定させることが難しいことです。<a href="http://elm-chan.org/docs/wire/wiring.html" target="_blank" rel="noopener">この方</a>のようなユニバーサル基板の達人になれば、ワンオフで基板を作るにはとても良い選択肢なのですが、複数の基板を製造するには割に合わなくなってきます。</p><p>これに対してプリント基板は、「ビルドに時間はかかるが性能の良いコンパイル言語」という感じです。</p><p>基板のアートワーク（後述します）にこそ時間はかかりますが、一度デザインが出来てしまえばエンジニアの手を離れて製造が進んでいきます。最近は中国（主に深セン）のプリント基板製造メーカーさんが台頭しており、基板製造だけならば1,000円未満から始めることが出来るため、お金の面で言えばユニバーサル基板と対等になってきています。</p><p>長々と書いてきましたが、目的に応じた手段をまとめると以下のようになると思います。</p><h4 id="Q-目的はプロジェクトのコンセプト検証やデモで、何より早く検証を進めたい？"><a href="#Q-目的はプロジェクトのコンセプト検証やデモで、何より早く検証を進めたい？" class="headerlink" title="Q. 目的はプロジェクトのコンセプト検証やデモで、何より早く検証を進めたい？"></a>Q. 目的はプロジェクトのコンセプト検証やデモで、何より早く検証を進めたい？</h4><ul><li>Yes<br>Arduinoと各種モジュールを組み合わせたプロトタイプを作る。<br>またはユニバーサル基板で製作する。</li><li>No, コンセプトの検証は済んでいて、更に小型化したい / コストを下げたいなど<br>ユニバーサル基板 or プリント基板の製作</li></ul><h4 id="Q-必要な台数はせいぜい数台で、今後仕様変更が入る可能性が大きい？"><a href="#Q-必要な台数はせいぜい数台で、今後仕様変更が入る可能性が大きい？" class="headerlink" title="Q. 必要な台数はせいぜい数台で、今後仕様変更が入る可能性が大きい？"></a>Q. 必要な台数はせいぜい数台で、今後仕様変更が入る可能性が大きい？</h4><ul><li>Yes<br>ユニバーサル基板で製作する。</li><li>No, 仕様もほぼ固まっていて台数も必要<br>プリント基板で製作する。</li></ul><p>害獣檻センサーの開発では、すでにコンセプト検証は済んでおり、また数十台の製造が必要なことから、プリント基板を製造することに決定しました。</p><h2 id="プリント基板の設計から製造まで"><a href="#プリント基板の設計から製造まで" class="headerlink" title="プリント基板の設計から製造まで"></a>プリント基板の設計から製造まで</h2><p>ここからは、害獣檻センサー製造時の具体的なプリント基板設計・製造の話をしていきます。</p><p>プリント基板を作るには、一般に下記のような手順で進めていきます。</p><ol><li>仕様を定義する</li></ol><ul><li>何はともあれ仕様を決めるところからです。これはソフトウェアもハードウェアも変わりませんね。<br>業務要件を基板の仕様へブレークダウンしていきます。</li></ul><ol start="2"><li>回路を設計する</li></ol><ul><li>仕様を満たすための回路を設計します。<br>システム開発に例えるならば、詳細設計のフェーズにあたるかと思います。</li></ul><ol start="3"><li>部品を選定する</li></ol><ul><li>設計した回路に用いる部品を選定します。<br>同じ目的を満たすためにも、様々なメーカーから複数の電子部品が出ています。<br>システム開発に例えるならば、技術スタックを選定するフェーズにあたるかと思います。</li></ul><ol start="4"><li>アートワークを描く</li></ol><ul><li>3で選定した部品をプリント基板上に配置し、<br>配線を描いて2の回路を作り上げていく作業です。<br>システム開発に例えるならば、コーディングにあたるかと思います。</li></ul><ol start="5"><li>基板を製造する</li></ol><ul><li>4で描いたアートワークを基にプリント基板を製造します。</li></ul><ol start="6"><li>部品を実装する</li></ol><ul><li>5で出来上がったプリント基板に、3で選定した部品を実装していきます。<br>5と6はシステム開発に例えるのが難しいのですが・・・強いて言うならコンパイル・ビルドでしょうか。</li></ul><p>これらについてすべて紹介してしまうと指輪物語並の大作になってしまうため、<br>この投稿では4のアートワークと5の基板製造に絞って詳しく紹介させていただきます。</p><h3 id="アートワークを描く"><a href="#アートワークを描く" class="headerlink" title="アートワークを描く"></a>アートワークを描く</h3><p>基板のアートワークを描くには、専用の基板CADと呼ばれるソフトウェアが必要です。<br>有名どころでは<a href="https://www.autodesk.co.jp/products/eagle/overview" target="_blank" rel="noopener">Eagle</a>、<a href="https://www.innotech.co.jp/products/orcad/products/orcad-capture/overview/" target="_blank" rel="noopener">OrCAD</a>などがあります。</p><p>今回は、オープンソースの<a href="http://www.kicad-pcb.org/" target="_blank" rel="noopener">KiCAD</a>を使用しました。<br>小規模なプリント基板の製作には十分な機能を備えていますし、Windows、macOS、Linuxの全てで動作するのも嬉しいところです。</p><p>アートワークを描き始めるにあたって、なんらかの制約条件が無いと効率的に進めていくのは難しいでしょう。<br>最も一般的な制約は、基板の大きさ・形状かと思います。<br>既に筐体の大きさが定められていて、基板形状もそれに縛られるパターンです。<br>特に制約が無い場合は、はじめに基板の大きさを決めてしまうのがおすすめです。<br>プリント基板の製造コストはほぼ大きさで決まるため、小さいに越したことはありません。</p><img src="/images/20190826/photo_20190826_02.png">これは害獣檻センサーのものではありませんがKiCADでのアートワーク中のキャプチャです。<p>アートワーク作業は、端的に言うと「終わりのないパズル」です。<br>大電流が流れる配線は太く短くなど様々な考慮をしつつ、部品と配線の配置を描いては消し、描いては消し…を繰り返していきます。</p><p>鼻歌交じりに部品を配置し、配線を進めていくと、「基板の中に収まらない～～！！！」ということも多々生じます。<br>お茶を飲んで一息ついてから、部品の配置を改善して配線をやり直します。<br>終わりのないパズルは、非常に泥臭い作業です。</p><p>基板の中に収めるだけでなく、以下のような点を心に留めながらアートワークを描いていく必要があります。</p><ul><li>電源ラインは太く短く</li><li>パスコンはICの近くに配置する</li><li>コネクタ類はケースに収めたときに作業性が良いように配置する</li><li>手半田で実装する場合はコテ先を取り回しやすいように部品を配置する</li><li>電解コンデンサは発熱する部品から離して配置する</li><li>GNDループが出来ないように</li><li>ベタGNDがアンテナ状にならないように</li><li>etc…</li></ul><p>また、一通り配線を終えた後にも、「ここはもう少しスマートに配線出来そうだな…」とか、「この部品配置は性能が悪くなりそうだな…」という点が出てきます。<br>これはソフトウェアで言うところのリファクタリングに近い作業になります。<br>全くやらないのも問題ですが、気を付けないと沼にはまります。<br>（本職の基板屋さんは良い方法論をお持ちかもしれません。教えてほしいです。）</p><h3 id="手戻り"><a href="#手戻り" class="headerlink" title="手戻り"></a>手戻り</h3><ol start="2"><li>回路を設計する</li><li>部品を選定する</li><li>アートワークを描く</li></ol><p>基板づくりの手順を上記のように順序付けて紹介していましたが、私の場合は4から2へ、3から2へと何度か戻っていました。</p><p>アートワークを描く中でどうしても部品が基板に収まらないので一回り小さい部品に変更する、部品選定と見積もりを進めていたら部品コストが思ったよりも高くなったので、部品の削減・共通化のために回路を修正する、<br>といったことを行っていました。<br>他にもマイコンを使った回路の場合、配線をスマートにするために使用するピンを変更することもあります。</p><p>それぞれの手順で担当者が違う場合には大変なことかもしれませんが、私の場合は回路設計から部品調達までを一人で担当していたので、<br>はじめから手戻り覚悟で、ある程度「えいや」で回路を決めたりしていました。</p><p>今回の害獣檻センサーの製造で最も大変だった手戻りは、1608と呼ばれるサイズのMLCC（チップ積層セラミックコンデンサ）が世界的な品薄で手に入らず、<br>すべて1005と呼ばれるサイズのものに変更したことです。<br>そこに関わる配線はすべて引き直しです・・・。<br>※ 1005のMLCCも品薄ではあるのですが、P板.comさんに実装をお願いする場合は無料でP板.comさんの標準在庫品を使ってもらえます。</p><h3 id="基板製造・発注"><a href="#基板製造・発注" class="headerlink" title="基板製造・発注"></a>基板製造・発注</h3><p>アートワークが完成したら、いよいよ発注です。</p><p><a href="https://www.marutsu.co.jp/contents/shop/marutsu/mame/60.html" target="_blank" rel="noopener">感光基板</a>を使えば自前で基板を作ることも可能ですが、<br>設備や薬品が必要で大変なので今回は外注しました。</p><p>先述しましたが、最近は<a href="https://www.elecrow.com/services.html" target="_blank" rel="noopener">Elecrow</a>さんや<a href="https://www.pcbgogo.jp/" target="_blank" rel="noopener">PCBgogo</a>さんなど、中国のプリント基板製造メーカーさんが台頭しています。<br>こういったところに頼めば格安で基板の製造が可能ですが、<br>今回の部品の自動実装まで頼みたかったため、<a href="https://www.p-ban.com/" target="_blank" rel="noopener">P板.com</a>さんを利用しました。</p><p>自動実装を利用する理由は、選定した部品の中に<a href="https://ja.wikipedia.org/wiki/%E3%82%A6%E3%82%A8%E3%83%8F%E3%83%BC%E3%83%AC%E3%83%99%E3%83%ABCSP" target="_blank" rel="noopener">とても手半田ができそうに無い部品</a>があり、<br>機械での実装・半田をせざるを得なかったことと、数十台分の半田付けを手作業で行うにはそれなりの時間がかかってしまうためです。<br>（個人差があるかもしれませんが、私は長時間半田付けをしていると目がショボショボになります）</p><p>基板を発注する前には、<em>必ずアートワークのダブルチェックを行いましょう。</em><br>基板のサイズと実際の部品や筐体のサイズが合わない、なんてことになったら大惨事です。</p><p>私は普段は、完成したアートワークを原寸大で紙に印刷し、実際に部品をあてがってみて大きさに問題が無いかなどを確認しています。<br>基板CADにもDRC（Design Rule Check）やERC（Electrical Rule Check）というLinterのような機能がついていますが、これに頼り切らずきちんと自分の目で確認します。</p><h3 id="完成！"><a href="#完成！" class="headerlink" title="完成！"></a>完成！</h3><p>さあ、苦労して設計した基板が手元に届いたときの感動はひとしおです。<br>プリント基板とユニバーサル基板の比較を長々と書いたりもしましたが、メーカーさんに頼んで作ってもらったプリント基板は<em>何よりも美しく</em>、「製品」として見栄えするものになります。<br>ケースの蓋を閉めたら、見えなくなってしまいますが…。</p><img src="/images/20190826/photo_20190826_03.jpeg">※ 一部お見せできないシリアルなどにボカシを入れています。<p>この基板が、檻の状態を検知する各種センサーの情報を処理し、LoRaWANという無線通信を経由してクラウドへデータを送信します。<br>試算ではありますが、バッテリー（単1乾電池）は1年ほどは持つ予定のため、猟友会の方の見回りにかかる負担を大きく軽減できるはずです。</p><h2 id="完成した害獣檻センサーの設置とこぼれ話"><a href="#完成した害獣檻センサーの設置とこぼれ話" class="headerlink" title="完成した害獣檻センサーの設置とこぼれ話"></a>完成した害獣檻センサーの設置とこぼれ話</h2><p>以上のような苦労を経て完成した害獣檻センサーは、現在与謝野町でイノシシ・シカの捕獲を検知しています。</p><img src="/images/20190826/20190826-3.png" class="img-middle-size"><p>（設置の様子を京都新聞さんなどに取り上げていただきました。写真右の”業者”が私です。）</p><p>これは設置の後日談になるのですが、イノシシ・シカを捕獲するための罠に、まれにクマがかかることがあります。<br>そのクマに害獣檻センサーを壊されてしまいました。</p><p>害獣檻センサーは、ケース内蔵の人感センサーおよび振動センサーと、ケースからケーブルで引き伸ばした開閉センサーからなっているのですが、このケーブルをクマに引きちぎられてしまいました。</p><p>外に出ているケーブルが痛みやすいであろうことは認識していてコルゲートチューブで保護していたのですが、まさかクマに切られてしまうとは・・・恐ろしいパワーです。</p><p>こうしたこともあり現在は、壊れやすい開閉センサーを使わず、人感センサーと振動センサーのみの値で捕獲の検知が出来ないかどうか、機械学習の利用も含めてバージョンアップの検討を進めています。</p><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><p>このテックブログを見ている方のほとんどはソフトウェアエンジニアの方と思い、ところどころソフトウェア開発に例えて解説をしてみました。</p><p>その例え話を考える中で自分自身、こと開発手法という点においてはハード・ソフトの垣根を越えて活かせる知見が数多くあるんじゃないか？と思いました。<br>それぞれの分野のエンジニア同士が知見を共有する機会があれば面白いかもしれません。</p><p>プリント基板づくりはまだまだ奥が深い話なのですが、「脱ブレッドボード！まずは簡単に作ってみよう」というだけなら、さほどコストもかかりません。<br>皆さんにも挑戦していただけたら幸いです。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;はじめまして。筒井と申します。&lt;/p&gt;
&lt;p&gt;簡単に自己紹介をさせていただくと、新卒でフューチャーに入社後に&lt;a href=&quot;https://www.future.co.jp/company_profile/future_group/&quot; target=&quot;_blank&quot; re
      
    
    </summary>
    
      <category term="IoT" scheme="https://future-architect.github.io/categories/IoT/"/>
    
    
      <category term="IoT" scheme="https://future-architect.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>システム開発で得たRedis利用ノウハウ</title>
    <link href="https://future-architect.github.io/articles/20190821/"/>
    <id>https://future-architect.github.io/articles/20190821/</id>
    <published>2019-08-20T23:53:57.000Z</published>
    <updated>2019-08-21T00:37:30.523Z</updated>
    
    <content type="html"><![CDATA[<p>こんにちは。初投稿です。<br>2012年新卒入社の竹内です。入社当時を振り返るとOracle10g,11gを良く利用していおり、データモデリングなどテーブル設計が好きで、2018年4月ぐらいまでRDBとバッチに浸ってました。</p><p>さて、現在プロジェクトでRedisを使っているのですが、いままでRDB人間だっただけにKVSやRedisならではの特徴に四苦八苦してます。</p><p>苦しんだ分、色々な知見を得ることができているので、その内容をご紹介します！</p><h2 id="対象者"><a href="#対象者" class="headerlink" title="対象者"></a>対象者</h2><ul><li>Redisの業務システム導入を検討している方</li><li>RDBとRedisの違いを知りたい方</li><li>現場的なRedisの利用方法を知りたい方</li></ul><h2 id="書いてないこと"><a href="#書いてないこと" class="headerlink" title="書いてないこと"></a>書いてないこと</h2><ul><li>データ型やコマンドなど、HelloWorld的に公式ドキュメントを見て得られる情報</li><li>インストールなど、Redisを利用できるまでの手順</li><li>フェイルオーバーやバックアップをはじめとする運用に関する内容</li><li>データ永続化に関する内容</li></ul><h2 id="書いてること"><a href="#書いてること" class="headerlink" title="書いてること"></a>書いてること</h2><ul><li>設計・実装に関わる以下の内容<ul><li>公式ドキュメントに書いてあるけど、よく読まなきゃ見落としてしまうような落とし穴</li><li>公式ドキュメントに書いてある内容から一歩踏み込んだ挙動（「それってつまりどういうこと？」）</li><li>と、それに対する私の考え（「じゃあどうすればいい？」）</li></ul></li></ul><h2 id="検証用サーバ情報"><a href="#検証用サーバ情報" class="headerlink" title="検証用サーバ情報"></a>検証用サーバ情報</h2><ul><li>redis_version:4.0.10</li><li>redis_mode:standalone</li><li>os:Amazon ElastiCache</li><li>マスタ・スレーブ構成（スレーブ１つ）</li></ul><h2 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h2><ul><li><ol start="0"><li>Redisとは（教科書的なサマリ）</li></ol></li><li><ol><li>シングルスレッド</li></ol></li><li><ol start="2"><li>Transaction の実現方法</li></ol></li><li><ol start="3"><li>Hash型はMultiGetできない</li></ol></li><li><ol start="4"><li>KEYSは怖い</li></ol></li><li><ol start="5"><li>おまけ：データ量試算時の注意</li></ol></li><li><ol start="6"><li>今後試したいこと</li></ol></li><li><ol start="7"><li>所感</li></ol></li><li><ol start="8"><li>ためになるサイト</li></ol></li></ul><h2 id="0-Redisとは（教科書的なサマリ）"><a href="#0-Redisとは（教科書的なサマリ）" class="headerlink" title="0. Redisとは（教科書的なサマリ）"></a>0. Redisとは（教科書的なサマリ）</h2><ul><li>Redis はキーと５種類の値型の対応関係を格納する非リレーショナルデータベース(NoSQL)。</li><li>メモリ上にデータを持つインメモリDBのため、非常に高速。</li></ul><h2 id="1-シングルスレッド"><a href="#1-シングルスレッド" class="headerlink" title="1. シングルスレッド"></a>1. シングルスレッド</h2><p>Redisサーバはシングルスレッド<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>で動作します。（厳密には他にもスレッドあるがクエリ処理をするスレッドは1つ）</p><p>..これだと、「あっそうなんだ」で終わっちゃいますよね。<br>しかしながら、以下の点に注意してください。</p><ul><li><strong>Keysのような重いクエリは本番運用禁止！</strong><ul><li>高速なはずのRedisで簡単に待ちが発生します。詳細・対策は後述</li></ul></li><li><strong>性能検証でCPU使用率余裕♪と思いきや…</strong><ul><li>あなたのRedisサーバは何コアですか？</li><li>4コア？それなら性能計測した <strong>RedisのCPU使用率はその4倍</strong> として考える必要があります。</li></ul></li></ul><p>AWSでは<strong>EngineCPUUtilization</strong>というメトリクスを使えば、上記を加味したCPU使用率が見れます。性能検証等で測定する際は<a href="https://aws.amazon.com/jp/about-aws/whats-new/2018/04/amazon-elastiCache-for-redis-introduces-new-cpu-utilization-metric-for-better-visibility-into-redis-workloads/" target="_blank" rel="noopener">こちらの指標</a>を使いましょう。</p><h2 id="2-トランザクションの実現方法"><a href="#2-トランザクションの実現方法" class="headerlink" title="2. トランザクションの実現方法"></a>2. トランザクションの実現方法</h2><p>トランザクション中は、クエリをQueueに溜めます。</p><ul><li>RDBでいうCommitのタイミングでそのクエリを順に(FIFOで)実行します（<code>EXEC</code>）</li><li>RDBでいうRollbackはQueueを取り消すことで実現しています（<code>DISCARD</code>）</li></ul><p>…これも、「あっそうなんだ」と思いますよね。<br>しかしながら、以下の点に注意してください。</p><ul><li><strong>Commit前のデータはRDBと異なり自分のトランザクション中で取得できない</strong><ul><li>Queueに溜めているだけなので、Redisのデータは一切更新されていないです</li><li><code>INCR</code>というValueを+1してその結果をReturnするコマンドがありますが、トランザクション中に実行するとNULLがReturnされます。トランザクションを使わない場合は更新後の値が取得できます</li></ul></li><li><strong>Commitするまで実行されない＝実行順注意</strong><ul><li>例えば、Javaで実装した1~4の作り替え処理で、データが作成されない事象が発生しました。</li></ul></li></ul><p>1．Transaction開始<br>2．Redisのデータを複数DELETE<br>3．Redisのデータを作成（並列処理） ←並列処理でDELETEが入ったQueue以外のQueueが作成<br>4．Transaction終了</p><p>並列処理で新たなQueueが作られた結果、トランザクション終了のタイミングでDELETE処理を含んでいないQueue、DELETE処理を含んでいるQueueを同時に<code>EXEC</code>。同時に動いた結果、3の登録が先に処理されあとで2のDELETEで消されたデータがいたようです。並列化をやめることで解消しました。</p><p>RDBでは都度データを書き換えに行くため、実行順の入替は起こりません。</p><h2 id="3-Hash型はMultiGetできない"><a href="#3-Hash型はMultiGetできない" class="headerlink" title="3. Hash型はMultiGetできない"></a>3. Hash型はMultiGetできない</h2><p>Hash型はKeyの中に複数のFieldとValueを持てるため、RDB慣れしているとついつい使いたくなります。<br>ここに落とし穴があります。</p><p>Hash型はString型のデータと違い複数レコードを一括取得するメソッドが提供されていません。</p><p>複数レコードを取得して表示しようとすると1件ずつループ処理で取得することになり、NWのオーバーヘッドでとたんに遅いという性能問題になりかねません<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。</p><h3 id="回避策"><a href="#回避策" class="headerlink" title="回避策"></a>回避策</h3><p>自分達もハマり、色々悩んだのでいくつか回避策を紹介します。</p><h4 id="3-1-Hashを捨てる！"><a href="#3-1-Hashを捨てる！" class="headerlink" title="3-1. Hashを捨てる！"></a>3-1. Hashを捨てる！</h4><p>潔くHashを捨てます。以下のようにString型で持つことで複数キーを一括で取得する<code>MGET</code>が使えるようになります。Hashとして考えていたまとまりの概念はRedisにアクセスするEntityや、RedisのデータをGETするAPIが吸収すれば、大きな影響はないと思います。</p><figure class="highlight json"><figcaption><span>Hashイメージ.json</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>: <span class="string">"sales:111"</span>, </span><br><span class="line">  <span class="attr">"value"</span>: &#123;</span><br><span class="line">     <span class="attr">"name"</span>: <span class="string">"REDBULL"</span>,</span><br><span class="line">     <span class="attr">"amount"</span>: <span class="string">"200"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><figcaption><span>Hashを捨てたイメージ.json</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;  <span class="attr">"key"</span>: <span class="string">"sales:111:name"</span>, <span class="attr">"value"</span>: <span class="string">"REDBULL"</span>&#125;</span><br><span class="line">&#123;  <span class="attr">"key"</span>: <span class="string">"sales:111:amount"</span>, <span class="attr">"value"</span>: <span class="string">"200"</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="3-2-HashのMultiGetを実装する！"><a href="#3-2-HashのMultiGetを実装する！" class="headerlink" title="3-2. HashのMultiGetを実装する！"></a>3-2. HashのMultiGetを実装する！</h4><p>標準機能ではないようですが、以下2つの方法でHashの一括取得を実装できます。</p><h5 id="実装方法1-Luaスクリプト"><a href="#実装方法1-Luaスクリプト" class="headerlink" title="実装方法1. Luaスクリプト"></a>実装方法1. Luaスクリプト</h5><p>RDBには、複数クエリ実行やIF文・ループ処理などの一連の手続きを一回のクエリでRDB上で実行できるストアドプロシージャやストアドファンクションというものがあります。Luaスクリプトを使えばRedisでもそれと同様のことができます。</p><p>実際にHash型のKeyを一度に複数渡して処理できるスクリプトを作ってみました。試したところ、検証サーバでは1件7msかかってたHGETALLでしたが、10000件一括取得で400msぐらいでデータ取得できました。注意ですが、Luaスクリプトもクエリ処理用のスレッド（シングルスレッド）で動作するため、重い処理は避けるべきです。</p><p>※Javaから実行する方法は<a href="https://blog.kakakikikeke.com/2015/01/javaluaredis.html" target="_blank" rel="noopener">こちら</a>を参考ください。</p><p>luaスクリプト</p><figure class="highlight lua"><figcaption><span>hmgetall.lua</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- param1: hmgetallで取得したいkeyの数 param2~: 取得したいkey（半角スペース区切りで複数可能）</span></span><br><span class="line"><span class="keyword">local</span> result = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>, KEYS[<span class="number">1</span>] <span class="keyword">do</span></span><br><span class="line">  result[i] = &#123;<span class="string">'"key"'</span>, KEYS[i+<span class="number">1</span>] ,redis.call(<span class="string">'HGETALL'</span>, KEYS[i + <span class="number">1</span>])&#125;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>使い方</p><figure class="highlight shell"><figcaption><span>hmgetall.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h $&#123;REDIS_HOST&#125; -p $&#123;PORT&#125; --eval ./hmgetall.lua 2 sales:111 sales:222</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Return　Data</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 1) 1) "\"key\""</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#    2) "sales:111"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#    3)  1) "\"name\""</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#        2) "REDBULL"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#        3) "\"amount\""</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#        4) "200"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 2) 1) "\"key\""</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#    2) "sales:222"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#    3)  1) "\"name\""</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#        2) "MILK"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#        3) "\"amount\""</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#        4) "165"</span></span></span><br></pre></td></tr></table></figure><h5 id="実装方法2-syncAndReturnAll"><a href="#実装方法2-syncAndReturnAll" class="headerlink" title="実装方法2. syncAndReturnAll"></a>実装方法2. syncAndReturnAll</h5><p>Redisのライブラリによっては、1件ずつ同期的に処理するのではなく、<strong>「Queueに詰めて一括で実行して、その結果をまとめて取得する」ってことができるようです</strong>（JavaはJedisでできることを確認済）。使用する言語でいいライブラリがあればLuaスクリプトよりもこちらの方がよいと思います。</p><p>Queueに詰めた実行順でレスポンスも返ってくるので、Keyとのマッピングもできます。keyがない場合も空のMapが返るのでマッピング順がずれることはないです。<br><a href="http://tool.oschina.net/uploads/apidocs/jedis-2.1.0/redis/clients/jedis/Pipeline.html#syncAndReturnAll%28%29" target="_blank" rel="noopener">http://tool.oschina.net/uploads/apidocs/jedis-2.1.0/redis/clients/jedis/Pipeline.html#syncAndReturnAll%28%29</a></p><figure class="highlight java"><figcaption><span>hMGetAll.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  Jedis jedis = <span class="keyword">new</span> Jedis (host, port );</span><br><span class="line">  Pipeline pipe = jedis.pipelined();</span><br><span class="line">  pipe.hgetAll(<span class="string">"sales:111"</span>);</span><br><span class="line">  pipe.hgetAll(<span class="string">"sales:222"</span>);</span><br><span class="line">  pipe.hgetAll(<span class="string">"sales:NotExist"</span>);</span><br><span class="line">  List&lt;Object&gt; result=  pipe.syncAndReturnAll();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">結果</span></span><br><span class="line"><span class="comment">result= &#123;ArrayList@14772&#125;  size = 3</span></span><br><span class="line"><span class="comment"> 0 = &#123;HashMap@14777&#125;  size = 2</span></span><br><span class="line"><span class="comment">  ""name"" -&gt; "REDBULL"</span></span><br><span class="line"><span class="comment">  ""amount"" -&gt; "200"</span></span><br><span class="line"><span class="comment"> 1 = &#123;HashMap@14778&#125;  size = 2</span></span><br><span class="line"><span class="comment">  ""name"" -&gt; "MILK"</span></span><br><span class="line"><span class="comment">  ""amount"" -&gt; "165"</span></span><br><span class="line"><span class="comment"> 2 = &#123;HashMap@14779&#125;  size = 0</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h2 id="4-KEYSは怖い"><a href="#4-KEYSは怖い" class="headerlink" title="4. KEYSは怖い"></a>4. KEYSは怖い</h2><p>ここで、Redisに登録されたKey一覧を取得する<code>KEYS</code>というコマンドをご紹介します。</p><p>例えば <code>KEYS &quot;sales:*&quot;</code> と実行すれば正規表現（※）でkey検索できます。</p><p>keysの正規表現は機能に制限があり以下だけです。<br>? ・・・ 任意の1文字<br>* ・・・ 任意の文字列<br>[ ] ・・・ 角カッコ内の文字のどれか1文字</p><p>なんとなく便利そうな気、しますよね。</p><p>しかしながら、以下の点に注意してください。</p><ul><li>この<code>KEYS</code>はRDBのINDEXを用いた前方一致での効率的な検索をしません。O(N)となりめっちゃ遅いです<ul><li>計測時は約9百万の中から10件検索するようなクエリで1秒かかりました</li></ul></li><li>その間のRedisはシングルスレッドでクエリ捌くため、他のリクエストを捌けません。ReadもWriteの両方ともさばけません。</li></ul><p>Jedis（Java用ライブラリ）だとデフォルトtimeoutが2秒なので、2，3人がkeysを2発ぐらい実行するとそれだけでtimeoutエラーが出たりします。公式でもWARNINGって書いてます。<a href="https://redis.io/commands/keys" target="_blank" rel="noopener">https://redis.io/commands/keys</a></p><blockquote><p>While the time complexity for this operation is O(N), the constant times are fairly low. For example, Redis running on an entry level laptop can scan a 1 million key database in 40 milliseconds.<br>Warning: consider KEYS as a command that should only be used in production environments with extreme care. It may ruin performance when it is executed against large databases. This command is intended for debugging and special operations, such as changing your keyspace layout. Don’t use KEYS in your regular application code. If you’re looking for a way to find keys in a subset of your keyspace, consider using SCAN or sets.</p></blockquote><br><h3 id="KEYSの代替方法"><a href="#KEYSの代替方法" class="headerlink" title="KEYSの代替方法"></a>KEYSの代替方法</h3><p>「今の設計には<code>KEYS</code>が必要なんだ！」っていうことありますよね。代替方法、そろえてます。<br><br></p><h4 id="RDBから取得"><a href="#RDBから取得" class="headerlink" title="RDBから取得"></a>RDBから取得</h4><p>一定の条件が揃えば使える方法。例えば販売のトランザクションデータはRDBでその日の商品別のサマリデータはRedisという時です。<br>RDBから販売トランや商品マスタを<code>SELECT DISTINCT</code>すれば…<br><br></p><h4 id="Sets型利用"><a href="#Sets型利用" class="headerlink" title="Sets型利用"></a>Sets型利用</h4><p>Redisのデータ型には、Sets型という同じデータは無視する「重複なしリスト型」が存在します。</p><p>これに保持しているKey情報を登録しておくようにします。</p><p>例えば販売のサマリデータを作成・更新する際に、Sets型にデータ追加のコマンド（<code>SADD</code>）を都度発行します。※Redisの登録は高速（Pipeline処理で計測時は0.01ms程度）なので追加の<code>SADD</code>処理の性能影響は無視できるものと考えてます。</p><figure class="highlight shell"><figcaption><span>redis_sets_command.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Sets型のデータ登録</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># データ登録</span></span></span><br><span class="line">redis-cli -h $&#123;REDIS_HOST&#125; -p $&#123;PORT&#125; SADD sales:keys sales:111</span><br><span class="line">redis-cli -h $&#123;REDIS_HOST&#125; -p $&#123;PORT&#125; SADD sales:keys sales:222</span><br><span class="line">redis-cli -h $&#123;REDIS_HOST&#125; -p $&#123;PORT&#125; SADD sales:keys sales:111</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># データ取得</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 全件取得</span></span></span><br><span class="line">redis-cli -h $&#123;REDIS_HOST&#125; -p $&#123;PORT&#125; SMEMBERS sales:keys    #sales:111 とsales:222が返ってくる</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## カーソル的に一定件数ずつ取得することも可能</span></span></span><br><span class="line">redis-cli -h $&#123;REDIS_HOST&#125; -p $&#123;PORT&#125; SSCAN sales:keys 0 COUNT 1000</span><br></pre></td></tr></table></figure><br><h4 id="抜け道：KEYSは使う。負荷を下げる。"><a href="#抜け道：KEYSは使う。負荷を下げる。" class="headerlink" title="抜け道：KEYSは使う。負荷を下げる。"></a>抜け道：KEYSは使う。負荷を下げる。</h4><p>今更変えられないよ！抜け道ないの！？ということでこれも検討しました。<br>設計・実装変えれないときの最終手段に近い位置づけです。最初から選択すべき内容ではないです。</p><br><h5 id="DBを分ける"><a href="#DBを分ける" class="headerlink" title="DBを分ける"></a>DBを分ける</h5><p><code>KEYS</code>の検索対象はRedisの同一DBの範囲に閉じられています。DBを分けて、<code>KEYS</code>の対象減らすことで負荷を下げることができます。ただし、DBごとにスレッドが分かれるわけではないです。別DBへのクエリも同じシングルスレッドで処理されます。<br><br></p><h5 id="参照用レプリカ使用"><a href="#参照用レプリカ使用" class="headerlink" title="参照用レプリカ使用"></a>参照用レプリカ使用</h5><p>DBではなく別インスタンスを使おう、<code>KEYS</code>専用にレプリカ使おうっていう考えです。</p><p>この方法はDB分けとは違い、インスタンスが分かれるので、<code>KEYS</code>実行中にもマスター側でクエリを処理することが可能です。</p><br><h4 id="視点を変える-本当にKEYSが必要？-処理方式を見直そう"><a href="#視点を変える-本当にKEYSが必要？-処理方式を見直そう" class="headerlink" title="視点を変える:本当にKEYSが必要？ ~ 処理方式を見直そう ~"></a>視点を変える:本当にKEYSが必要？ ~ 処理方式を見直そう ~</h4><p>RDB脳だった自分にはなかなか思いつかなかった設計方式を記載しておきます。</p><h5 id="CASE1-Redisは毎日リセットしたい。対象データを一括で消したい。"><a href="#CASE1-Redisは毎日リセットしたい。対象データを一括で消したい。" class="headerlink" title="CASE1: Redisは毎日リセットしたい。対象データを一括で消したい。"></a>CASE1: Redisは毎日リセットしたい。対象データを一括で消したい。</h5><p>一括で消すには、<code>KEYS</code>で一覧取得が必要。なんてとき。</p><ul><li>見直し検討1:flushdbの利用<ul><li>一括で消したい単位でDBを分けておけば、<code>FLUSHDB</code>の1コマンドで削除できます</li></ul></li><li>見直し検討2:データ有効期間の設定<ul><li><code>EXPIRE</code>でデータに有効期限を設定できます。期限切れになると自動削除されます</li></ul></li></ul><h5 id="CASE2-数値を合計するためにKEYSで対象データがほしい。"><a href="#CASE2-数値を合計するためにKEYSで対象データがほしい。" class="headerlink" title="CASE2: 数値を合計するためにKEYSで対象データがほしい。"></a>CASE2: 数値を合計するためにKEYSで対象データがほしい。</h5><p>「店舗商品別データの売上金額」から、「店舗合計の売上金額」を取得するために、該当店舗のkey一覧取得→それぞれのデータをGETしてサマリしよう。なんてとき。</p><p><strong>見直し検討:最初から店舗合計のデータを作成する</strong><br>一括処理（更新・取得）はRDBの得意領域。細かく持って集計してっていうバッチ処理はRDB的考え方です。<br>Redisは数件を書き込む・読み込むことが高速。販売がある度に、店舗別に商品別のデータと、店舗合計のデータを更新すればいいじゃない。Redisの更新は速いので。数値の更新時は<code>INCR</code>を使えば、事前にロックとか考えずに数値を+-できます。</p><br><h2 id="5-おまけ：データ量試算時の注意"><a href="#5-おまけ：データ量試算時の注意" class="headerlink" title="5. おまけ：データ量試算時の注意"></a>5. おまけ：データ量試算時の注意</h2><p><strong>Hash型でデータを持たせた場合、HashのField名も含めることを忘れずに。</strong><br>RDBのテーブルのレコードのイメージでHash型を使うと、うっかりカラム名の試算を忘れがちなので注意です。<br>Valueが数値だったりすると、主にField名で容量喰いますｗ</p><br><h2 id="6-今後試したいこと"><a href="#6-今後試したいこと" class="headerlink" title="6. 今後試したいこと"></a>6. 今後試したいこと</h2><h3 id="Sets型を使ってRedisだけでKey検索も行う"><a href="#Sets型を使ってRedisだけでKey検索も行う" class="headerlink" title="Sets型を使ってRedisだけでKey検索も行う"></a>Sets型を使ってRedisだけでKey検索も行う</h3><p>業務システムでは「条件によって絞り込んで一覧表示する」ということが多いでしょう。</p><p>属性情報を元に該当するKeyを調べるため、RDBのマスタにアクセスすることになるかと思いますが、このKey検索もRedisだけで実現したいという内容です。</p><p>Sets型和集合(Union)、積集合(Intersection)、差集合(Difference)をサポートしてるので、属性情報に応じたKeyの検索も実装できそうです。例えば、飲み物のSets、今日売れたものSetsがあれば、積集合で「今日売れた飲み物」のキー一覧を取得できます。</p><p>…ここまでやるかって内容ですね。</p><h3 id="Hash型で列指向でデータを持たせる。"><a href="#Hash型で列指向でデータを持たせる。" class="headerlink" title="Hash型で列指向でデータを持たせる。"></a>Hash型で列指向でデータを持たせる。</h3><p>ついつい行指向で考えがち。数値情報を扱いたい場合、列指向で持たせると <code>HGETALL</code> で一度にまとめて取得できるので、列指向で持たせる方がいいかもしれません。<br>※<code>HSCAN</code>っていうカーソル的にデータ取得できるコマンドあるぐらいなのでそっちを想定しているのかも。<br>※同じKey内でフィールドの重複許さないので、列指向的な持ち方だとSets型 + String型の要素を足した扱い方ができますね。Sets型のような集合演算はできませんが。</p><h2 id="7-所感"><a href="#7-所感" class="headerlink" title="7. 所感"></a>7. 所感</h2><p>正直、RDBだとこんなの簡単にできるのにーと思うことが多々あり、最初はRedisを嫌いになりかけました。しかしRedisはKVSの中でもかなりRDBの人達に歩み寄ってくれてると感じます（Sets型やHash型はすごく好感持てます）。色々な可能性が見えてきて、今では気になる存在です。</p><p>この記事を読んでRedisを気にする仲間が増えればめちゃ嬉しいですー。</p><h2 id="8-ためになるサイト"><a href="#8-ためになるサイト" class="headerlink" title="8. ためになるサイト"></a>8. ためになるサイト</h2><ul><li>データイメージがわかりやすいサイト：<a href="http://redisgate.jp/redis/command/commands.php" target="_blank" rel="noopener">http://redisgate.jp/redis/command/commands.php</a></li><li>トランザクション：<a href="https://redis-documentasion-japanese.readthedocs.io/ja/latest/topics/transactions.html" target="_blank" rel="noopener">https://redis-documentasion-japanese.readthedocs.io/ja/latest/topics/transactions.html</a></li><li>spring での設定系（記事古め）：<a href="http://fits.hatenablog.com/entry/2015/08/27/205539" target="_blank" rel="noopener">http://fits.hatenablog.com/entry/2015/08/27/205539</a></li><li>RedisサーバのCPU負荷対策パターン：<a href="https://blog.yuuk.io/entry/redis-cpu-load" target="_blank" rel="noopener">https://blog.yuuk.io/entry/redis-cpu-load</a></li><li>Luaスクリプトは書き方ここに載ってます：<a href="https://redis.io/commands/eval" target="_blank" rel="noopener">https://redis.io/commands/eval</a></li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">厳密には、バックグラウンドプロセス等は別スレッドで動くため、完全なシングルスレッドというわけではないです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">検証サーバで計測したときは、1件取得で7ms程度かかりました。1000件取得するとなると7秒かかりますね...</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;こんにちは。初投稿です。&lt;br&gt;2012年新卒入社の竹内です。入社当時を振り返るとOracle10g,11gを良く利用していおり、データモデリングなどテーブル設計が好きで、2018年4月ぐらいまでRDBとバッチに浸ってました。&lt;/p&gt;
&lt;p&gt;さて、現在プロジェクトでRedi
      
    
    </summary>
    
      <category term="DB" scheme="https://future-architect.github.io/categories/DB/"/>
    
    
      <category term="Redis" scheme="https://future-architect.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>初めてのGCPで環境構築してハマったこと</title>
    <link href="https://future-architect.github.io/articles/20190820/"/>
    <id>https://future-architect.github.io/articles/20190820/</id>
    <published>2019-08-20T00:19:49.000Z</published>
    <updated>2019-08-20T00:30:16.491Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>はじめまして。TIG DXチーム<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>所属、ゲームとボルダリング好きなエンジニアの椎名@417yskです。</p><p>お仕事でGCP使って環境を構築することがあったのですが、色々とハマることが多かったので供養を兼ねて共有したいと思います。</p><p>当時の私の経験値としては「AWSの一部サービスは触ったことがある」程度でクラウド環境を下地から構築するのは初めての経験でした。一度触ってみれば常識だよねって内容が多いですが、初心者が小石につまずいてもすぐに立ち上れるようになれば幸いです。</p><h1 id="今回構築した環境の概要"><a href="#今回構築した環境の概要" class="headerlink" title="今回構築した環境の概要"></a>今回構築した環境の概要</h1><ul><li>既存のオンプレ環境との共存を前提とし、使えるアドレス範囲もオンプレのNWから払い出し</li><li>オンプレ環境とインターネットVPNでつなぐプロジェクトは1つ（ホストプロジェクト）</li><li>各環境（production、staging・・）は共有VPCで接続（サービスプロジェクト）</li></ul><img src="/images/20190820/photo_20190820_01.png"><p>なお、構築はTerraform, Ansibleで行いました。</p><h1 id="GCPで環境構築してハマったこと"><a href="#GCPで環境構築してハマったこと" class="headerlink" title="GCPで環境構築してハマったこと"></a>GCPで環境構築してハマったこと</h1><p>本編です。<br>カテゴリ別に記載しています。</p><h2 id="1-GKE関連"><a href="#1-GKE関連" class="headerlink" title="1. GKE関連"></a>1. GKE関連</h2><h3 id="1-1-GKEのコア数を増やせない"><a href="#1-1-GKEのコア数を増やせない" class="headerlink" title="1-1. GKEのコア数を増やせない"></a>1-1. GKEのコア数を増やせない</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><p>アカウントあたりの割り当て上限に達していた。</p><h4 id="対応"><a href="#対応" class="headerlink" title="対応"></a>対応</h4><p>制限変更を依頼することで解消しました。<br>自分が依頼したときは数分で対応してくれましたが、常に数分で対応されるかは定かではありません。<br>サービスインする前は想定されるスケール具合に合わせて事前に拡張しておきましょう。<br>割り当て増加の手順は他の方が書かれていますのでこちらをご参考に。<br><a href="https://qiita.com/mouse2/items/dd136453798804f99de7" target="_blank" rel="noopener">https://qiita.com/mouse2/items/dd136453798804f99de7</a><br><a href="https://cloud.google.com/compute/quotas?hl=ja&amp;_ga=1.181298212.2042940000.1483498197" target="_blank" rel="noopener">https://cloud.google.com/compute/quotas?hl=ja&amp;_ga=1.181298212.2042940000.1483498197</a></p><h3 id="1-2-プライベートGKEクラスタからインターネットアクセスできない"><a href="#1-2-プライベートGKEクラスタからインターネットアクセスできない" class="headerlink" title="1-2. プライベートGKEクラスタからインターネットアクセスできない"></a>1-2. プライベートGKEクラスタからインターネットアクセスできない</h3><h4 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h4><p>プライベートクラスタではノード（pod）に外部IPが付与されないため。</p><h4 id="対応-1"><a href="#対応-1" class="headerlink" title="対応"></a>対応</h4><p>CloudNATを設定しNAT経由でインターネットに出るようにしました。<br>今回はシステム要件で外部IPの付与が不可でしたが、外部IPが付与されていれば問題なくインターネットアクセスできます。</p><h3 id="1-3-GKEへのデプロイ時、kubectlコマンドが接続できない"><a href="#1-3-GKEへのデプロイ時、kubectlコマンドが接続できない" class="headerlink" title="1-3. GKEへのデプロイ時、kubectlコマンドが接続できない"></a>1-3. GKEへのデプロイ時、kubectlコマンドが接続できない</h3><h4 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h4><p>デプロイサーバが外部IPしか持っていなかったため。<br>GKEクラスタはこの時点でプライベートクラスタであった。</p><h4 id="対応-2"><a href="#対応-2" class="headerlink" title="対応"></a>対応</h4><p>システム要件もありデプロイサーバに内部IPを付与し、外部IPを削除しました。<br>その上でGKEクラスタの承認済みネットワークにデプロイサーバの属するサブネットを追加しました。</p><h3 id="1-4-GKEのLBでフロントのIPが固定できない"><a href="#1-4-GKEのLBでフロントのIPが固定できない" class="headerlink" title="1-4. GKEのLBでフロントのIPが固定できない"></a>1-4. GKEのLBでフロントのIPが固定できない</h3><h4 id="事象"><a href="#事象" class="headerlink" title="事象"></a>事象</h4><p>LB作成時にフロントエンドのIPが自動的に割り振られてしまう。</p><h4 id="対応-3"><a href="#対応-3" class="headerlink" title="対応"></a>対応</h4><p>Ingressを利用して意図したIPを割り当てました。<br>詳細は他の方が書かれていますのでこちらをご参考に。<br><a href="https://qiita.com/tinjyuu/items/fd7a97b0b81963dcc7f2" target="_blank" rel="noopener">https://qiita.com/tinjyuu/items/fd7a97b0b81963dcc7f2</a></p><h3 id="1-5-共有VPC上のGKEクラスタのセカンダリCIDR設計"><a href="#1-5-共有VPC上のGKEクラスタのセカンダリCIDR設計" class="headerlink" title="1-5. 共有VPC上のGKEクラスタのセカンダリCIDR設計"></a>1-5. 共有VPC上のGKEクラスタのセカンダリCIDR設計</h3><h4 id="事象-1"><a href="#事象-1" class="headerlink" title="事象"></a>事象</h4><p>オンプレ環境と接続する1つの共有VPC上にproduction, stagingなど複数プロジェクトを相乗りさせる場合、各プロジェクトで利用するセカンダリCIDRの設計が必要。</p><h4 id="対応-4"><a href="#対応-4" class="headerlink" title="対応"></a>対応</h4><p>GKEで必要なセカンダリCIDRを本腰入れて設計しました。<br>スタンダードなこれと言った解はなく、必要な環境数、オンプレ環境から割り当てられたIP範囲から適宜設計する必要があります。<br>ここだけでも1記事くらいのボリュームになりそうなので詳細はまた別途。</p><h3 id="1-6-GKEクラスタが大量に作成できない"><a href="#1-6-GKEクラスタが大量に作成できない" class="headerlink" title="1-6. GKEクラスタが大量に作成できない"></a>1-6. GKEクラスタが大量に作成できない</h3><h4 id="原因-3"><a href="#原因-3" class="headerlink" title="原因"></a>原因</h4><p>利用可能なセカンダリCIDRの上限に掛かるため。<br>共有VPC上にプライベートGKEクラスタを構築するためには、1クラスタあたりに2つのアドレス範囲（pod/service）を割り当てる必要があるが、1サブネット内にセカンダリCIDRは上限5つまでしか作成できない。<br>今回、1プロジェクト=1サブネットを共有するという方針であったため、1プロジェクト当たりに2つしかクラスタを作成できなかった。</p><h4 id="対応-5"><a href="#対応-5" class="headerlink" title="対応"></a>対応</h4><p>用途に応じてクラスタを分けるのではなく、ノードプールを分ける方針としました。<br>GKEの設計でクラスタを分けるかノードプールを分けるかはしばしば話に挙がりますが、共有VPC上に構築する場合はノードプールを分けるしかないです。</p><h2 id="2-CloudSQL関連"><a href="#2-CloudSQL関連" class="headerlink" title="2. CloudSQL関連"></a>2. CloudSQL関連</h2><h3 id="2-1-CloudSQLのインスタンスが再作成できない"><a href="#2-1-CloudSQLのインスタンスが再作成できない" class="headerlink" title="2-1. CloudSQLのインスタンスが再作成できない"></a>2-1. CloudSQLのインスタンスが再作成できない</h3><h4 id="原因-4"><a href="#原因-4" class="headerlink" title="原因"></a>原因</h4><p>同じインスタンス名は数日間（1週間ほど）は作成できない仕様であったため。</p><h4 id="対応-6"><a href="#対応-6" class="headerlink" title="対応"></a>対応</h4><p>初期構築時は連番やタイムスタンプなどを入れ確実に構築可能なことの保証が取れてから真名で構築することにしました。<br>インスタンス名にタイムスタンプなどを入れてクライアント側の接続情報を変更していく運用も考えましたが、担当した案件では開発に複数社入っていたりする状況もあり諦めました。</p><h3 id="2-2-CloudSQLのアクセス制限"><a href="#2-2-CloudSQLのアクセス制限" class="headerlink" title="2-2. CloudSQLのアクセス制限"></a>2-2. CloudSQLのアクセス制限</h3><h4 id="事象-2"><a href="#事象-2" class="headerlink" title="事象"></a>事象</h4><p>CloudSQLにアクセス可能なインスタンスを同一プロジェクトのインスタンスに絞りたいが、以下の制約がある。</p><ul><li>Firewall Ruleはサブネット単位（今回の構成のプロジェクト単位）で指定できない</li><li>CloudSQLにFirewall Ruleで利用するネットワークタグを設定できない。</li><li>承認済みネットワークにプライベートIPは設定できない</li></ul><h4 id="対応-7"><a href="#対応-7" class="headerlink" title="対応"></a>対応</h4><p>出来上がったCloudSQLのIPを、gcloudで取得して、それをFirewall Ruleに設定しました。なおFirewall Ruleはインスタンスに対して適応されるため、インスタンスからの下りに対して制御をかけることしかできません。</p><p>デフォルトは下りが全てallowされているので、まずはCloudSQLのIP範囲にdenyをかけて、その上で接続するSQLインスタンスのみallowするという対応をしています。<br>Firewall Ruleの話だけで1記事くらいのボリュームになりそうなので詳細はまた別途書きます。</p><h3 id="2-3-CloudSQL-のパスワードが有効では無かった"><a href="#2-3-CloudSQL-のパスワードが有効では無かった" class="headerlink" title="2-3. CloudSQL のパスワードが有効では無かった"></a>2-3. CloudSQL のパスワードが有効では無かった</h3><h4 id="原因-5"><a href="#原因-5" class="headerlink" title="原因"></a>原因</h4><p>Terraformでデプロイしていたが、その定義が不正だったため。<br>後述のサンプルだとインスタンス名が正しく紐づかない。GCPは関係なくTerraformの記述ミスが原因でした。</p><h4 id="対応-8"><a href="#対応-8" class="headerlink" title="対応"></a>対応</h4><p>依存関係があるリソースは、ハードコードで名称を設定しない。<br>${xxxxx}を使用して実際に設定されている名称を取得する。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// インスタンスの作成</span></span><br><span class="line">resource <span class="string">"google_sql_database_instance"</span> <span class="string">"db-instance-test"</span> &#123;</span><br><span class="line">    name = <span class="string">"test-instance"</span></span><br><span class="line">    <span class="comment">/*省略*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// パスワード設定：NGパターン</span></span><br><span class="line">resource <span class="string">"google_sql_user"</span> <span class="string">"test-postgres-user"</span> &#123;</span><br><span class="line">    name = <span class="string">"postgres"</span></span><br><span class="line">    instance = <span class="string">"test-instance"</span></span><br><span class="line">    password = <span class="string">"postgres"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// パスワード設定：OKパターン</span></span><br><span class="line">resource <span class="string">"google_sql_user"</span> <span class="string">"test-postgres-user"</span> &#123;</span><br><span class="line">    name = <span class="string">"postgres"</span></span><br><span class="line">    instance = <span class="string">"$&#123;google_sql_database_instance.db-instance-test.name&#125;"</span></span><br><span class="line">    password = <span class="string">"postgres"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-4-CloudSqlProxyを使ってSQLインスタンスにつながらない"><a href="#2-4-CloudSqlProxyを使ってSQLインスタンスにつながらない" class="headerlink" title="2-4. CloudSqlProxyを使ってSQLインスタンスにつながらない"></a>2-4. CloudSqlProxyを使ってSQLインスタンスにつながらない</h3><h4 id="原因-6"><a href="#原因-6" class="headerlink" title="原因"></a>原因</h4><p>Cloud SQL Administration APIが有効化されていないため。<br>CloudSqlProxyを使う際は有効化する必要があります。<br><a href="https://cloud.google.com/sql/docs/postgres/connect-external-app?hl=ja" target="_blank" rel="noopener">https://cloud.google.com/sql/docs/postgres/connect-external-app?hl=ja</a></p><h4 id="対応-9"><a href="#対応-9" class="headerlink" title="対応"></a>対応</h4><p>Cloud SQL Administration APIを有効化します。<br>環境の断面が増えてくると、Administration APIの有効化手順が漏れるので、これもちゃんと<a href="https://www.terraform.io/docs/providers/google/r/google_project_services.html" target="_blank" rel="noopener">Terraformで管理</a>することになりました。<br>（※それまでは手動で有効にしていました☠）</p><h3 id="2-5-CloudSQLの接続CIDRが任意のアドレス範囲で作成されてしまった"><a href="#2-5-CloudSQLの接続CIDRが任意のアドレス範囲で作成されてしまった" class="headerlink" title="2-5. CloudSQLの接続CIDRが任意のアドレス範囲で作成されてしまった"></a>2-5. CloudSQLの接続CIDRが任意のアドレス範囲で作成されてしまった</h3><h4 id="原因-7"><a href="#原因-7" class="headerlink" title="原因"></a>原因</h4><p>IPアドレスの設計前にCloudSQLのインスタンスを立てて検証していたため初期構築時にCIDRの割り当てを明確に行っていなかった。</p><h4 id="対応-10"><a href="#対応-10" class="headerlink" title="対応"></a>対応</h4><p>GCPのSREチーム（米国）へ変更対応を依頼しました（ちょうどクリスマスシーズンだったので大変でした）。2019年1月時点では、このCIDRは一度設定するとGUIやコマンドで変更できないため依頼する必要があります。<br>共有VPCの環境でCloudSQLのアドレス範囲を明示的に定めたい場合は注意しましょう。</p><h3 id="2-6-GCEからCloudSQLへ接続ができない"><a href="#2-6-GCEからCloudSQLへ接続ができない" class="headerlink" title="2-6. GCEからCloudSQLへ接続ができない"></a>2-6. GCEからCloudSQLへ接続ができない</h3><h4 id="原因-8"><a href="#原因-8" class="headerlink" title="原因"></a>原因</h4><p>GCEインスタンスには内部IPのみで外部IPが付与されておらず、SQLインスタンスには外部IPのみで内部IPを付与していなかった（β版のため）。<br>SQL Proxyが上手いことやってくれると淡い期待をしたがダメであった。</p><h4 id="対応-11"><a href="#対応-11" class="headerlink" title="対応"></a>対応</h4><p>他のシステム要件からCloudSQLに内部IPを付与しました</p><h2 id="3-LB関連"><a href="#3-LB関連" class="headerlink" title="3. LB関連"></a>3. LB関連</h2><h3 id="3-1-Internal-特定の通信においてInternal-LBで負荷分散されない"><a href="#3-1-Internal-特定の通信においてInternal-LBで負荷分散されない" class="headerlink" title="3-1. Internal 特定の通信においてInternal LBで負荷分散されない"></a>3-1. Internal 特定の通信においてInternal LBで負荷分散されない</h3><h4 id="原因-9"><a href="#原因-9" class="headerlink" title="原因"></a>原因</h4><p>コネクションを貼って通信していたため。<br>Internal LBでセッションアフィニティをOFFにしてもコネクション貼って通信するものはコネクション貼ったバックエンドに流れる仕様であった。</p><p>※参考<br><a href="https://cloud.google.com/load-balancing/docs/backend-service?hl=ja&amp;_ga=2.47555939.-570213192.1545967516" target="_blank" rel="noopener">https://cloud.google.com/load-balancing/docs/backend-service?hl=ja&amp;_ga=2.47555939.-570213192.1545967516</a><br><a href="https://cloud.google.com/compute/docs/reference/rest/v1/backendServices?hl=ja" target="_blank" rel="noopener">https://cloud.google.com/compute/docs/reference/rest/v1/backendServices?hl=ja</a></p><h4 id="対応-12"><a href="#対応-12" class="headerlink" title="対応"></a>対応</h4><p>クライアント側で定期的にコネクションを貼りなおすようにした。<br>大量のクライアントがいる処理であれば正常時はコネクションを貼る時点で後ろのノードは分散されれるので問題ないですが、ノード障害で別ノードとコネクション貼ってしまうとノード復旧時に再度振り分けられなくなってしまうのを回避するためです。</p><h3 id="3-2-Internal-LBのヘルスチェックが通らない"><a href="#3-2-Internal-LBのヘルスチェックが通らない" class="headerlink" title="3-2. Internal LBのヘルスチェックが通らない"></a>3-2. Internal LBのヘルスチェックが通らない</h3><h4 id="原因-10"><a href="#原因-10" class="headerlink" title="原因"></a>原因</h4><p>Internal LBのヘルスチェックが「130.211.0.0/22」と「35.191.0.0/16」 内のアドレスから送信されるため。<br>これらの接続を許可するようにFirewall Ruleを設定する必要があった。</p><h4 id="対応-13"><a href="#対応-13" class="headerlink" title="対応"></a>対応</h4><p>ヘルスチェックの通信元のIPに対して通信を許可するようにファイアウォールルールを追加しました。</p><h2 id="4-GCPプロジェクト"><a href="#4-GCPプロジェクト" class="headerlink" title="4. GCPプロジェクト"></a>4. GCPプロジェクト</h2><h3 id="4-1-新規に環境構築できない"><a href="#4-1-新規に環境構築できない" class="headerlink" title="4-1. 新規に環境構築できない"></a>4-1. 新規に環境構築できない</h3><h4 id="原因-11"><a href="#原因-11" class="headerlink" title="原因"></a>原因</h4><p>課金プロジェクトの作成数に限りがあったため</p><h4 id="対応-14"><a href="#対応-14" class="headerlink" title="対応"></a>対応</h4><p>サポートに連絡して上限を上げてもらった。<br>コア数の上限同様に事前に確認すべきでした。</p><h3 id="4-2-プロジェクトID-名を指定してリソースにアクセスできない。"><a href="#4-2-プロジェクトID-名を指定してリソースにアクセスできない。" class="headerlink" title="4-2. プロジェクトID/名を指定してリソースにアクセスできない。"></a>4-2. プロジェクトID/名を指定してリソースにアクセスできない。</h3><h4 id="原因-12"><a href="#原因-12" class="headerlink" title="原因"></a>原因</h4><p>プロジェクトID＝プロジェクト名を前提としてリソースにアクセスしていたが、プロジェクトIDとプロジェクト名が異なっていた。</p><h4 id="対応-15"><a href="#対応-15" class="headerlink" title="対応"></a>対応</h4><p>プロジェクトIDとプロジェクト名を同じに変更しました。<br>特に制約が無ければ同じにしておいた方がハマりどころ減ります。</p><h3 id="4-3-突然CloudSQLやGKEにアクセスできなくなった。"><a href="#4-3-突然CloudSQLやGKEにアクセスできなくなった。" class="headerlink" title="4-3. 突然CloudSQLやGKEにアクセスできなくなった。"></a>4-3. 突然CloudSQLやGKEにアクセスできなくなった。</h3><h4 id="原因-13"><a href="#原因-13" class="headerlink" title="原因"></a>原因</h4><p>アカウントが有効なクレジットと紐付いていなかった(!!!)。<br>最初は無料利用枠で動いてしまうため、構築して数日後に発覚した。</p><h4 id="対応-16"><a href="#対応-16" class="headerlink" title="対応"></a>対応</h4><p>アカウントを有効なクレジットと紐付けた。<br>プロジェクト構築時のオペレーションとして手順化した。</p><h2 id="5-踏み台"><a href="#5-踏み台" class="headerlink" title="5. 踏み台"></a>5. 踏み台</h2><h3 id="5-1-踏み台サーバにsshで接続できない"><a href="#5-1-踏み台サーバにsshで接続できない" class="headerlink" title="5-1. 踏み台サーバにsshで接続できない"></a>5-1. 踏み台サーバにsshで接続できない</h3><h4 id="原因-14"><a href="#原因-14" class="headerlink" title="原因"></a>原因</h4><p>IAMの権限不足。<br>「編集者」をベースとしたカスタム権限を作成していたが、GCEのログイン権限が継承されていなかった。</p><h4 id="対応-17"><a href="#対応-17" class="headerlink" title="対応"></a>対応</h4><p>IAMに「編集者」を直接付与する形式に変更。<br>アクセスするメンバーが限られていたため、カスタム権限で細かく制御は不要と判断しました。</p><h3 id="5-2-どの環境の踏み台サーバで作業しているか分からない"><a href="#5-2-どの環境の踏み台サーバで作業しているか分からない" class="headerlink" title="5-2. どの環境の踏み台サーバで作業しているか分からない"></a>5-2. どの環境の踏み台サーバで作業しているか分からない</h3><h4 id="原因-15"><a href="#原因-15" class="headerlink" title="原因"></a>原因</h4><p>踏み台サーバのインスタンス名が全ての環境（productionとかstagingとか）で同一のため。<br>CloudShellだとURL部分にPJ名が出るので判断可能であるがsshのターミナルツールによっては判別できない。</p><h4 id="対応-18"><a href="#対応-18" class="headerlink" title="対応"></a>対応</h4><p>踏み台にはインスタンス名に環境名を付与した。<br>命名規約上他のインスタンスに対して環境名を付けないとしても、実際にログインして作業することが多い踏み台だけは付けてあげた方が優しいです。</p><h2 id="6-その他"><a href="#6-その他" class="headerlink" title="6. その他"></a>6. その他</h2><h3 id="6-1-共有VPC設定ができない"><a href="#6-1-共有VPC設定ができない" class="headerlink" title="6-1. 共有VPC設定ができない"></a>6-1. 共有VPC設定ができない</h3><h4 id="原因-16"><a href="#原因-16" class="headerlink" title="原因"></a>原因</h4><p>共有VPCを設定するためには「共有 VPC 管理者」権限が必要であったが権限がなかった。<br><a href="https://cloud.google.com/vpc/docs/provisioning-shared-vpc#nominating_shared_vpc_admins_for_the_organization" target="_blank" rel="noopener">https://cloud.google.com/vpc/docs/provisioning-shared-vpc#nominating_shared_vpc_admins_for_the_organization</a><br>更には「共有 VPC 管理者」を付与するために「組織管理者」権限が必要であるが、構築メンバーが誰も権限を持っていなかった。</p><h4 id="対応-19"><a href="#対応-19" class="headerlink" title="対応"></a>対応</h4><p>「組織管理者」権限は契約者しか権限持っていなかったため依頼して操作ユーザに対して「組織管理者」権限を付与し、その上で「共有 VPC 管理者」を付与しました。</p><h3 id="6-2-特定アプリケーションのインストールができない"><a href="#6-2-特定アプリケーションのインストールができない" class="headerlink" title="6-2. 特定アプリケーションのインストールができない"></a>6-2. 特定アプリケーションのインストールができない</h3><h4 id="原因-17"><a href="#原因-17" class="headerlink" title="原因"></a>原因</h4><p>外部サイトへアクティベーションが必要であったが外部IPが無く接続できなかったため。</p><h4 id="対応-20"><a href="#対応-20" class="headerlink" title="対応"></a>対応</h4><p>一時的に外部IPを付与してインストールを行った。<br>※前述のCloudNAT導入前だったためこのような対応しています。<br>※CloudNAT導入後であれば問題なく出来たと思われます。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>ここまでお疲れ様でした。<br>忙しい人向けに、全体通してのまとめです。</p><ul><li>全体的にネットワーク、権限周りがハマりどころ多かった。</li><li>GKEは共有VPC、ネットワークの制約によるハマりどころが多かった。</li><li>逆にこの辺りがすんなりいけば簡単に環境作れる感じがした。</li><li>GCP、ネットワーク知識いらないって聞いてた（自分だけ？）けど結構必要。</li><li>オンプレ環境と密な構成は難易度が跳ね上がる。</li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。その中でもDXチームは特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;はじめまして。TIG DXチーム&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnot
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="GCP" scheme="https://future-architect.github.io/tags/GCP/"/>
    
  </entry>
  
  <entry>
    <title>はじめてのTerraform 0.12 ～実践編～</title>
    <link href="https://future-architect.github.io/articles/20190819/"/>
    <id>https://future-architect.github.io/articles/20190819/</id>
    <published>2019-08-18T22:32:16.000Z</published>
    <updated>2019-08-19T02:25:21.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちはー<br>TIG DXチーム<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>のゆるふわエンジニアの前原です。</p><p>前回の<a href="https://future-architect.github.io/articles/20190816/">はじめてのTerraform 0.12 ～環境構築～</a>に続き実践編です。実際の構築を通して、最近バージョンアップしたTerraform 0.12の構文がこんな感じで変わったよー的な話を伝えていければと思っています。</p><p>では、Terraformを用いてAWSのリソースを作成していきましょう。</p><h1 id="構築する環境構成図"><a href="#構築する環境構成図" class="headerlink" title="構築する環境構成図"></a>構築する環境構成図</h1><p>下図の環境(VPC, VPC Endpoint, NAT Gatewayなど)をTerraformで構築していきます。</p><img src="/images/20190819/photo_20190819_01.jpeg"><ul><li>VPC</li></ul><p>VPCは、Staging（stg）とProduction（prd）に二つのVPCを構成します。AZ（Availability Zone）は3つのゾーンを利用し、サブネットはパブリックとプライベートに分けて構成します。</p><ul><li>VPC Endpoint</li></ul><p>Endpointとして、S3をセットします。</p><ul><li>NAT Gateway</li></ul><p>パブリックプライベートにNAT Gatewayを構築します。コストを抑えるために1台とします。</p><h1 id="Terraformのディレクトリ構成"><a href="#Terraformのディレクトリ構成" class="headerlink" title="Terraformのディレクトリ構成"></a>Terraformのディレクトリ構成</h1><p>最終的に以下のディレクトリ構成になります。前回の記事でお伝えしたように、1つのディレクトリにtfファイルを配置する設計にします。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── backend.tf  // 前回の記事で説明</span><br><span class="line">├── provider.tf // 同上 </span><br><span class="line">├── versions.tf // 同上</span><br><span class="line">|</span><br><span class="line">├── eip.tf</span><br><span class="line">├── igw.tf</span><br><span class="line">├── nat_gateway.tf</span><br><span class="line">├── route.tf</span><br><span class="line">├── route_association.tf</span><br><span class="line">├── route_table.tf</span><br><span class="line">├── subnet.tf</span><br><span class="line">├── variable.tf</span><br><span class="line">├── vpc.tf</span><br><span class="line">└── vpc_endpoint.tf</span><br></pre></td></tr></table></figure><h1 id="VPCの構築"><a href="#VPCの構築" class="headerlink" title="VPCの構築"></a>VPCの構築</h1><p>ここでは前回の記事で作成した<code>backend.tf</code>など以外のtfファイルを作成します。<br>基本的にリソース単位でファイルを分けておりますが、好みでひとまとめにしても問題ありません。</p><h2 id="VPCリソースの定義"><a href="#VPCリソースの定義" class="headerlink" title="VPCリソースの定義"></a>VPCリソースの定義</h2><p>VPCを構築するためのVPCリソースを定義します。<br>このリソースで必須の項目は、<code>cidr_block</code>のみですが、タグを付与したいため記述します。</p><figure class="highlight bash"><figcaption><span>vpc.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_vpc"</span> <span class="string">"vpc"</span> &#123;</span><br><span class="line">  cidr_block = local.vpc_cidr[terraform.workspace]</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>vpc.tf</code>は、ローカル変数を呼び出しているので、以下のように<code>variable.tf</code>に定義する必要があります。<br>また、<code>variable.tf</code>は、変数を定義するため今後も追記していきますので、これが最終的な内容でありませんのでご注意ください。</p><figure class="highlight bash"><figcaption><span>variable.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">  project_name = <span class="string">"example"</span></span><br><span class="line"></span><br><span class="line">  vpc_cidr = &#123;</span><br><span class="line">    stg = <span class="string">"10.0.0.0/16"</span></span><br><span class="line">    prd = <span class="string">"10.1.0.0/16"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>準備ができたのでTerraformを実行します。<br>が、実行する前に構文や設定に問題がないかを確認するためのコマンドを実行します。</p><h3 id="terraform-validate"><a href="#terraform-validate" class="headerlink" title="terraform validate"></a>terraform validate</h3><p>構文に問題ないかを<code>validate</code>コマンドで確認します。<br>問題なければ<code>Success</code>と出力されます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform validate</span><br><span class="line">Success! The configuration is valid.</span><br></pre></td></tr></table></figure><h3 id="terraform-fmt"><a href="#terraform-fmt" class="headerlink" title="terraform fmt"></a>terraform fmt</h3><p>次に<code>terraform fmt</code>というインデントなどのスタイルを揃えるコマンドを実行します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform fmt</span><br></pre></td></tr></table></figure><h3 id="terraform-plan"><a href="#terraform-plan" class="headerlink" title="terraform plan"></a>terraform plan</h3><p>それでは、設定に問題ないかを確認します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">$ terraform plan</span><br><span class="line">Refreshing Terraform state <span class="keyword">in</span>-memory prior to plan...</span><br><span class="line">The refreshed state will be used to calculate this plan, but will not be</span><br><span class="line">persisted to <span class="built_in">local</span> or remote state storage.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">An execution plan has been generated and is shown below.</span><br><span class="line">Resource actions are indicated with the following symbols:</span><br><span class="line">  + create</span><br><span class="line"></span><br><span class="line">Terraform will perform the following actions:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># aws_vpc.vpc will be created</span></span><br><span class="line">  + resource <span class="string">"aws_vpc"</span> <span class="string">"vpc"</span> &#123;</span><br><span class="line">      + arn                              = (known after apply)</span><br><span class="line">      + assign_generated_ipv6_cidr_block = <span class="literal">false</span></span><br><span class="line">      + cidr_block                       = <span class="string">"10.0.0.0/16"</span></span><br><span class="line">      + default_network_acl_id           = (known after apply)</span><br><span class="line">      + default_route_table_id           = (known after apply)</span><br><span class="line">      + default_security_group_id        = (known after apply)</span><br><span class="line">      + dhcp_options_id                  = (known after apply)</span><br><span class="line">      + enable_classiclink               = (known after apply)</span><br><span class="line">      + enable_classiclink_dns_support   = (known after apply)</span><br><span class="line">      + enable_dns_hostnames             = (known after apply)</span><br><span class="line">      + enable_dns_support               = <span class="literal">true</span></span><br><span class="line">      + id                               = (known after apply)</span><br><span class="line">      + instance_tenancy                 = <span class="string">"default"</span></span><br><span class="line">      + ipv6_association_id              = (known after apply)</span><br><span class="line">      + ipv6_cidr_block                  = (known after apply)</span><br><span class="line">      + main_route_table_id              = (known after apply)</span><br><span class="line">      + owner_id                         = (known after apply)</span><br><span class="line">      + tags                             = &#123;</span><br><span class="line">          + <span class="string">"Env"</span>     = <span class="string">"stg"</span></span><br><span class="line">          + <span class="string">"Name"</span>    = <span class="string">"stg-example"</span></span><br><span class="line">          + <span class="string">"Project"</span> = <span class="string">"example"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">Plan: 1 to add, 0 to change, 0 to destroy.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">Note: You didn<span class="string">'t specify an "-out" parameter to save this plan, so Terraform</span></span><br><span class="line"><span class="string">can'</span>t guarantee that exactly these actions will be performed <span class="keyword">if</span></span><br><span class="line"><span class="string">"terraform apply"</span> is subsequently run.</span><br></pre></td></tr></table></figure><h3 id="terraform-apply"><a href="#terraform-apply" class="headerlink" title="terraform apply"></a>terraform apply</h3><p>最後に<code>apply</code>を実行し、<code>Apply complete!</code>と出力されたら完了です。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ terraform apply</span><br><span class="line"><span class="comment">### 以下の質問が出力されるので`yes`を入力</span></span><br><span class="line">  Enter a value: yes</span><br><span class="line">aws_vpc.vpc: Creating...</span><br><span class="line">aws_vpc.vpc: Creation complete after 9s [id=vpc-0f1c8121f72d84ee9]</span><br><span class="line"></span><br><span class="line">Apply complete! Resources: 1 added, 0 changed, 0 destroyed.</span><br></pre></td></tr></table></figure><h2 id="ちょっとした解説①"><a href="#ちょっとした解説①" class="headerlink" title="ちょっとした解説①"></a>ちょっとした解説①</h2><p>ここでは上記で説明できていない部分について解説します。</p><h3 id="Workspace"><a href="#Workspace" class="headerlink" title="Workspace"></a>Workspace</h3><p><code>vpc.tf</code>で記述されていた<code>${terraform.workspace}</code>についてですが、これはWorkspaceの環境名を割り当てるための変数です。<br>そのため、今回の実行結果を見るとタグに指定した値に<code>stg</code>と入っていることがわかります。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### terraform apply結果の抜粋</span></span><br><span class="line">      + tags                             = &#123;</span><br><span class="line">          + <span class="string">"Env"</span>     = <span class="string">"stg"</span></span><br><span class="line">          + <span class="string">"Name"</span>    = <span class="string">"stg-example"</span></span><br><span class="line">          + <span class="string">"Project"</span> = <span class="string">"example"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>また、<code>cidr_block</code>には、<code>10.0.0.0/24</code>のネットワークアドレスが入っていることがわかります。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ cidr_block                       = <span class="string">"10.0.0.0/16"</span></span><br></pre></td></tr></table></figure><p>これは、Workspaceによって値が変わる部分のため、以下のように二つ定義をしています。<br>そのため、<code>vpc.tf</code>で呼び出すときは、<code>terraform.workspace</code>を利用します。</p><figure class="highlight bash"><figcaption><span>variable.tf（抜粋）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">  project_name = <span class="string">"example"</span></span><br><span class="line"></span><br><span class="line">  vpc_cidr = &#123;</span><br><span class="line">    stg = <span class="string">"10.0.0.0/16"</span></span><br><span class="line">    prd = <span class="string">"10.1.0.0/16"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Local変数"><a href="#Local変数" class="headerlink" title="Local変数"></a>Local変数</h3><p>タグの<code>project</code>には、<code>example</code>という文字列が入っております。<br>これは、<code>variable.tf</code>で定義したローカル変数が割り当てられています。</p><figure class="highlight bash"><figcaption><span>vpc.tf（抜粋）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Project = local.project_name</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>variable.tf（抜粋）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">  project_name = <span class="string">"example"</span></span><br></pre></td></tr></table></figure><p>ネットで調べているとVariable変数を使うケースをよく見かけることがあるかと思います。<br>しかし、個人的には、変数の組み込みやコマンド時の変数挿入などを防ぐことができるため、<code>Local変数</code>を利用しています。</p><h1 id="SubnetやNAT-Gatewayなどの構築"><a href="#SubnetやNAT-Gatewayなどの構築" class="headerlink" title="SubnetやNAT Gatewayなどの構築"></a>SubnetやNAT Gatewayなどの構築</h1><p>続いて、残りのリソースも作成していきます</p><h2 id="Subnet"><a href="#Subnet" class="headerlink" title="Subnet"></a>Subnet</h2><p>パブリックサブネットとプライベートサブネットを合計で6つ作成します。<br>以下のtfファイルを作成します。</p><figure class="highlight bash"><figcaption><span>subnet.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_subnet"</span> <span class="string">"public_subnet"</span> &#123;</span><br><span class="line">  for_each          = local.subnet_numbers</span><br><span class="line">  vpc_id            = aws_vpc.vpc.id</span><br><span class="line">  availability_zone = each.key</span><br><span class="line">  cidr_block        = cidrsubnet(aws_vpc.vpc.cidr_block, 8, each.value)</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>-private"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_subnet"</span> <span class="string">"private_subnet"</span> &#123;</span><br><span class="line">  for_each          = local.subnet_numbers</span><br><span class="line">  vpc_id            = aws_vpc.vpc.id</span><br><span class="line">  availability_zone = each.key</span><br><span class="line">  cidr_block        = cidrsubnet(aws_vpc.vpc.cidr_block, 8, each.value + 3)</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>-private"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Internet-Gatewayとルートテーブル"><a href="#Internet-Gatewayとルートテーブル" class="headerlink" title="Internet Gatewayとルートテーブル"></a>Internet Gatewayとルートテーブル</h2><p>Internet Gatewayを作成します。</p><figure class="highlight bash"><figcaption><span>igw.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_internet_gateway"</span> <span class="string">"igw"</span> &#123;</span><br><span class="line">  vpc_id = aws_vpc.vpc.id</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ルートテーブルを作成します。</p><figure class="highlight bash"><figcaption><span>route_table.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_route_table"</span> <span class="string">"public"</span> &#123;</span><br><span class="line">  vpc_id = aws_vpc.vpc.id</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>-public"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_route_table"</span> <span class="string">"private"</span> &#123;</span><br><span class="line">  vpc_id = aws_vpc.vpc.id</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>-private"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>パブリックサブネットとプライベートサブネットをルートテーブルに紐付けます。</p><figure class="highlight bash"><figcaption><span>route_association.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_route_table_association"</span> <span class="string">"public"</span> &#123;</span><br><span class="line">  for_each       = local.subnet_numbers</span><br><span class="line">  subnet_id      = aws_subnet.public_subnet[each.key].id</span><br><span class="line">  route_table_id = aws_route_table.public.id</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_route_table_association"</span> <span class="string">"private"</span> &#123;</span><br><span class="line">  for_each       = local.subnet_numbers</span><br><span class="line">  subnet_id      = aws_subnet.private_subnet[each.key].id</span><br><span class="line">  route_table_id = aws_route_table.private.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ルーティングを定義します。</p><ul><li>パブリックサブネットから<code>0.0.0.0/0</code>にアクセスする場合は、<code>Internet Gatewat</code>への向き先を指定</li><li>プライベートサブネットから<code>0.0.0.0/0</code>にアクセスする場合は、<code>NAT Gatewat</code>への向き先を指定</li></ul><figure class="highlight bash"><figcaption><span>route.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_route"</span> <span class="string">"public"</span> &#123;</span><br><span class="line">  route_table_id         = aws_route_table.public.id</span><br><span class="line">  gateway_id             = aws_internet_gateway.igw.id</span><br><span class="line">  destination_cidr_block = <span class="string">"0.0.0.0/0"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_route"</span> <span class="string">"private"</span> &#123;</span><br><span class="line">  route_table_id         = aws_route_table.private.id</span><br><span class="line">  gateway_id             = aws_nat_gateway.nat_gateway.id</span><br><span class="line">  destination_cidr_block = <span class="string">"0.0.0.0/0"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="NAT-Gateway"><a href="#NAT-Gateway" class="headerlink" title="NAT Gateway"></a>NAT Gateway</h3><p>パブリックサブネットに<code>NAT Gateway</code>を１台構築します。<br>NAT Gatewayは、固定グローバルIPをアタッチする必要があるので<code>EIP</code>を作成します。<br>また、各サブネットに対してのルートテーブルも定義します。</p><figure class="highlight bash"><figcaption><span>nat_gateway.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_nat_gateway"</span> <span class="string">"nat_gateway"</span> &#123;</span><br><span class="line">  allocation_id = aws_eip.nat_gateway.id</span><br><span class="line">  subnet_id     = aws_subnet.public_subnet[<span class="string">"ap-southeast-2a"</span>].id</span><br><span class="line">  depends_on    = [aws_internet_gateway.igw]</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>eip.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_eip"</span> <span class="string">"nat_gateway"</span> &#123;</span><br><span class="line">  vpc        = <span class="literal">true</span></span><br><span class="line">  depends_on = [aws_internet_gateway.igw]</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>-nat"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="S3-Endpoint"><a href="#S3-Endpoint" class="headerlink" title="S3 Endpoint"></a>S3 Endpoint</h2><p>S3 Endpointを作成します。</p><figure class="highlight bash"><figcaption><span>vpc_endpoint.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_vpc_endpoint"</span> <span class="string">"s3"</span> &#123;</span><br><span class="line">  vpc_id       = aws_vpc.vpc.id</span><br><span class="line">  service_name = <span class="string">"com.amazonaws.<span class="variable">$&#123;local.region&#125;</span>.s3"</span></span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>-s3"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = local.project_name</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_vpc_endpoint_route_table_association"</span> <span class="string">"private_s3"</span> &#123;</span><br><span class="line">  vpc_endpoint_id = aws_vpc_endpoint.s3.id</span><br><span class="line">  route_table_id  = aws_route_table.private.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>現在利用しているリージョンをデータリソースから取得し、ローカル変数で定義しています。</p><figure class="highlight bash"><figcaption><span>variable（抜粋）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data <span class="string">"aws_region"</span> <span class="string">"current"</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">locals &#123;</span><br><span class="line">  region       = data.aws_region.current.name</span><br></pre></td></tr></table></figure><h2 id="ちょっとした解説②"><a href="#ちょっとした解説②" class="headerlink" title="ちょっとした解説②"></a>ちょっとした解説②</h2><h3 id="リソースの参照"><a href="#リソースの参照" class="headerlink" title="リソースの参照"></a>リソースの参照</h3><p>以下は、先ほど作成したvpcの<code>id</code>を取得するための構文です。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vpc_id            = aws_vpc.vpc.id</span><br></pre></td></tr></table></figure><h3 id="cidrsubnet"><a href="#cidrsubnet" class="headerlink" title="cidrsubnet"></a>cidrsubnet</h3><p>本記事のサブネットは、以下のレンジで作成しています。</p><ul><li>Public Subnetework<ul><li>10.0.0.0/24</li><li>10.0.1.0/24</li><li>10.0.2.0/24</li></ul></li><li>Private subnetwork<ul><li>10.0.3.0/24</li><li>10.0.4.0/24</li><li>10.0.5.0/24</li></ul></li></ul><p>そこで役に立つのが、<a href="https://www.terraform.io/docs/configuration/functions/cidrsubnet.html" target="_blank" rel="noopener">cidrsubnet Function</a>です。<br><code>cidrsubnet</code>は、以下のように3つの引数を持つ関数で、IPレンジをいい感じに分割してくれます。</p><blockquote><p>cidrsubnet(prefix, newbits, netnum)</p></blockquote><p>今回のケースで、値を割り当てると以下のかたちになります。</p><ul><li>prefix: 10.0.0.0/16</li><li>newbits: 8</li><li>netnum: 0（ここはcountでインクリメントされる）</li></ul><p>具体的にどう変換されるかを<code>terraform console</code>で確認してみます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ terraform console</span><br><span class="line">&gt; cidrsubnet(<span class="string">"10.0.0.0/16"</span>, 8, 0)</span><br><span class="line">10.0.0.0/24</span><br><span class="line">&gt; cidrsubnet(<span class="string">"10.0.0.0/16"</span>, 8, 1)</span><br><span class="line">10.0.1.0/24</span><br></pre></td></tr></table></figure><p>このようにサブネットの結果が不安な場合は、<code>terraform console</code>を利用すると捗ります。</p><h3 id="depends-on"><a href="#depends-on" class="headerlink" title="depends_on"></a>depends_on</h3><p>NAT GatewayとEIPは、Internet Gatewayに依存しています。<br>そこで、<code>depends_on</code>を記述することで明示的に依存関係を記すことで、先にInternet Gatewayを構築し、その後にEIPとNAT Gatewayを構築するという流れを確立できます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">depends_on = [aws_internet_gateway.igw]</span><br></pre></td></tr></table></figure><h1 id="Production-環境の構築"><a href="#Production-環境の構築" class="headerlink" title="Production 環境の構築"></a>Production 環境の構築</h1><p>コードの変更は不要です。<br>Workspaceの<code>prd</code>に切り替えて<code>terraform apply</code>するだけです。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ terraform workspace selece prd</span><br><span class="line">$ terraform plan</span><br><span class="line">$ terraform apply</span><br></pre></td></tr></table></figure><p>めっちゃ簡単ですね！</p><p>ここまででVPCの構築が完了しました。</p><h1 id="最終的なVariable-tf"><a href="#最終的なVariable-tf" class="headerlink" title="最終的なVariable.tf"></a>最終的なVariable.tf</h1><p>本記事で作成した<code>variable.tf</code>です。</p><figure class="highlight bash"><figcaption><span>variable.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">data <span class="string">"aws_region"</span> <span class="string">"current"</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">locals &#123;</span><br><span class="line">  project_name = <span class="string">"example"</span></span><br><span class="line">  region       = data.aws_region.current.name</span><br><span class="line"></span><br><span class="line">  vpc_cidr = &#123;</span><br><span class="line">    stg = <span class="string">"10.0.0.0/16"</span></span><br><span class="line">    prd = <span class="string">"10.1.0.0/16"</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  subnet_numbers = &#123;</span><br><span class="line">    <span class="string">"ap-southeast-2a"</span> = 0</span><br><span class="line">    <span class="string">"ap-southeast-2b"</span> = 1</span><br><span class="line">    <span class="string">"ap-southeast-2c"</span> = 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Terraform-0-12-変更点"><a href="#Terraform-0-12-変更点" class="headerlink" title="Terraform 0.12 変更点"></a>Terraform 0.12 変更点</h1><p>この章では、Terraform 0.12とそれ以前での変更点をまとめていきます。</p><h3 id="面倒だったブロックが不要になったよ"><a href="#面倒だったブロックが不要になったよ" class="headerlink" title="面倒だったブロックが不要になったよ"></a>面倒だったブロックが不要になったよ</h3><p>ブロックやダブルクォーテーション（<code>&quot;${}&quot;</code>）で囲う必要がなくなりました。<br>ただし、変数同士を繋いで表現する場合（NameやEnv）は、囲う必要があります（tagの部分）</p><h3 id="Terraform-0-11系"><a href="#Terraform-0-11系" class="headerlink" title="Terraform 0.11系"></a>Terraform 0.11系</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_vpc"</span> <span class="string">"vpc"</span> &#123;</span><br><span class="line">  cidr_block = <span class="string">"<span class="variable">$&#123;local.vpc_cidr[terraform.workspace]&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = <span class="string">"<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Terraform-0-12系"><a href="#Terraform-0-12系" class="headerlink" title="Terraform 0.12系"></a>Terraform 0.12系</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_vpc"</span> <span class="string">"vpc"</span> &#123;</span><br><span class="line">  cidr_block = local.vpc_cidr[terraform.workspace]</span><br><span class="line"></span><br><span class="line">  tags = &#123;</span><br><span class="line">    Name    = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>-<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">    Env     = <span class="string">"<span class="variable">$&#123;terraform.workspace&#125;</span>"</span></span><br><span class="line">    Project = <span class="string">"<span class="variable">$&#123;local.project_name&#125;</span>"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="無口なValidateが返信してくれるようになった"><a href="#無口なValidateが返信してくれるようになった" class="headerlink" title="無口なValidateが返信してくれるようになった"></a>無口なValidateが返信してくれるようになった</h3><p><code>terraform validate</code>を実行すると<code>Success!</code>って、反応が返ってくるようになりました。</p><h4 id="Terraform-0-11系-1"><a href="#Terraform-0-11系-1" class="headerlink" title="Terraform 0.11系"></a>Terraform 0.11系</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform validate</span><br></pre></td></tr></table></figure><h4 id="Terraform-0-12系-1"><a href="#Terraform-0-12系-1" class="headerlink" title="Terraform 0.12系"></a>Terraform 0.12系</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform validate</span><br><span class="line">Success! The configuration is valid.</span><br></pre></td></tr></table></figure><h3 id="Planなどの実行結果がわかりやすくなった"><a href="#Planなどの実行結果がわかりやすくなった" class="headerlink" title="Planなどの実行結果がわかりやすくなった"></a>Planなどの実行結果がわかりやすくなった</h3><p>劇的な変化はないですが、見やすくなりました。</p><h4 id="Terraform-0-11系-2"><a href="#Terraform-0-11系-2" class="headerlink" title="Terraform 0.11系"></a>Terraform 0.11系</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ terraform plan</span><br><span class="line">  + create</span><br><span class="line"></span><br><span class="line">Terraform will perform the following actions:</span><br><span class="line"></span><br><span class="line">  + aws_vpc.vpc</span><br><span class="line">      id:                               &lt;computed&gt;</span><br><span class="line">      arn:                              &lt;computed&gt;</span><br><span class="line">      assign_generated_ipv6_cidr_block: <span class="string">"false"</span></span><br><span class="line">      cidr_block:                       <span class="string">"10.0.0.0/24"</span></span><br><span class="line">      default_network_acl_id:           &lt;computed&gt;</span><br><span class="line">      default_route_table_id:           &lt;computed&gt;</span><br><span class="line">      default_security_group_id:        &lt;computed&gt;</span><br><span class="line">      dhcp_options_id:                  &lt;computed&gt;</span><br><span class="line">      enable_classiclink:               &lt;computed&gt;</span><br><span class="line">      enable_classiclink_dns_support:   &lt;computed&gt;</span><br><span class="line">      enable_dns_hostnames:             &lt;computed&gt;</span><br><span class="line">      enable_dns_support:               <span class="string">"true"</span></span><br><span class="line">      instance_tenancy:                 <span class="string">"default"</span></span><br><span class="line">      ipv6_association_id:              &lt;computed&gt;</span><br><span class="line">      ipv6_cidr_block:                  &lt;computed&gt;</span><br><span class="line">      main_route_table_id:              &lt;computed&gt;</span><br><span class="line">      owner_id:                         &lt;computed&gt;</span><br><span class="line">      tags.%:                           <span class="string">"3"</span></span><br><span class="line">      tags.Env:                         <span class="string">"stg"</span></span><br><span class="line">      tags.Name:                        <span class="string">"stg-example"</span></span><br><span class="line">      tags.Project:                     <span class="string">"example"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Plan: 1 to add, 0 to change, 0 to destroy.</span><br></pre></td></tr></table></figure><h4 id="Terraform-0-12系-2"><a href="#Terraform-0-12系-2" class="headerlink" title="Terraform 0.12系"></a>Terraform 0.12系</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ terraform plan</span><br><span class="line">  + create</span><br><span class="line"></span><br><span class="line">Terraform will perform the following actions:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># aws_vpc.vpc will be created</span></span><br><span class="line">  + resource <span class="string">"aws_vpc"</span> <span class="string">"vpc"</span> &#123;</span><br><span class="line">      + arn                              = (known after apply)</span><br><span class="line">      + assign_generated_ipv6_cidr_block = <span class="literal">false</span></span><br><span class="line">      + cidr_block                       = <span class="string">"10.0.0.0/24"</span></span><br><span class="line">      + default_network_acl_id           = (known after apply)</span><br><span class="line">      + default_route_table_id           = (known after apply)</span><br><span class="line">      + default_security_group_id        = (known after apply)</span><br><span class="line">      + dhcp_options_id                  = (known after apply)</span><br><span class="line">      + enable_classiclink               = (known after apply)</span><br><span class="line">      + enable_classiclink_dns_support   = (known after apply)</span><br><span class="line">      + enable_dns_hostnames             = (known after apply)</span><br><span class="line">      + enable_dns_support               = <span class="literal">true</span></span><br><span class="line">      + id                               = (known after apply)</span><br><span class="line">      + instance_tenancy                 = <span class="string">"default"</span></span><br><span class="line">      + ipv6_association_id              = (known after apply)</span><br><span class="line">      + ipv6_cidr_block                  = (known after apply)</span><br><span class="line">      + main_route_table_id              = (known after apply)</span><br><span class="line">      + owner_id                         = (known after apply)</span><br><span class="line">      + tags                             = &#123;</span><br><span class="line">          + <span class="string">"Env"</span>     = <span class="string">"stg"</span></span><br><span class="line">          + <span class="string">"Name"</span>    = <span class="string">"stg-example"</span></span><br><span class="line">          + <span class="string">"Project"</span> = <span class="string">"example"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">Plan: 1 to add, 0 to change, 0 to destroy.</span><br></pre></td></tr></table></figure><h2 id="for-eachの導入"><a href="#for-eachの導入" class="headerlink" title="for_eachの導入"></a>for_eachの導入</h2><p><code>for_each</code>が使えるようになりました！<br>これは個人的には革新的で今まで抱えていた問題を解決する一つの武器となると思っています。</p><h3 id="Terraform-0-11系-3"><a href="#Terraform-0-11系-3" class="headerlink" title="Terraform 0.11系"></a>Terraform 0.11系</h3><p>サブネットを作成するときに以下のように<code>count</code>を利用するケースがありました。</p><figure class="highlight bash"><figcaption><span>sample_subnet.tf（抜粋）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data <span class="string">"aws_availability_zones"</span> <span class="string">"available"</span> &#123;</span><br><span class="line">  state = <span class="string">"available"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_subnet"</span> <span class="string">"public_subnet"</span> &#123;</span><br><span class="line">  count             = 3</span><br><span class="line">  vpc_id            = aws_vpc.vpc.id</span><br><span class="line">  availability_zone = <span class="string">"<span class="variable">$&#123;data.aws_availability_zones.available.names[count.index]&#125;</span>"</span></span><br><span class="line">  cidr_block        = cidrsubnet(aws_vpc.vpc.cidr_block, 8, count.index + 0)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一見問題ないように見えるのですが、<code>count</code>を利用しているため、数字をインクリメントしてリストが作成されていきます。<br>その結果、リストの変更などでインデックスがずれてしまう問題が発生する可能性がありました。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># aws_subnet.public_subnet[0] will be created</span><br></pre></td></tr></table></figure><h3 id="Terraform-0-12系-3"><a href="#Terraform-0-12系-3" class="headerlink" title="Terraform 0.12系"></a>Terraform 0.12系</h3><p><code>0.12.6</code>から<code>for_each</code>をマップ形式でアクセスできるようになりました。<br>以下のように<code>for_each</code>で定義し、<code>each.key</code>と<code>each.value</code>で各要素にアクセスできます。</p><figure class="highlight bash"><figcaption><span>subnet.tf（抜粋）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">resource <span class="string">"aws_subnet"</span> <span class="string">"public_subnet"</span> &#123;</span><br><span class="line">  for_each          = local.subnet_numbers</span><br><span class="line">  vpc_id            = aws_vpc.vpc.id</span><br><span class="line">  availability_zone = each.key</span><br><span class="line">  cidr_block        = cidrsubnet(aws_vpc.vpc.cidr_block, 8, each.value)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_subnet"</span> <span class="string">"private_subnet"</span> &#123;</span><br><span class="line">  for_each          = local.subnet_numbers</span><br><span class="line">  vpc_id            = aws_vpc.vpc.id</span><br><span class="line">  availability_zone = each.key</span><br><span class="line">  cidr_block        = cidrsubnet(aws_vpc.vpc.cidr_block, 8, each.value + 3)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>for_each</code>で参照する定義をvariable.tfに追記します。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">subnet_numbers = &#123;</span><br><span class="line">  &quot;ap-southeast-2a&quot; = 1</span><br><span class="line">  &quot;ap-southeast-2b&quot; = 2</span><br><span class="line">  &quot;ap-southeast-2c&quot; = 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>NAT Gateway</code>のように一つのサブネットに作成したい場合などに役立ちます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subnet_id     = aws_subnet.public_subnet[&quot;ap-southeast-2a&quot;].id</span><br></pre></td></tr></table></figure><p>ちなみに、<code>0.12.6</code>より古いバージョンで<code>terraform validate</code>を実行するとエラーが発生します。</p><figure class="highlight bash"><figcaption><span>Error（terrform0.12.5実行結果）</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Error: Reserved argument name <span class="keyword">in</span> resource block</span><br><span class="line"></span><br><span class="line">  on subnet.tf line 2, <span class="keyword">in</span> resource <span class="string">"aws_subnet"</span> <span class="string">"public_subnet"</span>:</span><br><span class="line">   2:   for_each          = local.subnet_numbers</span><br><span class="line"></span><br><span class="line">The name <span class="string">"for_each"</span> is reserved <span class="keyword">for</span> use <span class="keyword">in</span> a future version of Terraform.</span><br></pre></td></tr></table></figure><h2 id="lookupについて"><a href="#lookupについて" class="headerlink" title="lookupについて"></a>lookupについて</h2><p>今回の構成では、お伝えすることができなかったのですが、Terraform 0.12からlookupの書き方が変わったので変更点を以下に記載します。</p><h3 id="Terraform-0-11系-4"><a href="#Terraform-0-11系-4" class="headerlink" title="Terraform 0.11系"></a>Terraform 0.11系</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">instance_type               = <span class="string">"<span class="variable">$&#123;lookup(local.ec2_config[terraform.workspace], "instance_type")&#125;</span>"</span></span><br></pre></td></tr></table></figure><h3 id="Terraform-0-12系-4"><a href="#Terraform-0-12系-4" class="headerlink" title="Terraform 0.12系"></a>Terraform 0.12系</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">instance_type               = local.ec2_config[terraform.workspace][<span class="string">"instance_type"</span>]</span><br></pre></td></tr></table></figure><h1 id="Terraform-0-11-14からアップグレードする方法"><a href="#Terraform-0-11-14からアップグレードする方法" class="headerlink" title="Terraform 0.11.14からアップグレードする方法"></a>Terraform 0.11.14からアップグレードする方法</h1><p>ここからは、すでにTerraform0.11系を利用している方のために、ざっくりですが0.12にアップグレードする方法を記載します。</p><h2 id="Terraform-アップグレード"><a href="#Terraform-アップグレード" class="headerlink" title="Terraform アップグレード"></a>Terraform アップグレード</h2><p>Terraform 0.11.14でinitを実行します<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform init</span><br></pre></td></tr></table></figure><p>Workspaceを切り替えます（Workspace環境を前提にしています。）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform workspace list</span><br><span class="line">$ terraform workspace select stg</span><br></pre></td></tr></table></figure><p><code>terraform plan</code>を実行します。<br>もし、planを実行し、差分が発生した場合はTerraform 0.12に対応した構文に変更する必要があります。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform plan</span><br></pre></td></tr></table></figure><p><code>checklistコマンド</code>を実行し、アップグレード可能な状態かを確認します。<br>問題がなければ<code>Looks good!</code>と出力されます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ terraform_0.11 0.12checklist</span><br><span class="line">Looks good! We did not detect any problems that ought to be</span><br><span class="line">addressed before upgrading to Terraform v0.12.</span><br><span class="line"></span><br><span class="line">This tool is not perfect though, so please check the v0.12 upgrade</span><br><span class="line">guide <span class="keyword">for</span> additional guidance, and <span class="keyword">for</span> next steps:</span><br><span class="line">    https://www.terraform.io/upgrade-guides/0-12.html</span><br></pre></td></tr></table></figure><p>terraformのバージョンを0.12に変更し、initを実行します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform init</span><br></pre></td></tr></table></figure><p><code>upgradeコマンド</code>を実行します。<br>問題がなければ<code>Upgrade complete!</code>と出力されます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform 0.12upgrade</span><br><span class="line">Upgrade complete!</span><br></pre></td></tr></table></figure><p><code>plan</code>を実行し、問題が発生しなければアップグレード完了です。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terrafrom plan</span><br></pre></td></tr></table></figure><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>いかがでしたか？</p><p>Terraform 0.12になったことで、構文が変わって戸惑う場面もあるかと思いますが、それ以上に恩恵を授かれることを少しでも感じ取ってもらえたのではないでしょうか。また、これを機にTerraformを触ってみたいぞ！って方が増えたら嬉しいです。</p><p>今回は、VPCの話しかできなかったので、次回は更にこの環境を大きくしていき、皆さんのお役に立てる記事を書いていきたいと思います。</p><p>ありがとうございました！</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.terraform.io/upgrade-guides/0-12.html" target="_blank" rel="noopener">Upgrading to Terraform v0.12</a><br><a href="https://www.terraform.io/docs/configuration/resources.html#for_each-multiple-resource-instances-defined-by-a-map-or-set-of-strings" target="_blank" rel="noopener">Resouces</a><br><a href="https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each" target="_blank" rel="noopener">Terraform 0.12 Preview</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。その中でもDXチームは特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">Terraformを0.12にアップグレードする場合は、<code>0.11.14</code>まで上げる必要があります。</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちはー&lt;br&gt;TIG DXチーム&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;foot
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="AWS" scheme="https://future-architect.github.io/tags/AWS/"/>
    
      <category term="Terraform" scheme="https://future-architect.github.io/tags/Terraform/"/>
    
  </entry>
  
  <entry>
    <title>はじめてのTerraform 0.12 ～環境構築～</title>
    <link href="https://future-architect.github.io/articles/20190816/"/>
    <id>https://future-architect.github.io/articles/20190816/</id>
    <published>2019-08-16T03:43:21.000Z</published>
    <updated>2019-08-18T22:35:23.081Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちはー<br>TIG DXチーム<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>のゆるふわエンジニアの前原です。</p><p>最近は、プラットフォームを新規で構築するプロジェクトや、既存の環境を運用改善していくプロジェクトに従事しています。その中で私はクラウドインフラ部分を担当しており、アーキテクチャデザインや、Terraform・Ansible・Packerといった構成管理ツールを利用したAWSやGCP環境の構築をしています。</p><p>本記事では、最近バージョンアップしたTerraform 0.12の構文がこんな感じで変わったよー的な話を伝えていきます。</p><p>大きくは以下の流れで進めます。</p><ol><li>Terraformの事始め (今回の記事です)</li><li>Terraform 0.12でVPCを構築する （<a href="https://future-architect.github.io/articles/20190819/">次回の記事</a>で説明します！）</li></ol><p>これからTerraformを触っていきたいといった方にもわかるように書いていきます。<br>そのため少し長めの内容になってしまいますが、お付き合いください。</p><h1 id="Terraformとは"><a href="#Terraformとは" class="headerlink" title="Terraformとは"></a>Terraformとは</h1><p><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>は、<a href="https://www.hashicorp.com/" target="_blank" rel="noopener">HashiCorp</a>によって開発された構成管理ツールで、主にクラウド環境（クラウド以外でも利用可能）を構築するときに利用します。</p><p>Terraformなどのツールを利用しない場合は、ブラウザを通してGUIから構築するケースがあるかと思います。その場合は、作業ミスをなくすために設定手順書やパラメータシートを元に構築するかとおもいますが、規模が大きくなったり関わる人が多くなってくると、人による設定ミスなどが発生することも多いのでは無いでしょうか。ミスを回避するために、各種施策やドキュメントの陳腐化を防ぐ方法に時間を費やすことも多々あるでしょう。</p><p>そういったケースにTerraformのような構成管理ツールを利用することで、インフラの構成をコードに落とし込み、状態を定義することができるようになります。</p><p>これにより誰が実行しても結果が同じになることで、ミスを低減することが可能です。また、コードを見ることで常にインフラの最新状態を把握することができます。また、コード化しているため、Gitなどのバージョン管理システムで管理することもできます。</p><p>…と、ここまでメリットについて書きましたが、いざTerraformを使用するとそれなりに学習コストが必要となります。</p><h1 id="Terraformの事始め"><a href="#Terraformの事始め" class="headerlink" title="Terraformの事始め"></a>Terraformの事始め</h1><p>ここでは、Terraformを実行するための環境をつくります。</p><h2 id="環境"><a href="#環境" class="headerlink" title="環境"></a>環境</h2><p>Terraformを体験するために以下の環境で行います。</p><ul><li><code>AWS</code></li><li><code>Terraform: 0.12.6</code> &amp; <code>0.11.14</code></li><li><code>tfenv: 1.0.1</code></li><li><code>MacBook Pro Mojave</code> or <code>Windows10 64bit</code></li></ul><h2 id="Terraformのインストール"><a href="#Terraformのインストール" class="headerlink" title="Terraformのインストール"></a>Terraformのインストール</h2><p>Terraformのインストールを行います。</p><h3 id="MacOSの場合"><a href="#MacOSの場合" class="headerlink" title="MacOSの場合"></a>MacOSの場合</h3><p>Terraformの実行環境を準備します。<br>今回は、バージョンの切り替えを楽にしてくれる<a href="https://github.com/tfutils/tfenv" target="_blank" rel="noopener">tfenv</a>を利用します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Install tfenv</span></span><br><span class="line">$ brew install tfenv</span><br><span class="line">$ tfenv -v</span><br><span class="line">tfenv 1.0.1</span><br></pre></td></tr></table></figure><p>tfenvでterraformをインストールし、使用可能なバージョンを確認します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tfenv install latest</span><br><span class="line">$ tfenv install 0.11.14</span><br><span class="line">$ tfenv list</span><br><span class="line">* 0.12.6 (<span class="built_in">set</span> by /usr/<span class="built_in">local</span>/Cellar/tfenv/1.0.1/version)</span><br><span class="line">  0.11.14</span><br></pre></td></tr></table></figure><p>バージョンの切り替えは、<code>use</code>を利用することで簡単に切り替えることができます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ tfenv use 0.11.14</span><br><span class="line">[INFO] Switching to v0.11.14</span><br><span class="line">[INFO] Switching completed</span><br></pre></td></tr></table></figure><p>tfenvを使用しない場合は、<a href="https://learn.hashicorp.com/terraform/getting-started/install.html" target="_blank" rel="noopener">こちら</a>のサイトを確認してください。</p><h3 id="Windowsの場合"><a href="#Windowsの場合" class="headerlink" title="Windowsの場合"></a>Windowsの場合</h3><p>Terraformを<a href="https://www.terraform.io/downloads.html" target="_blank" rel="noopener">ダウンロード</a>します。<br>ダウンロードしたファイルを解凍し、<code>C:¥Windows</code>配下に<code>terraform.exe</code>を配置します。<br>コマンドプロントもしくはお使いのターミナルを開き、以下のコマンドを発行します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform version</span><br><span class="line">Terraform v0.12.6</span><br></pre></td></tr></table></figure><p>ここでは試しておりませんが、Windowsもtfenv（only git-bash）に対応しているので興味のある方は試して頂ければと思います。  </p><ul><li>GitHub: <a href="https://github.com/tfutils/tfenv" target="_blank" rel="noopener">tfenv</a></li></ul><h2 id="Terraform-を実行するまでにやること"><a href="#Terraform-を実行するまでにやること" class="headerlink" title="Terraform を実行するまでにやること"></a>Terraform を実行するまでにやること</h2><h3 id="環境変数の設定"><a href="#環境変数の設定" class="headerlink" title="環境変数の設定"></a>環境変数の設定</h3><p>AWSのAPIを発行するために必要な設定です。<br>AWSのIAM Userであらかじめユーザを作成し、アクセスキーとシークレットキーを環境変数にセットします。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MacOSの場合</span></span><br><span class="line">$ <span class="built_in">export</span> AWS_ACCESS_KEY_ID=xxx</span><br><span class="line">$ <span class="built_in">export</span> AWS_SECRET_ACCESS_KEY=xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windowsの場合</span></span><br><span class="line">$ <span class="built_in">set</span> AWS_ACCESS_KEY_ID=xxx</span><br><span class="line">$ <span class="built_in">set</span> AWS_SECRET_ACCESS_KEY=xxx</span><br></pre></td></tr></table></figure><p>MacOSの場合に限りますが、複数のAWSアカウント扱っている場合は、<a href="https://direnv.net/" target="_blank" rel="noopener">direnv</a>を利用するとディレクトリ単位で環境変数を切り替えることができるため便利です。</p><p>もし、HTTP Proxy配下の環境で実行したい場合は以下のオプションも追加で設定ください。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MacOSの場合</span></span><br><span class="line"><span class="built_in">export</span> HTTPS_PROXY=https://proxy.example.com:443</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windowsの場合</span></span><br><span class="line"><span class="built_in">set</span> HTTPS_PROXY=https://proxy.example.com:443</span><br></pre></td></tr></table></figure><h3 id="tfstateファイルの管理について"><a href="#tfstateファイルの管理について" class="headerlink" title="tfstateファイルの管理について"></a>tfstateファイルの管理について</h3><p>tfstateファイルは、Terraformで管理しているインフラの状態を管理するためのファイルです。<br>このファイルは非常に大切です。</p><p>通常、tfstateファイルを保存する場所を指定しない場合は、Terraformを実行したディレクトリに保存されます。<br>そのため、複数人でTerraformを実行する環境や、可用性を意識するとローカルでの保存はイケてないです。</p><p>そこで、tfstateファイルを管理するためのS3 バケットを用意します。<br>（<a href="https://docs.aws.amazon.com/ja_jp/cli/latest/userguide/install-macos.html" target="_blank" rel="noopener">AWS CLI</a>が実行できることを前提とします）<br>また、バケットはバージョニングの設定をします。<br>バージョニングすることでtfstateファイルに予期せぬ更新や、壊してしまった時に戻せるようにするためです。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### バケットの作成</span></span><br><span class="line">$ aws s3 mb s3://example-bucket --region ap-southeast-2</span><br><span class="line"><span class="comment">### バージョニングの設定</span></span><br><span class="line">$ aws s3api put-bucket-versioning --bucket example-bucket --versioning-configuration Status=Enabled</span><br><span class="line"><span class="comment">### バージョニングの設定ができていることを確認します</span></span><br><span class="line">$ aws s3api get-bucket-versioning --bucket example-bucket</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"Status"</span>: <span class="string">"Enabled"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="リージョンの選択"><a href="#リージョンの選択" class="headerlink" title="リージョンの選択"></a>リージョンの選択</h3><p>リージョンは適切に選択してください。<br>もし学習用途であればバージニア（us-east-1）を利用することを個人的におすすめします。<br>理由は、単純に安いからです！</p><p>ただ、本記事は諸事情によりシドニーで構築しています（ap-southeast-2）</p><h2 id="Terraformのディレクトリ構成"><a href="#Terraformのディレクトリ構成" class="headerlink" title="Terraformのディレクトリ構成"></a>Terraformのディレクトリ構成</h2><p>以下のようなフラットなディレクトリ構成で、1つのディレクトリにtfファイルを配置する設計にします。</p><p>以下の3つのtfファイルについては、次章以降で説明します。</p><ul><li>backend.tf</li><li>provider.tf</li><li>versions.tf</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── backend.tf</span><br><span class="line">├── provider.tf</span><br><span class="line">├── versions.tf</span><br><span class="line">└── ...(次回の記事で説明します)</span><br></pre></td></tr></table></figure><h2 id="Backendの指定"><a href="#Backendの指定" class="headerlink" title="Backendの指定"></a>Backendの指定</h2><p>tfstateファイルをS3 バケットで管理するため、Backend用のtfファイルを作成します。<br>先ほどAWS CLIで作成したバケットを指定します。</p><figure class="highlight bash"><figcaption><span>backend.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">"s3"</span> &#123;</span><br><span class="line">    bucket = <span class="string">"example-bucket"</span></span><br><span class="line">    key    = <span class="string">"state/service"</span></span><br><span class="line">    region = <span class="string">"ap-southeast-2"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Providerの指定"><a href="#Providerの指定" class="headerlink" title="Providerの指定"></a>Providerの指定</h2><p>Terraformは、AWSだけでなく、GCP、Alibaba Cloudなど様々なプロバイダに対応しています。<br>今回は、AWSを利用するための定義をします。<br>また、リージョンを指定します。</p><figure class="highlight bash"><figcaption><span>provider.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">provider <span class="string">"aws"</span> &#123;</span><br><span class="line">  region = <span class="string">"ap-southeast-2"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Versions"><a href="#Versions" class="headerlink" title="Versions"></a>Versions</h3><p>このファイルはなくても問題ないのですが、Terraform 0.12から構文が変わっているため、明示的に記述します。<br>以下により<code>0.12</code>以上のバージョンでないと実行できないようになっています。<br>（Terraformのアップグレードコマンドで0.12にした場合は、自動で作成されます）</p><figure class="highlight bash"><figcaption><span>versions.tf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  required_version = <span class="string">"&gt;= 0.12"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Terraform-init"><a href="#Terraform-init" class="headerlink" title="Terraform init"></a>Terraform init</h2><p>準備が整ったので、Terraformを実行します。<br>まず、Terraformのワークスペースの初期化や、プラグインをダウンロードするために<code>terraform init</code>を実行します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform init</span><br></pre></td></tr></table></figure><p>問題がなければ以下のようなメッセージが出力されます。</p><blockquote><p>Terraform has been successfully initialized!</p></blockquote><p>仮に<code>0.11.14</code>で<code>terraform init</code>を実行すると以下の結果になります。</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> terraform init</span></span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">Backend configuration changed!</span><br><span class="line"></span><br><span class="line">Terraform has detected that the configuration specified for the backend</span><br><span class="line">has changed. Terraform will now check for existing state in the backends.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Successfully configured the backend "s3"! Terraform will automatically</span><br><span class="line">use this backend unless the backend configuration changes.</span><br><span class="line"></span><br><span class="line">Error: The currently running version of Terraform doesn't meet the</span><br><span class="line">version requirements explicitly specified by the configuration.</span><br><span class="line">Please use the required version or update the configuration.</span><br><span class="line">Note that version requirements are usually set for a reason, so</span><br><span class="line">we recommend verifying with whoever set the version requirements</span><br><span class="line">prior to making any manual changes.</span><br><span class="line"></span><br><span class="line">  Module: root</span><br><span class="line">  Required version: &gt;= 0.12</span><br><span class="line">  Current version: 0.11.14</span><br></pre></td></tr></table></figure><h2 id="Workspaces-の準備"><a href="#Workspaces-の準備" class="headerlink" title="Workspaces の準備"></a>Workspaces の準備</h2><p>本構成は、<code>stg</code>と<code>prd</code> の二つの環境を構築します。<br>stgはStaging(検証環境)、prdはProduction(本番環境)の略です。</p><p>Terraformでは、複数の環境を構築するにあたって便利な<code>Workkspace</code>があります。<br>Workspaceを使うことで、ディレクトリで環境を分けることなく、コード内で識別することが可能となります。</p><p>それでは、Workspaceコマンドで<code>stg</code>と<code>prd</code>を作成します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ terraform workspace new stg</span><br><span class="line">Created and switched to workspace <span class="string">"stg"</span>!</span><br><span class="line">$ terraform workspace new prd</span><br><span class="line">Created and switched to workspace <span class="string">"prd"</span>!</span><br></pre></td></tr></table></figure><p>現在のWorkspaceを確認します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform workspace show</span><br><span class="line">prd</span><br></pre></td></tr></table></figure><p>最後に作成した<code>prd</code>が対象になっているため、変更します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ terraform workspace select stg</span><br><span class="line">Switched to workspace <span class="string">"stg"</span>.</span><br><span class="line">$ terraform workspace show</span><br><span class="line">stg</span><br></pre></td></tr></table></figure><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>これで、いよいよTerraformで環境構築できる準備が整いました。<br>次回の記事では実際のAWSリソースのTerraform定義から、VPCを作成する手順を説明していきますのでお楽しみに！</p><ul><li><a href="https://future-architect.github.io/articles/20190819/">はじめてのTerraform 0.12 ～実践編～</a><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。その中でもDXチームは特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちはー&lt;br&gt;TIG DXチーム&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;foot
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="AWS" scheme="https://future-architect.github.io/tags/AWS/"/>
    
      <category term="Terraform" scheme="https://future-architect.github.io/tags/Terraform/"/>
    
  </entry>
  
  <entry>
    <title>WAFとして go-swagger を選択してみた</title>
    <link href="https://future-architect.github.io/articles/20190814/"/>
    <id>https://future-architect.github.io/articles/20190814/</id>
    <published>2019-08-14T01:30:07.000Z</published>
    <updated>2019-08-14T01:18:37.523Z</updated>
    
    <content type="html"><![CDATA[<p>こんにちは、TIG DXチーム<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>の多賀です。<br>2019年7月にキャリア入社しました。</p><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>Go のWebアプリケーションフレームワークを検討した際に、 <code>go-swagger</code> が良いのではと思い、比較調査してみました。</p><p>その結果、実際にPJへ導入しています。</p><h2 id="バージョン"><a href="#バージョン" class="headerlink" title="バージョン"></a>バージョン</h2><table><thead><tr><th align="left">名称</th><th align="left">バージョン</th></tr></thead><tbody><tr><td align="left">Go</td><td align="left">1.12.7</td></tr><tr><td align="left"><a href="https://github.com/go-swagger/go-swagger" target="_blank" rel="noopener">go-swagger</a></td><td align="left">v0.19.0</td></tr><tr><td align="left"><a href="https://github.com/swaggo/swag" target="_blank" rel="noopener">swaggo/swag</a></td><td align="left">v1.6.2</td></tr><tr><td align="left"><a href="https://github.com/OpenAPITools/openapi-generator" target="_blank" rel="noopener">openapi-generator</a></td><td align="left">4.0.3</td></tr><tr><td align="left"><a href="https://github.com/gin-gonic/gin" target="_blank" rel="noopener">gin</a></td><td align="left">v1.4.0</td></tr></tbody></table><h2 id="開発物"><a href="#開発物" class="headerlink" title="開発物"></a>開発物</h2><p>以下の実装を行うとします。<br>Web API を作成して、Swagger でドキュメントを管理しましょうというよくある構成かと思います。</p><table><thead><tr><th>項目</th><th>内容</th></tr></thead><tbody><tr><td>作成物</td><td>Web API</td></tr><tr><td>仕様定義</td><td>Swagger</td></tr><tr><td>言語</td><td>Go</td></tr><tr><td>仕様変更</td><td>高頻度</td></tr></tbody></table><h2 id="Go-のフレームワークに求めるもの"><a href="#Go-のフレームワークに求めるもの" class="headerlink" title="Go のフレームワークに求めるもの"></a>Go のフレームワークに求めるもの</h2><p>この場合、フレームワークに対して何を求めるでしょうか。<br>私は以下を重要視していました。</p><h3 id="重要視したこと"><a href="#重要視したこと" class="headerlink" title="重要視したこと"></a>重要視したこと</h3><p>ドキュメントと実装の乖離をなくすことで、認識齟齬なく開発を行うこと</p><h4 id="なぜ？"><a href="#なぜ？" class="headerlink" title="なぜ？"></a>なぜ？</h4><ol><li>ドキュメントと実装のズレを解消するコストが高いため<ul><li>Web API 開発をする中で最も困ることは <strong>ドキュメントと実装がかけ離れること</strong> です。ドキュメントととのずれによる、コミュニケーションを極力減らしたいと考えました</li></ul></li><li>インターフェイスが頻繁に変わることが想定されたため<ul><li>データ定義の部分が固く決まっていなかったため、データに引きずられて API 仕様の変更も頻繁に起きるだろうと思いました</li></ul></li><li>インターフェイスのやり取りの物理的な距離が遠いため<ul><li>同一の会社内だけでなく会社間をまたいだ開発も想定されたため、コミュニケーションコストがより高くなると想定しました</li></ul></li></ol><h2 id="フレームワーク比較"><a href="#フレームワーク比較" class="headerlink" title="フレームワーク比較"></a>フレームワーク比較</h2><p>ドキュメントと実装の整合性を重要視する考えのもと、下記 2 パターンの方式を検討しました。</p><ol><li>ドキュメントからコードを生成</li><li>コードからドキュメントを生成</li></ol><p>それぞれの方式についてサンプルを作りながら検討しました。<br>結果としては、<strong>1 のパターンのほうが重要視した要件を満たす</strong> と考えました。</p><h3 id="1-ドキュメントからコードを生成"><a href="#1-ドキュメントからコードを生成" class="headerlink" title="1. ドキュメントからコードを生成"></a>1. ドキュメントからコードを生成</h3><p>Swagger ファイルから Go のソースコードが生成できないかを考えました。<br>ライブラリとして、 <a href="https://github.com/go-swagger/go-swagger" target="_blank" rel="noopener">go-swagger</a> をあげています。</p><h4 id="go-swagger"><a href="#go-swagger" class="headerlink" title="go-swagger"></a><a href="https://github.com/go-swagger/go-swagger" target="_blank" rel="noopener">go-swagger</a></h4><p>Swaggerファイルを入力にGoのコードを生成することができるツールです。<br>生成されるコードは、<a href="https://github.com/go-openapi" target="_blank" rel="noopener">go-openapi</a> で管理されているモジュールが利用されています。</p><h4 id="サンプル"><a href="#サンプル" class="headerlink" title="サンプル"></a>サンプル</h4><p>swagger.yml (一部抜粋)</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">paths:</span></span><br><span class="line">  <span class="string">/data/&#123;name&#125;:</span></span><br><span class="line"><span class="attr">    post:</span></span><br><span class="line"><span class="attr">      operationId:</span> <span class="string">dataId</span></span><br><span class="line"><span class="attr">      consumes:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">application/json</span></span><br><span class="line"><span class="attr">      produces:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">application/json</span></span><br><span class="line"><span class="attr">      parameters:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">name</span></span><br><span class="line"><span class="attr">          in:</span> <span class="string">path</span></span><br><span class="line"><span class="attr">          required:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">データ名</span></span><br><span class="line"><span class="attr">          type:</span> <span class="string">string</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">body</span></span><br><span class="line"><span class="attr">          in:</span> <span class="string">body</span></span><br><span class="line"><span class="attr">          schema:</span></span><br><span class="line">            <span class="string">$ref:</span> <span class="string">"#/definitions/Sample"</span></span><br><span class="line"><span class="attr">      responses:</span></span><br><span class="line">        <span class="string">"200"</span><span class="string">:</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">OK</span></span><br><span class="line"><span class="attr">          schema:</span></span><br><span class="line">            <span class="string">$ref:</span> <span class="string">"#/definitions/ApiResponse"</span></span><br><span class="line">        <span class="string">"404"</span><span class="string">:</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">Data</span> <span class="string">Not</span> <span class="string">Found</span></span><br><span class="line">        <span class="string">"500"</span><span class="string">:</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">Internal</span> <span class="string">Server</span> <span class="string">Error</span></span><br></pre></td></tr></table></figure><p>生成コードを利用した handler</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">dataHandler</span><span class="params">(params operations.DataIDParams)</span> <span class="title">middleware</span>.<span class="title">Responder</span></span> &#123;</span><br><span class="line"><span class="comment">// リクエスト</span></span><br><span class="line"><span class="comment">// params にすべての情報が含まれている</span></span><br><span class="line">log.Println(params)</span><br><span class="line">log.Println(*params.Body)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ビジネスロジック層にリクエスト情報を渡す</span></span><br><span class="line">service := service.New()</span><br><span class="line"><span class="keyword">if</span> err := service.Save(params.Body); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="comment">// エラーの場合</span></span><br><span class="line"><span class="comment">// 500エラー返せる</span></span><br><span class="line"><span class="keyword">return</span> operations.NewDataIDInternalServerError()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// レスポンス</span></span><br><span class="line">dummyResponse := &amp;models.APIResponse&#123;</span><br><span class="line">Message: <span class="string">"OK"</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 200 レスポンス</span></span><br><span class="line"><span class="keyword">return</span> operations.NewDataIDOK().WithPayload(dummyResponse)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="メリット"><a href="#メリット" class="headerlink" title="メリット"></a>メリット</h4><ol><li>Swagger と実装が乖離することはない<ul><li>Swagger から自動生成でリクエスト/レスポンスの struct を吐き出します。自動生成部分も CI で必ず生成して build するようにすれば、漏れることはないです。</li></ul></li><li>go-swagger でリクエスト/レスポンスのオブジェクト型を 生成してくれるためロジックに集中できる<ul><li>リクエスト/レスポンスの型だけでなく、リクエストを受ける/レスポンスを返す実装も合わせて生成されます。そのため、実装者は生成されたコードから リクエストパラメータ struct を受け取る → レスポンス struct を生成 までを実装すればよいです</li></ul></li></ol><h4 id="デメリット"><a href="#デメリット" class="headerlink" title="デメリット"></a>デメリット</h4><ol><li>Swagger の定義を手で書く必要がある<ul><li>Swagger の yml 定義を手でメンテする必要がある点は、デメリットになるかと思います。</li></ul></li></ol><h3 id="2-コードからドキュメントを生成"><a href="#2-コードからドキュメントを生成" class="headerlink" title="2. コードからドキュメントを生成"></a>2. コードからドキュメントを生成</h3><p>実装コードを正として、ドキュメント(Swagger ファイル)を出せないかを考えました。<br>現状対応しているライブラリとしては、<a href="https://github.com/swaggo/swag" target="_blank" rel="noopener">swaggo/swag</a> があげられました。</p><h4 id="swaggo-swag"><a href="#swaggo-swag" class="headerlink" title="swaggo/swag"></a><a href="https://github.com/swaggo/swag" target="_blank" rel="noopener">swaggo/swag</a></h4><p>Go のソースコードを静的解析して、Swagger ドキュメントを生成してくれるツールです。<br>以下のフレームワークとの連携をサポートしています。</p><ul><li><a href="https://github.com/gin-gonic/gin" target="_blank" rel="noopener">gin</a></li><li><a href="https://github.com/labstack/echo" target="_blank" rel="noopener">echo</a></li><li><a href="https://github.com/gobuffalo/buffalo" target="_blank" rel="noopener">buffalo</a></li><li><a href="https://golang.org/pkg/net/http/" target="_blank" rel="noopener">net/http</a></li></ul><h4 id="サンプル-1"><a href="#サンプル-1" class="headerlink" title="サンプル"></a>サンプル</h4><p>gin を利用したパターンの handler サンプルコードです。<br>Swagger ファイルは自動生成されるため割愛します。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataHandler godoc</span></span><br><span class="line"><span class="comment">// @Summary Show a account</span></span><br><span class="line"><span class="comment">// @Description get string by ID</span></span><br><span class="line"><span class="comment">// @ID dataId</span></span><br><span class="line"><span class="comment">// @Accept  json</span></span><br><span class="line"><span class="comment">// @Produce  json</span></span><br><span class="line"><span class="comment">// @Param name path string true "data name"</span></span><br><span class="line"><span class="comment">// @Param id body int true "id"</span></span><br><span class="line"><span class="comment">// @Param info body string false "info"</span></span><br><span class="line"><span class="comment">// @Success 200 &#123;object&#125; APIResponse</span></span><br><span class="line"><span class="comment">// @Failure 400 &#123;object&#125; APIResponse</span></span><br><span class="line"><span class="comment">// @Failure 500 &#123;object&#125; APIResponse</span></span><br><span class="line"><span class="comment">// @Router /data/&#123;name&#125; [post]</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DataHandler</span><span class="params">(c *gin.Context)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> params DataRequestParams</span><br><span class="line"><span class="keyword">if</span> err := c.ShouldBindJSON(&amp;params); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    c.JSON(http.StatusBadRequest, &amp;APIResponse&#123;Message: <span class="string">"Error"</span>&#125;)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">service := service.New()</span><br><span class="line"><span class="keyword">if</span> err := service.Save(params.Body); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    c.JSON(http.StatusInternalServerError, &amp;APIResponse&#123;Message: <span class="string">"Error"</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">res := APIResponse&#123;Message: <span class="string">"OK"</span>&#125;</span><br><span class="line">c.JSON(http.StatusOK, &amp;res)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="メリット-1"><a href="#メリット-1" class="headerlink" title="メリット"></a>メリット</h4><ol><li>コードが正になり、コードの修正がドキュメントに反映される</li><li>コードのコメントで Swagger の仕様定義を実施できる</li><li>Swagger ファイル生成時に、コードのコメントのバリデーションを一部実行してくれる</li><li>有力フレームワークの機能をそのまま活用できる</li></ol><h4 id="デメリット-1"><a href="#デメリット-1" class="headerlink" title="デメリット"></a>デメリット</h4><ol><li>仕様定義漏れを目見でチェックする必要がある<ul><li>コメントの解析をベースに、Swagger 生成をしていますが、定義が漏れている場合にエラーになりませんでした。(パラメータの記載漏れ、レスポンスのステータスコード漏れ 等確認しました。) そのため、実装とコメントが乖離していないかは目見で確認しないといけませんでした。コメントの量も多く、目見での確認には漏れが出ることが想像されました。</li></ul></li><li>コメント+実装ベースのため Swagger との連携度が低い</li></ol><h3 id="補足-コード生成系フレームワーク比較"><a href="#補足-コード生成系フレームワーク比較" class="headerlink" title="補足: コード生成系フレームワーク比較"></a>補足: コード生成系フレームワーク比較</h3><p>実際、go-swagger 以外にも Swagger -&gt; コード生成ツールは存在します。<br>ですが、<a href="https://github.com/OpenAPITools/openapi-generator" target="_blank" rel="noopener">openapi-generator</a> での生成コードは現状はまだ、運用に耐えるレベルではない考えます。</p><p>特に、Handlerとリクエスト/レスポンスの型定義がマッチされたコードが生成されない点が辛いです。<br>せっかくコード生成したのに、各 API ごとにドキュメントと見比べながらモデルを紐付けるのはいまいちだと思いました。<br>(生成コードが薄いことは良かったですが、紐付けを固くする選択をしました。)</p><p>比較表</p><table><thead><tr><th align="left">対象</th><th align="left">評価</th><th align="left">メリット</th><th align="left">デメリット</th></tr></thead><tbody><tr><td align="left">go-swagger</td><td align="left">o</td><td align="left">- リクエスト/レスポンスの型が定まる <br><br>- リクエストを受け取る/レスポンスを返す 部分を意識しなくて良い <br><br> - リクエストパラメータのバリデーションを自動で実行 <br><br>- 編集不要ファイルは DO NOT EDIT コメントがついている<br><br> - デフォルトで未実装エラーが出る Handler が登録される</td><td align="left">- 自動生成だけでは API 受け付けられない (configure_xxx.go 内の修正が必須) <br><br>- Router 周りのコードが長い</td></tr><tr><td align="left">openapi generator (net/http)</td><td align="left">x</td><td align="left">- 生成コード量が少なく明瞭</td><td align="left">- 非編集ファイルが明確にされていない <br><br>- リクエスト/レスポンスの型定義が Handler に紐付いていない</td></tr><tr><td align="left">openapi generator (gin)</td><td align="left">x</td><td align="left">- 生成コード量が少なく明瞭</td><td align="left">- 非編集ファイルが明確にされていない <br><br>- リクエスト/レスポンスの型定義が Handler に紐付いていない</td></tr></tbody></table><h4 id="openapi-generator-サンプル-gin-version"><a href="#openapi-generator-サンプル-gin-version" class="headerlink" title="openapi-generator サンプル (gin version)"></a>openapi-generator サンプル (gin version)</h4><details><summary>サンプルコード</summary><div>swagger.yml (一部抜粋)<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">paths:</span></span><br><span class="line">  <span class="string">"/data/&#123;name&#125;"</span><span class="string">:</span></span><br><span class="line"><span class="attr">    post:</span></span><br><span class="line"><span class="attr">      operationId:</span> <span class="string">dataId</span></span><br><span class="line"><span class="attr">      parameters:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">name</span></span><br><span class="line"><span class="attr">          in:</span> <span class="string">path</span></span><br><span class="line"><span class="attr">          required:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">データ名</span></span><br><span class="line"><span class="attr">          schema:</span></span><br><span class="line"><span class="attr">            type:</span> <span class="string">string</span></span><br><span class="line"><span class="attr">      requestBody:</span></span><br><span class="line"><span class="attr">        content:</span></span><br><span class="line">          <span class="string">application/json:</span></span><br><span class="line"><span class="attr">            schema:</span></span><br><span class="line">              <span class="string">$ref:</span> <span class="string">"#/components/schemas/Sample"</span></span><br><span class="line"><span class="attr">      responses:</span></span><br><span class="line">        <span class="string">"200"</span><span class="string">:</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">OK</span></span><br><span class="line"><span class="attr">          content:</span></span><br><span class="line">            <span class="string">application/json:</span></span><br><span class="line"><span class="attr">              schema:</span></span><br><span class="line">                <span class="string">$ref:</span> <span class="string">"#/components/schemas/ApiResponse"</span></span><br><span class="line">        <span class="string">"404"</span><span class="string">:</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">Data</span> <span class="string">Not</span> <span class="string">Found</span></span><br><span class="line">        <span class="string">"500"</span><span class="string">:</span></span><br><span class="line"><span class="attr">          description:</span> <span class="string">Internal</span> <span class="string">Server</span> <span class="string">Error</span></span><br></pre></td></tr></table></figure><p>handler</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataId -</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DataId</span><span class="params">(c *gin.Context)</span></span> &#123;</span><br><span class="line">  c.JSON(http.StatusOK, gin.H&#123;&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>model</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ApiResponse <span class="keyword">struct</span> &#123;</span><br><span class="line">  Message <span class="keyword">string</span> <span class="string">`json:"message,omitempty"`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>(handler に model が紐付いていないことが伝わればよいかと思います)</p></div></details><h2 id="所感"><a href="#所感" class="headerlink" title="所感"></a>所感</h2><p>複数のフレームワークを比較検討してみました。</p><p>ドキュメントベースで開発して、コミュニケーションコストを下げたい目的があれば、<code>go-swagger</code> の利用はおすすめできると思います。<br>開発進めてみて知見が溜まってきたら、また公開していきます。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。その中でもDXチームは特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;こんにちは、TIG DXチーム&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;の多賀です。&lt;br&gt;2019年7月にキャリア入社しました。&lt;/p&gt;
&lt;h2 id=&quot;概要&quot;&gt;&lt;a href=&quot;#概要&quot; cl
      
    
    </summary>
    
      <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
      <category term="Go" scheme="https://future-architect.github.io/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>Google Cloud Next &#39;19 in Tokyo Day3 セッションレポート</title>
    <link href="https://future-architect.github.io/articles/20190809/"/>
    <id>https://future-architect.github.io/articles/20190809/</id>
    <published>2019-08-08T23:29:54.000Z</published>
    <updated>2019-08-08T23:54:38.736Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは、TIG DXチームの統合思念体です。<a href="https://cloud.withgoogle.com/next/tokyo/" target="_blank" rel="noopener">Google Cloud Next ’19 in Tokyo Day3</a>に少し顔を出していたので参加レポートをお送りします。</p><ul><li><a href="https://future-architect.github.io/articles/20190804/">Day2 の参加レポート</a>はこちらです。</li></ul><h1 id="Google-Cloud-Next-’19-in-Tokyoとは"><a href="#Google-Cloud-Next-’19-in-Tokyoとは" class="headerlink" title="Google Cloud Next ’19 in Tokyoとは"></a>Google Cloud Next ’19 in Tokyoとは</h1><p>「かつてないクラウドを体験しよう」をテーマに、📍東京プリンスホテル, 📍ザ・プリンス パークタワー東京の2ヶ所で 7/30~8/1の3日間に渡ってクラウドの最新動向や、採用事例を学べるセッションが開催されるカンファレンスです。ハッシュタグは<code>#GoogleNext2019</code>。2019年は160ものセッションが開催され年々熱気が増しているように感じます。</p><h1 id="会場への道のり-amp-会場の様子"><a href="#会場への道のり-amp-会場の様子" class="headerlink" title="会場への道のり &amp; 会場の様子"></a>会場への道のり &amp; 会場の様子</h1><p>Day2に参加した私はすでに会場への道をマスターしており、道中で「これブログに使えるかな？」などと考えながら写真を撮る余裕がありました。<br><img src="/images/20190809/photo_20190809_01.jpeg"><br>↑行きしなに東京タワーをパシャリ。変わらずの炎天下でしたが会場着後は快適な空調のおかげで穏やかな気持ちでセッション聴講できました！<br><img src="/images/20190809/photo_20190809_02.jpeg"><br>↑こちらはEXPO会場のとある一角。バーコーナー的な感じでしょうか。写真ではお水のみですが、時間帯によってはお菓子も並んでいました。個人的には<code>揚一番</code>を陳列してくれていた点に全力で称賛を送りたいと思います!!（何個も食べてすいません…揚一番大好きです！！）</p><h1 id="セッションレポート"><a href="#セッションレポート" class="headerlink" title="セッションレポート"></a>セッションレポート</h1><p>さて、本題に入っていきましょう。Day3もコンテナオーケストレーションネタを主軸にいくつかのセッションに参加したのでレポートを書いていきます！</p><h2 id="☁ハイブリッド-マルチクラウド環境下における-Kubernetes-デザインの勘所-データ管理の視点から"><a href="#☁ハイブリッド-マルチクラウド環境下における-Kubernetes-デザインの勘所-データ管理の視点から" class="headerlink" title="☁ハイブリッド マルチクラウド環境下における Kubernetes デザインの勘所 - データ管理の視点から"></a>☁ハイブリッド マルチクラウド環境下における Kubernetes デザインの勘所 - データ管理の視点から</h2><blockquote><p>本セッションでは、なぜ Kubernetes クラスタがステートレスである必要があるか、アプリケーションから生成されるデータを保管する Kubernetes ストレージのデザインについて、ネットアップのソリューションを使用するとどのような課題を解決できるかをお話します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=327831-143299" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=327831-143299</a></p></blockquote><p>k8s、ハイブリッド・マルチクラウド、という単語に惹かれる形で参加を決定しました。コンテナを使うときに悩みどころのひとつとなる「ステートフルデータの取り扱い方法」について詳しく解説してくれたセッションでした。本セッションはランチセッションだったみたいなのですが、知らずにギリギリで会場イン。係員の方に「お弁当はもう無いです。」と言われ、「ああーー勿体ないことしたぁぁーー」と思いながら着席しました笑</p><p>セッションを通じて、k8sひいてはコンテナアプリケーションを扱う際に必ずつきまとう「ステートフルデータどうする問題」に詳しくなりました！クラウドであれば、コンテナはステートレスな状態としステートフルなものはマネージドサービスをフル活用する、というのがコンテナアプリケーション運用時のベストプラクティスと考えていましたが、アプリケーションレベルでの管理に私の意識が寄っていた気がします。ハイブリッド・マルチクラウドが進む世界においては、etcd含め、クラスタレベルでのステートという考えも大事であり、「コンテナを破棄可能な状態に保つ」だけでなく「クラスタを破棄可能な状態に保つ」ことも重要だなと改めて考えさせられました！</p><p>以下セッションメモです。</p><h3 id="複数のk8sクラスタを運用する際の課題"><a href="#複数のk8sクラスタを運用する際の課題" class="headerlink" title="複数のk8sクラスタを運用する際の課題"></a>複数のk8sクラスタを運用する際の課題</h3><ul><li>クラウドごと、あるいはオンプレでクラスタのオペレーションが微妙に異なる</li><li>複数クラスタをどうやって接続するか</li><li>ステートフルなデータをどういったストレージで管理するか（本日のメイントピック）</li></ul><h3 id="ハイブリッドクラウドの実現に向けて"><a href="#ハイブリッドクラウドの実現に向けて" class="headerlink" title="ハイブリッドクラウドの実現に向けて"></a>ハイブリッドクラウドの実現に向けて</h3><h4 id="オペレーションの統合"><a href="#オペレーションの統合" class="headerlink" title="オペレーションの統合"></a>オペレーションの統合</h4><ul><li>環境ごとにマネージド範囲が異なるので差異を吸収するレイヤが必要</li><li>統一的に操作できるAPIなどを定義した管理レイヤを設けるのが好ましい</li></ul><h4 id="k8sクラスタを破棄可能な状態にしておき、クラスタ移動に備える"><a href="#k8sクラスタを破棄可能な状態にしておき、クラスタ移動に備える" class="headerlink" title="k8sクラスタを破棄可能な状態にしておき、クラスタ移動に備える"></a>k8sクラスタを破棄可能な状態にしておき、クラスタ移動に備える</h4><ul><li>ワークロードにはステートフルとステートレスの2種類あるが、ステートフルワークロードの扱い方が重要</li><li>ステートフルデータがあると、クラスタの移動が容易にできなくなってしまうため</li><li>保存の仕方は主に以下3種<ul><li>マネージドのデータサービス</li><li>ユーザ管理データサービス</li><li>ブロック・ファイルストレージ</li></ul></li></ul><h3 id="コンテナにおけるステートとは？"><a href="#コンテナにおけるステートとは？" class="headerlink" title="コンテナにおけるステートとは？"></a>コンテナにおけるステートとは？</h3><p>システム稼働時に必要なデータあるいはコンテナ起動時に必要なデータがそれにあたる</p><h4 id="k8sにおけるステート"><a href="#k8sにおけるステート" class="headerlink" title="k8sにおけるステート"></a>k8sにおけるステート</h4><ul><li>ステートフルなものは、Podのライフサイクルとは異なるライフサイクルのもので、<code>PVC</code>や<code>PV</code>など</li><li>現実的にマニフェスト化できないもの（コードで管理が難しいもの）はSecretなど</li><li>ステートレスなものは、k8sのオブジェクトは基本ステートレス</li></ul><h4 id="k8sがステートを持たない利点"><a href="#k8sがステートを持たない利点" class="headerlink" title="k8sがステートを持たない利点"></a>k8sがステートを持たない利点</h4><ul><li>ステートを持つ場合は、有事の際に直す必要がでてくる<ul><li>アドホックだし時間がかかる</li></ul></li><li>ステートを持たなければ、再作成で復旧可能<ul><li>壊れても良い</li></ul></li></ul><h3 id="ではそのステートをどうやって管理するか？"><a href="#ではそのステートをどうやって管理するか？" class="headerlink" title="ではそのステートをどうやって管理するか？"></a>ではそのステートをどうやって管理するか？</h3><h4 id="データ永続化の領域"><a href="#データ永続化の領域" class="headerlink" title="データ永続化の領域"></a>データ永続化の領域</h4><ul><li>マネージドデータサービスとユーザ管理データサービス<ul><li>ベンダーロックイン的な話も出るが、大事なのはデータサービスの抽象化レイヤを配置し、入れ替え可能にしておくこと</li></ul></li><li>ブロック・ファイルストレージ<ul><li><code>Storage in k8s</code>と<code>Storage for k8s</code>。クラスタ上にデータを置くと、再作成など難しい</li></ul></li></ul><h4 id="CSIとは-Container-Storage-Interface-？"><a href="#CSIとは-Container-Storage-Interface-？" class="headerlink" title="CSIとは(Container Storage Interface)？"></a>CSIとは(Container Storage Interface)？</h4><ul><li>コンテナストレージの共通仕様</li><li>APIは共通化されているため、バックエンドを置き換え可能になる</li><li>ただし、CSI対応を謳っていても実装状況は違うので注意</li></ul><h3 id="ステートフルなデータの取り扱い"><a href="#ステートフルなデータの取り扱い" class="headerlink" title="ステートフルなデータの取り扱い"></a>ステートフルなデータの取り扱い</h3><p>Podが動いている間にうまれるデータ、およびetcdのデータがある</p><h4 id="etcdを保護するために"><a href="#etcdを保護するために" class="headerlink" title="etcdを保護するために"></a>etcdを保護するために</h4><ul><li>etcdは<code>クラスタのステート</code>と捉える場合と<code>クラスタのコンフィグレーション</code>と捉える場合でアプローチが異なる</li><li>クラスタのステートとして考える場合<ul><li>マネージドなクラスタの場合は、サービス提供側に任せるか、3rdパーティ製ツールを用いる</li><li>マネージドではないクラスタの場合は、自身で必ず保護し、バックアップのみならずそこからのリストアフローまでしっかり考えておく</li></ul></li><li>クラスタのコンフィグレーションとして考える場合<ul><li>GitOpsのような状態が理想</li><li>管理しているマニフェストを再実行で復旧状態にしておく</li><li>Secretをどのように考えるかが大事だが、例えばHashicorp Vaultを使うのは1つの解決策となりうる</li></ul></li></ul><h3 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h3><ul><li>微妙に違うk8sたちを統一的に管理することが必要</li><li>重要なのはクラスタを破棄可能にするためのステート管理方式の決定</li></ul><h2 id="☁Kubernetes-ソフトウェア-サプライチェーンにおけるエンドツーエンドのセキュリティ＆コンプライアンス"><a href="#☁Kubernetes-ソフトウェア-サプライチェーンにおけるエンドツーエンドのセキュリティ＆コンプライアンス" class="headerlink" title="☁Kubernetes ソフトウェア サプライチェーンにおけるエンドツーエンドのセキュリティ＆コンプライアンス"></a>☁Kubernetes ソフトウェア サプライチェーンにおけるエンドツーエンドのセキュリティ＆コンプライアンス</h2><blockquote><p>このセッションでは、コンテナがもたらす課題とメリットについて、ANZ のメンバーも参加して意見を交わします。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=302742-140857" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=302742-140857</a></p></blockquote><p>k8sにおけるセキュリティに興味があり参加を決めました！スピーカーの方が英語で話されるとのことで入り口では通訳レシーバーが配布されていましたが、良い機会だと思い私はレシーバーを受け取らずにセッション会場へ突入していきました。(わりとなんとかなります。みなさんもぜひチャレンジを！)</p><p>ANZ(オーストラリア・ニュージーランド銀行)さんの事例に合わせ、いかにセキュリティを高めるかがテーマのセッションでした。コンテナセキュリティという観点で登場したサービス・ソリューション群はDay2で聞いたものと一緒でしたが、その分洗練されたセキュリティサービスが提供されていると理解しました。緻密なセキュリティ対策が求められる銀行ビジネスの中で、セキュリティを高めつつクラウド・コンテナアプリケーションを導入していくかという話が興味深く、技術ネタそのものよりもそちらに耳を傾けてしまいました。</p><p>講演中に手元の端末を使ってDEMOを行う際は、スイッチャーの方に「画面切り替えお願いします」といった形でお願いするのですが、うまく切り替わった後に講演者の方がスマートに発した「Perfect」の一言が最高にCoolでかっこいいなとテンション上がってました！笑</p><p>以下、セッションメモです。</p><h3 id="Supply-Chain-Security"><a href="#Supply-Chain-Security" class="headerlink" title="Supply Chain Security"></a>Supply Chain Security</h3><ul><li>VM時代のサプライチェーンはToo Human Baseでした</li><li>マイクロサービスであるということは大量のデプロイを何度も行うということである</li><li>人力ではとても回らないので、CI/CDを適切に整えることが大切</li></ul><h3 id="ANZにおける事例"><a href="#ANZにおける事例" class="headerlink" title="ANZにおける事例"></a>ANZにおける事例</h3><ul><li>ANZ = オーストラリア・ニュージーランド銀行<ul><li>50thousand employees</li><li>10million customers</li></ul></li><li>New ways of workingを考えている</li><li>Fintechの流れもあり、techにも力を入れている<ul><li>Quick change &amp; Quick feedback</li></ul></li><li>素晴らしいエクスペリエンスは顧客の信頼の中で生まれる<ul><li>「Security is key to gain customers trust.」</li></ul></li></ul><h3 id="まとめ-1"><a href="#まとめ-1" class="headerlink" title="まとめ"></a>まとめ</h3><ul><li>Base image、Image scan、Binary AuthorizationなどのGCPセキュリティサービスを活用してコンテナアプリをセキュアに保つことが大事</li></ul><h2 id="☁Anthos-が変えるハイブリッドクラウドの形"><a href="#☁Anthos-が変えるハイブリッドクラウドの形" class="headerlink" title="☁Anthos が変えるハイブリッドクラウドの形"></a>☁Anthos が変えるハイブリッドクラウドの形</h2><blockquote><p>本セッションでは、Anthos が何を目指しているのか、何が実現できるのかというようなコンセプトから、Kubernetes、Istio などのコンポーネントに触れながら、これを利用することで何が変わるのか、技術者、ビジネス担当者それぞれの立場から見たメリットを合わせ、ご説明します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=297710-140796" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=297710-140796</a></p></blockquote><p>話題のAnthosのセッションなのでぜひ聞きたいと真っ先に参加申し込みをしたのがこのセッションです！やる気出しすぎて最前ど真ん中というベスポジ中のベスポジをゲットしつつ臨みました。</p><p>Anthosの具体的なアーキテクチャについての話というよりも、Anthosがどこに向かっているのかを聞けるセッションでした。本セッションで話していたことは、Anthosに閉じず、GCPがどこに向かおうとしているのか、も多分に含んでいるんだろうなーと感じています。OSSに対する強い思いも随所にあふれており、私の大好きなIstioの話も登場し、Google Cloud ソリューションアーキテクト長谷部さんの熱意あふれる大満足な40分間でした！</p><p>以下、セッションメモです。</p><h3 id="日本のエンタープライズITは変革が求められている"><a href="#日本のエンタープライズITは変革が求められている" class="headerlink" title="日本のエンタープライズITは変革が求められている"></a>日本のエンタープライズITは変革が求められている</h3><ul><li>開発手法・スキル・リソース配分・市場など様々な観点で変化があり、それに追従するためにも変革が求められている</li><li>その一つの解がAnthosであり、本セッションでは技術よりも、Anthosが向かう先を話す</li></ul><h3 id="Anthosが目指すもの"><a href="#Anthosが目指すもの" class="headerlink" title="Anthosが目指すもの"></a>Anthosが目指すもの</h3><h4 id="ハイブリッド＆マルチクラウド"><a href="#ハイブリッド＆マルチクラウド" class="headerlink" title="ハイブリッド＆マルチクラウド"></a>ハイブリッド＆マルチクラウド</h4><ul><li>既存リソースの有効活用<ul><li>すべてクラウドに移行しているのは稀。最近の調査では、クラウドからオンプレに戻そうとする動きもある</li></ul></li><li>レギュレーション・社内ポリシーの対応<ul><li>クラウドに置けないデータはオンプレにおくしかない</li></ul></li><li>マルチクラウド<ul><li>他社クラウドもサポート</li></ul></li></ul><h4 id="フルマネージド指向"><a href="#フルマネージド指向" class="headerlink" title="フルマネージド指向"></a>フルマネージド指向</h4><ul><li>デファクトとなりつつある3つのOSS、それらをマネージドサービスで提供する<ul><li>k8s –&gt; GKE</li><li>Istio –&gt; Istio on GKE</li><li>Knative –&gt; Cloud Run</li></ul></li><li>価値のある業務に集中する。プラットフォーム管理はGoogleが、開発者は価値のあるところにフォーカスしてほしい</li><li>マネージドサービスの提供領域についてはGoogleがテスト、監査を行う</li><li>あくまで元々のOSSに準拠し、魔改造はしない</li></ul><h4 id="オープンテクノロジー-with-Google"><a href="#オープンテクノロジー-with-Google" class="headerlink" title="オープンテクノロジー with Google"></a>オープンテクノロジー with Google</h4><ul><li>Goolgeはk8s・Knative・Istio・Tensorflowをはじめ2000を超えるOSSプロジェクトへ貢献してきた</li><li>昨今のクラウドベンダーとOSSベンダーとの衝突は悲しいものであり、GoogleはOSSを育ててきた企業だからこそ、OSS企業を大事にしたい</li><li>OSS各社と戦略的パートナーシップを結んだ</li></ul><h4 id="Anthosが支えたい世界"><a href="#Anthosが支えたい世界" class="headerlink" title="Anthosが支えたい世界"></a>Anthosが支えたい世界</h4><p>CEOの方々と話す機会があるが、「3年後のIT投資戦略をたてなきゃいけないがそれは可能か？」とよく聞かれる。変化が早く、見通せないのは前提。であれば、変化したらそれに柔軟に合わせられる状態になるような選択をするのが大事。しかし保守的すぎてもだめで、競争力をつけるためにk8sやIstioなどの最新のテクノロジーは使える状態であるべき。それらをマネージドサービスにて利用することで開発者は価値のある箇所に注力することができる。</p><h3 id="Anthosの構成要素"><a href="#Anthosの構成要素" class="headerlink" title="Anthosの構成要素"></a>Anthosの構成要素</h3><ul><li>Anthosはコンテナを基礎としている</li><li>コンテナの特徴は3点<ul><li>「ファイルサイズが小さい」・「アプリに必要なものがひとまとめ」・「(仮想マシンに比べ）負荷が低い」</li></ul></li></ul><h4 id="なぜGoogleがコンテナを使うのか？"><a href="#なぜGoogleがコンテナを使うのか？" class="headerlink" title="なぜGoogleがコンテナを使うのか？"></a>なぜGoogleがコンテナを使うのか？</h4><ul><li>開発速度をあげて、早くリリースしたい</li><li>サーバリソースを有効活用したい</li><li>開発者は開発に集中したい</li></ul><h4 id="コンテナオーケストレーションの重要性"><a href="#コンテナオーケストレーションの重要性" class="headerlink" title="コンテナオーケストレーションの重要性"></a>コンテナオーケストレーションの重要性</h4><ul><li>どのサーバ上につくる？ = スケジューリング</li><li>サーバが落ちたらどうする？ = セルフヒーリング</li><li>負荷が高くなったらどうする？ = オートスケーリング</li></ul><h4 id="Anthosのテクノロジースタック"><a href="#Anthosのテクノロジースタック" class="headerlink" title="Anthosのテクノロジースタック"></a>Anthosのテクノロジースタック</h4><img src="/images/20190809/photo_20190809_03.jpeg"><ul><li>ベースにGKEとIstioがいて、その上にControl Planeがある</li></ul><h3 id="Anthosのもたらす価値・提供機能"><a href="#Anthosのもたらす価値・提供機能" class="headerlink" title="Anthosのもたらす価値・提供機能"></a>Anthosのもたらす価値・提供機能</h3><img src="/images/20190809/photo_20190809_04.jpeg"><h5 id="コンテナオーケストレーション-GKE-GKE-On-prem"><a href="#コンテナオーケストレーション-GKE-GKE-On-prem" class="headerlink" title="コンテナオーケストレーション - GKE/GKE On-prem"></a>コンテナオーケストレーション - GKE/GKE On-prem</h5><ul><li>k8sは宣言型APIで設定する</li><li>宣言型API = あるべき状態を記述する。手順ではなく、最後の状態を定義する</li><li>k8sは宣言された状態をkeepするように動く</li></ul><h4 id="サービスメッシュ-の前に…"><a href="#サービスメッシュ-の前に…" class="headerlink" title="サービスメッシュ(の前に…)"></a>サービスメッシュ(の前に…)</h4><p>なぜマイクロサービス？</p><ul><li>1つ1つのサービスが小さくシンプル</li><li>機動的な機能追加</li><li>個別集中的なセキュリティ</li><li>個別のテクノロジー採用」</li></ul><p>しかし…連携が増え管理が大変</p><ul><li>どのように連携するか？</li><li>どのサービスがどのサービスと連携しているのか？</li><li>サービス間のセキュリティ、認証認可の担保は？</li></ul><h4 id="サービスメッシュ-Istio-on-GKE-CSM"><a href="#サービスメッシュ-Istio-on-GKE-CSM" class="headerlink" title="サービスメッシュ - Istio on GKE/CSM"></a>サービスメッシュ - Istio on GKE/CSM</h4><ul><li>Istioという解決策。間に入り、サービス間の連携を取り持つ<ul><li>つなげる、セキュアに保つ、見える化する</li></ul></li></ul><h4 id="設定、ポリシーの一元管理-Anthos-Config-Management"><a href="#設定、ポリシーの一元管理-Anthos-Config-Management" class="headerlink" title="設定、ポリシーの一元管理 - Anthos Config Management"></a>設定、ポリシーの一元管理 - Anthos Config Management</h4><ul><li>マルチ、ハイブリッドクラスタの一元管理</li><li>宣言型モデルと継続的なモニタリング</li><li>シンプルなマイグレーション</li></ul><h4 id="コンテナへのマイグレーション-Migrate-for-Anthos"><a href="#コンテナへのマイグレーション-Migrate-for-Anthos" class="headerlink" title="コンテナへのマイグレーション - Migrate for Anthos"></a>コンテナへのマイグレーション - Migrate for Anthos</h4><ul><li>仮想マシンで動いているものを簡単にコンテナ化できる</li></ul><h3 id="ユースケース"><a href="#ユースケース" class="headerlink" title="ユースケース"></a>ユースケース</h3><h4 id="Anthos-on-Edges"><a href="#Anthos-on-Edges" class="headerlink" title="Anthos on Edges"></a>Anthos on Edges</h4><ul><li>エッジロケーション(工場など)にAnthosを導入し、集中管理を行う</li><li>GKE On-premはインターネットへの疎通ができれば導入可能</li></ul><h4 id="Anthos-for-Hybrid-Cloud"><a href="#Anthos-for-Hybrid-Cloud" class="headerlink" title="Anthos for Hybrid Cloud"></a>Anthos for Hybrid Cloud</h4><ul><li>クラウドにおけないものはOn-prem、おけるものはクラウドに</li></ul><h4 id="Anthos-for-Multi-Cloud"><a href="#Anthos-for-Multi-Cloud" class="headerlink" title="Anthos for Multi Cloud"></a>Anthos for Multi Cloud</h4><ul><li>複数のクラウドを組み合わせたサービス構成</li><li>複数クラウドでDRを組むなども可能になる</li></ul><h3 id="まとめ-2"><a href="#まとめ-2" class="headerlink" title="まとめ"></a>まとめ</h3><img src="/images/20190809/photo_20190809_05.jpeg"><ul><li>2019/09/03にGoogle Cloud Kubernetes Dayやります(私も楽しみです！)</li></ul><h2 id="☁Istio-Kubernetes-Spinnaker-を使ったカナリア-デプロイメント"><a href="#☁Istio-Kubernetes-Spinnaker-を使ったカナリア-デプロイメント" class="headerlink" title="☁Istio, Kubernetes, Spinnaker を使ったカナリア デプロイメント"></a>☁Istio, Kubernetes, Spinnaker を使ったカナリア デプロイメント</h2><blockquote><p>Istio, Kubernetes, Spinnaker を使うことで、カナリアデプロイメントなど高度なロールアウトパターンをサポートし、アプリケーションを安全かつ簡単にデプロイすることが可能です。本セッションではこれらを如何に GCP 上で実現するか、最新のプロダクト情報も交えながら説明します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=299647-140817" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=299647-140817</a></p></blockquote><p>Istioが好きで最近仕事でCI/CDを設計している私にとってまたとない機会だったので、意気揚々と参加登録しました。本セッションもスピーカーの方が英語ネイティブな方だったのですが、2つ前のセッションを通訳レシーバーなしで過ごした私は、これまた意気揚々と「レシーバー要らないです」と言いながら会場へ足を踏み入れました。</p><p>k8sとIstioを使っていかにカナリアデプロイを実現するか、デモを交えて詳しく説明してくれるセッションでした。講演者の方の朗らかな人柄もあいまって、幸せな笑いに満ちたセッションだなーと思いつつ聴講していました！ちなみにセッションタイトルには「Spinnaker」とありますが、本セッションでは代わりに「TEKTON」を利用したカナリアデプロイメントの説明をしてくださっています。「Spinnaker」を利用したのはGoogle Cloud Next ‘19 in San Franciscoだったようです。(セッションの模様はYouTubeで見られるとのこと！)</p><p><a href="https://youtu.be/CmZWau04ZS4" target="_blank" rel="noopener">Canary Deployments With Istio and Kubernetes Using Spinnaker (Cloud Next ‘19)</a></p><p>デモアプリで登場した猫のアプリがとても印象的でした！猫！かわいい！！</p><p>以下、セッションのメモです。</p><h3 id="k8sにおけるコンテナデプロイ"><a href="#k8sにおけるコンテナデプロイ" class="headerlink" title="k8sにおけるコンテナデプロイ"></a>k8sにおけるコンテナデプロイ</h3><ul><li>課題は、どうやって安全かつ簡単にコンテナアプリケーションのバージョンを切り替えるか</li><li>ケースとして、アプリバージョンをOldからNewへ切り替えたい時</li><li>k8sではすでに下記に対応可能<ul><li>Rollingアップデート</li><li>Blue/Greenデプロイ</li><li>オーバープロビジョニング</li></ul></li></ul><h3 id="カナリアデプロイメント"><a href="#カナリアデプロイメント" class="headerlink" title="カナリアデプロイメント"></a>カナリアデプロイメント</h3><p>徐々に新しいバージョンにアプリケーションを切り替えていく。</p><ul><li>k8sでやるには、Deployment objectを利用する</li><li>よりアドバンスにやるには、Istioを利用してTrafficの分配を行う<ul><li><code>Destination Rule</code>と<code>Virtual Service</code>の設定によって実現可能</li></ul></li></ul><h3 id="TEKTONについて"><a href="#TEKTONについて" class="headerlink" title="TEKTONについて"></a>TEKTONについて</h3><ul><li>カナリアデプロイメントに際し、フェーズごとに設定変更しなければならない箇所がたくさんある</li><li>でも手で全部やるのは大変！！→自動化しよう！！</li><li>TEKTONはIstioを利用してカナリアデプロイメントを自動化してくれるツール</li><li>TEKTONはk8sのCRD(Custom Resource Definition)をラップしており、PipelineとTasksを定義することで動作する​​</li></ul><h3 id="まとめ-3"><a href="#まとめ-3" class="headerlink" title="まとめ"></a>まとめ</h3><ul><li>k8sを利用したカナリアデプロイメントにはIstioは絡めてTrafficコントロールを任せよう</li><li>TEKTONやSpinnakerを使って自動化することはとても重要</li><li>Spinnakerを使ったDEMOを行った<a href="https://youtu.be/CmZWau04ZS4" target="_blank" rel="noopener">サンフランシスコでのセッション動画</a>をぜひみてください！</li></ul><h1 id="最後に"><a href="#最後に" class="headerlink" title="最後に"></a>最後に</h1><p><a href="https://future-architect.github.io/articles/20190804/">Day2のレポート</a>でも書きましたが、Anthos含めKubernetesに関連するセッションが非常に充実していました。AnthosのセッションはまさにGoogle Cloudがどこに向かっていくかをありのまま伝えてくれたように思います。</p><p>Anthosのセッションを担当されていた長谷部さんが「実はGoogleは数年前からコンテナを使っているが、昨今いろいろな所でコンテナという言葉を耳にする。コンテナ技術は今流行っていると言える。」と発言されていました。Kubernetes・Istio・Knativeなどをはじめ、いまデファクトスタンダードになりつつある様々なOSSは例えばBorgなど元々Googleの社内システムにて利用されていたシステムが起源となっています。彼らは数年かけてブラッシュアップさせてきたものをOSSとして公開し、そしてそれを今GCPにてマネージドサービスとして提供しています。</p><p>変化の早いテクノロジーの世界において、知見は隠すものではなく皆で共有し・皆で育てていくものとなってきています。GCPを活用するということは言い換えればGoogleが長年培ってきた知見の集大成を一気に享受できるということであり、そのメリットは計り知れないはずです。我々も受け取るだけでなく広く世に発信し続けなければならないなと改めて考えさせられる良い機会にもなりました。</p><p>Day2・Day3の2日間だけの参加でしたが、非常に有意義な時間を過ごすことができました！GCPについての学びを惜しみなく発信する機運がマックスに高まってますので本ブログにも引き続きご注目ください！</p><p>我ら統合思念体の起源であるDXユニットに興味を持っていただけたら、 <a href="https://jobs.qiita.com/employers/future/development_teams/109" target="_blank" rel="noopener">Qiita Jobs</a>や<a href="https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=344" target="_blank" rel="noopener">このあたりの職種</a> もぜひご覧いただけると幸いです。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちは、TIG DXチームの統合思念体です。&lt;a href=&quot;https://cloud.withgoogle.com/
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="GCP" scheme="https://future-architect.github.io/tags/GCP/"/>
    
  </entry>
  
  <entry>
    <title>Google Cloud Next ’19 in Tokyo Day2 セッションレポート</title>
    <link href="https://future-architect.github.io/articles/20190804/"/>
    <id>https://future-architect.github.io/articles/20190804/</id>
    <published>2019-08-04T00:00:00.000Z</published>
    <updated>2019-08-03T15:22:13.251Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは、TIG DXチーム<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>の統合思念体です。<a href="https://cloud.withgoogle.com/next/tokyo/" target="_blank" rel="noopener">Google Cloud Next ’19 in Tokyo</a> Day2 にチームメンバーで参加しましたので参加レポートをお送りします。</p><p>チームでの参加に至った理由ですが、社内の中でも特にDXチームではGCPの活用事例が非常に増えており、著しい変化を見せるGCPの最新動向を知ること、またGCPサービスの深い理解すること、他社事例などに刺激を貰うことで、自社のFuture IoTサービス<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>をさらに成長させたい、という思いがあったことが背景にあります。</p><p>…という建付けで、実際にはチームメンバーの村田さんによる「みんなで行こうよ」発言ですぐに決まりました。</p><h2 id="Google-Cloud-Next-’19-in-Tokyoとは"><a href="#Google-Cloud-Next-’19-in-Tokyoとは" class="headerlink" title="Google Cloud Next ’19 in Tokyoとは"></a>Google Cloud Next ’19 in Tokyoとは</h2><p>「かつてないクラウドを体験しよう」をテーマに、📍東京プリンスホテル, 📍ザ・プリンス パークタワー東京の2ヶ所で 7/30~8/1の3日間に渡ってクラウドの最新動向や、採用事例を学べるセッションが開催されるカンファレンスです。ハッシュタグは <code>#GoogleNext2019</code> です<br>2019年は160ものセッションが開催され年々熱気が増しているように感じます<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。</p><p><a href="https://cloud.withgoogle.com/next/tokyo/" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/</a></p><h2 id="会場の様子"><a href="#会場の様子" class="headerlink" title="会場の様子"></a>会場の様子</h2><p>当日は気候的に猛暑であったという点で物理的な熱気が凄まじく、会場へ向かうだけでかなり試されました。2ヶ所の会場それぞれでセッションが存在するため、シャトルバスで15minかけて移動するか、徒歩8分程で移動するかの選択肢でした。思念体を構成する一部のメンバーは両会場のセッションを交互に予約したため4往復するハメになり詰んでました。会場を一つにまとめるようなセッションの選び方もイベントを楽しむためには重要かもしれません。</p><p>ちなみに、移動途中には増上寺の敷居を通らせていただくのですが、歴史ある寺院の建造物とバックにある東京タワーを一緒に見ることができて、いかにも東京らしい絶景を味わえます。</p><p>会場では弊社の代表取締役社長の神宮さんパネルがお出迎え。知らなかったので一同でビビりました。</p><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">フューチャーもGoogle Cloud<br>Next ’19 in Tokyoを応援しています！実は会場内のパネルに代表取締役社長の神宮さんが登場してます✨<a href="https://twitter.com/hashtag/GoogleNext19?src=hash&amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener">#GoogleNext19</a> <a href="https://t.co/maaknVdD0p" target="_blank" rel="noopener">pic.twitter.com/maaknVdD0p</a></p>&mdash; フューチャー技術ブログ (@future_techblog) <a href="https://twitter.com/future_techblog/status/1156409806606888961?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">July 31, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><h2 id="セッションレポート"><a href="#セッションレポート" class="headerlink" title="セッションレポート"></a>セッションレポート</h2><p>まずは、Day2について、私たちが聴講したセッションについて報告します。Day3の午後のセッションもいくつか参加したので、別の記事で公開予定です。</p><p>本来は3日間フル参戦したかったのですが、業務調整が大変すぎるという判断でDay1参加は見送っています。全体を期待した方、すいません。</p><h2 id="☁基調講演"><a href="#☁基調講演" class="headerlink" title="☁基調講演"></a>☁基調講演</h2><p><a href="https://cloud.withgoogle.com/next/tokyo/next-onair" target="_blank" rel="noopener">こちら</a>から講演の様子をオンデマンドで視聴できます。</p><p>内容は、様々なGCPを利用しているユーザ企業の方々がビジョンや戦略を中心に説明。統一しているのは、多くの企業も「ユーザーファースト」を謳っており、デジタルシフトがますます進んでいると感じました。技術的には、「BigQuery」や「Cloud Spanner」が多く利用されているようでした。</p><h2 id="☁Cloud-Code-とコンテナツールで-Kubernetes-を使った開発を徹底効率化"><a href="#☁Cloud-Code-とコンテナツールで-Kubernetes-を使った開発を徹底効率化" class="headerlink" title="☁Cloud Code とコンテナツールで Kubernetes を使った開発を徹底効率化"></a>☁Cloud Code とコンテナツールで Kubernetes を使った開発を徹底効率化</h2><blockquote><p>本セッションでは、Cloud Code、skaffold、Tekton などを使って、Kubernetes 開発をどのように効率化するか、デモを中心にご紹介します。Kubernetes は怖くない！<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=297697-140795" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=297697-140795</a></p></blockquote><p>わたしは普段、helmを利用したk8sアプリケーションのデプロイを行っているのですが、<code>コーディング</code>→<code>GCR push</code>→<code>kubectl apply</code>の流れを効率化できる手法を知りたいと思い参加しました。ただし、今回はCI/CDではなくローカル環境での開発をCloud Codeを利用して効率化するという話でした。</p><h3 id="k8sを用いたローカル開発の課題"><a href="#k8sを用いたローカル開発の課題" class="headerlink" title="k8sを用いたローカル開発の課題"></a>k8sを用いたローカル開発の課題</h3><p>k8sをつかうとコード開発以外に細かい作業がたくさんあります。</p><ul><li>ソースコードを変更するたびに、YAMLなどの設定の変更を始めとした様々な繰り返し作業が発生</li><li>ターミナル、ブラウザなど切り替えが多いため、コンテキストスイッチにより生産性が低下</li><li>関連ツールを全て覚えるのが困難</li></ul><h3 id="Cloud-Code-for-IDEs"><a href="#Cloud-Code-for-IDEs" class="headerlink" title="Cloud Code for IDEs"></a>Cloud Code for IDEs</h3><ul><li>エンジニアがコードにフォーカスすることを支援してくれるツールで、k8sの開発サイクルに対応し、デバッグ機能・クラスタ管理・テンプレートと編集支援をしてくれる</li><li>Kubernetesアプリケーションの継続的デプロイメントをサポートするCLIであるSkaffoldを利用している</li><li>Build push deployを指定して自動化してくれる</li></ul><h3 id="Cloud-Code-for-IDEの主な特徴"><a href="#Cloud-Code-for-IDEの主な特徴" class="headerlink" title="Cloud Code for IDEの主な特徴"></a>Cloud Code for IDEの主な特徴</h3><p>1．Kubernetesの開発サイクルを短く<br>2．デバッグ<br>3．クラスタ管理<br>4．テンプレートと編集支援<br>5．エコシステムとの統合<br>6．GCPとの統合</p><h3 id="セッションの感想"><a href="#セッションの感想" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>Kubernetesは柔軟でスケーラブルではあるが学習コストが高いというのは今身をもって体感しています。ローカルで簡単に試す環境を作りたい、勉強したいという初心者にもかなり使えるツールなのではないかなと感じました。</p><p>個人的には帰宅してすぐにVSCodeにCloud Codeプラグインを入れちゃいました。仕事ではそこそこの規模なGKEを運用しており、この場合はhelm等使うことが良いと思いますが、小規模でk8s使って開発したい時に活躍しそうです。</p><p>kubectlでのクラスタ切り替えや、gcloudでのクラスタ情報を取得など、多くのコマンドがあり覚えきれないですよね泣。そういった部分が隠蔽化されて、ワンポチでできちゃうってのはすごく使いやすいですね。</p><h2 id="☁Cloud-Run-〜Knative-を使った新しいサーバーレス"><a href="#☁Cloud-Run-〜Knative-を使った新しいサーバーレス" class="headerlink" title="☁Cloud Run 〜Knative を使った新しいサーバーレス"></a>☁Cloud Run 〜Knative を使った新しいサーバーレス</h2><blockquote><p>本セッションでは Cloud Run を使って具体的にどういったことが出来るのかデモを交えながら説明します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=297911-140799" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=297911-140799</a></p></blockquote><p>コンテナアプリケーションのデプロイ先として、Cloud Runを使うか・GKEを使うか、を迷う機会があり、Cloud Runの特徴についてより深く学びたいと考え参加を決めました！Cloud Run・Knativeについて、サーバーレスとは？という話題から実際に使うときのプロダクト選定基準まで幅広く解説してくれたセッションでした。</p><h3 id="サーバーレスとこれまでの課題"><a href="#サーバーレスとこれまでの課題" class="headerlink" title="サーバーレスとこれまでの課題"></a>サーバーレスとこれまでの課題</h3><ul><li>サーバーレスとは？<ul><li>No infra management、Fully managed security、Pay only for usage の3点</li></ul></li><li>GCPのサーバーレス<ul><li>Functions(Cloud Functions)、Apps(App Engine)、Containers(Cloud Run)</li></ul></li><li>これまでの課題<ul><li>対応言語や対応ライブラリに依存すること、ベンダーロックイン、GPU/TPUなどの特定リソースにアクセスできないことの3点</li></ul></li></ul><h3 id="Knativeが登場"><a href="#Knativeが登場" class="headerlink" title="Knativeが登場"></a>Knativeが登場</h3><ul><li>k8sクラスタ上にFaaS/PaaS実行環境を構築できる</li><li>特徴は、「OSS」「コンテナをサーバーレスライクに使える」「k8sクラスタのHWリソースが使える（GPUなどもOK）」</li></ul><h3 id="Cloud-Run"><a href="#Cloud-Run" class="headerlink" title="Cloud Run"></a>Cloud Run</h3><ul><li>Cloud Runの主な特徴が3つある<ol><li>高速なデプロイと、リクエストがなければコンテナ数は0になる = 課金されない</li><li>サーバーレスネイティブ</li><li>高いポータビリティ</li></ol></li><li>2種類のCloud Run実行パターンが有る<ul><li>Cloud Run (以下、無印)と、Cloud Run on GKEがある</li></ul></li><li>2つのCloud Runの違い<ul><li>インフラ面で違いはあるが、「Same API, Same CLI, Same App」である</li><li>ユーザ目線では、無印はマシンスペックについていじれる項目が少ない。VPCへのアクセスが無印ではまだできず、on GKEは可能という違いがある</li></ul></li><li>Cloud Runのリソースモデル<ul><li>「Service」カスタムドメインも選択可能</li><li>「Revision」splittingはApp Engineで既にできるが、Cloud Runでもそのうち可能になる（これは期待！）</li><li>「Container Instance」</li></ul></li><li>Cloud Runのその他の特徴<ul><li>エンドポイントはインターネットFacing</li><li>Cloud PubSub、Cloud Tasks、Cloud Schedulerトリガーで起動ができる</li></ul></li><li>高速なデプロイとスケールをセキュアに実現する技術<ul><li>gVisorという、ホストとコンテナの間に入るレイヤーがある</li></ul></li></ul><h3 id="Concurrencyについて"><a href="#Concurrencyについて" class="headerlink" title="Concurrencyについて"></a>Concurrencyについて</h3><p>1つのコンテナに投げられるリクエストの最大数。<br>Concurrencyの設定を変えて、コンテナ数がどのように変化するか見てみました。</p><ul><li>Concurrency = 1、1400TPSで負荷をかけると、Containerは500個へスケール</li><li>Concurrency = 80、1400TPSで負荷をかけると、Containerは100個へスケール</li></ul><p>Concurrencyの値を大きくした時に注意すべきことは、コールドスタートが少なくなることと、スレッドセーフにする必要がある点です。</p><h3 id="GCPのサーバーレスどう使い分けるか？"><a href="#GCPのサーバーレスどう使い分けるか？" class="headerlink" title="GCPのサーバーレスどう使い分けるか？"></a>GCPのサーバーレスどう使い分けるか？</h3><ul><li>Functionsは「コードベース」で「イベントドリブン」</li><li>Appsは「コードベース」で「10年の歴史があるので知見が転がっている」</li><li>Containersは「コンテナベース」、「ランタイム制約・ロックインなし」、「まだベータ版」</li><li><a href="https://cloud.google.com/serverless-options/" target="_blank" rel="noopener">公式の使い分けチャート</a>もあります！</li></ul><h3 id="セッションの感想-1"><a href="#セッションの感想-1" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>これからはコンテナベースなサーバーレスが主流になっていくのかなーと感じられるセッションでした！いまはFunctionsめちゃくちゃ使ってるけど、徐々にCloud Runに移行しようかなと思いました。</p><p>あと、Cloud Run東京リージョン来てくれてうれしい！（VPC Accessも期待しています！）</p><h2 id="☁データウェアハウスのあるべき姿とBigQueryの新機能"><a href="#☁データウェアハウスのあるべき姿とBigQueryの新機能" class="headerlink" title="☁データウェアハウスのあるべき姿とBigQueryの新機能"></a>☁データウェアハウスのあるべき姿とBigQueryの新機能</h2><blockquote><p>今日、企業はデータを活用するにあたって、<br>データ ウェアハウスに求められる役割についてあらためて考えます。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-3-S01" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-3-S01</a></p></blockquote><p>もともとデータベースを主軸に仕事をしてきたこともあり参加しました。内容としては主にBigQueryの概要と性能アップ、そして新機能の紹介でした。</p><h3 id="BigQuery特徴"><a href="#BigQuery特徴" class="headerlink" title="BigQuery特徴"></a>BigQuery特徴</h3><ul><li>性能<ul><li>ある事例では250ペタバイトの保存データや5ペタバイトのクエリの実行記録もある</li><li>昨年まで400MBのクエリが24.5secで処理されていたが、現在は4.2secで処理された記録がある</li></ul></li><li>Serverless<ul><li>upgradeやセキュリティアップデートをシームレスに実施することができる</li><li>カスタマーが一切気にすることがない世界唯一のデータウェアハウスである</li><li>自動再クラスタリングがバックグラウンドで実行される</li></ul></li><li>Open<ul><li>BigQueryをどのPFでもどのようなインプットからも利用することができる</li></ul></li></ul><h3 id="新機能"><a href="#新機能" class="headerlink" title="新機能"></a>新機能</h3><ul><li>Parquet &amp; ORC Federation Beta<ul><li>Parquet/ORCを使ったBigQueryテーブルが作成できる</li><li>列ファイル形式と論理区画により高速に</li><li>Hiveパーティションで、クエリとロードをサポートしている</li></ul></li><li>Cloud Sql Federation Beta<ul><li>BigQuery＋PostgresQL、MySQL、CloudCqlの組み合わせで使う場面が多い</li><li>External query functionを利用してBigQueryからCloudCqlへクエリを投げることができる。Joinも可能。</li></ul></li><li>BigQueryStorage APIs<ul><li>BigQueryからデータを取り出すための新しいAPIです。 </li><li>BigQueryのストレージ層に対してgRPCでクエリを投げることによって、従来のAPIと比較して高速かつリアルタイムにデータを取得できる。</li></ul></li><li>BigQueryBI Engine<ul><li>レポートで頻繁に必要とされるデータをインメモリ処理にしてくれることで、パフォーマンスを向上させる</li><li>BigQueyとBIツールの間にデータを蓄積するメモリを加えることで実現している</li></ul></li></ul><h3 id="セッションの感想-2"><a href="#セッションの感想-2" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>DWHやそれを取り巻くBIの大きな課題である性能問題に注力するだけでなく、RDBとの連携やAPIの提供などユーザがさらに使いやすく他システムと連携できるような機能を提供していますね。</p><p>今後のDWHの選定では性能だけでなくどれだけ他システムとの連携が取れるかが大事な軸になりそうと思わせるセッションでした。</p><h2 id="☁オブザーバビリティを加速させる-Stackdriver"><a href="#☁オブザーバビリティを加速させる-Stackdriver" class="headerlink" title="☁オブザーバビリティを加速させる Stackdriver"></a>☁オブザーバビリティを加速させる Stackdriver</h2><blockquote><p>本セッションでは「オブザーバビリティ」とは何かを紹介し、従来の監視との差異、そして Stackdriver がどのようにオブザーバビリティを確保する支えになるかを解説します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=295818-140777" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=295818-140777</a></p></blockquote><p>最近DevOpsという単語を意識する機会が多く、GCPにおいてDevOpsを支えるStackdriverについて詳しくなりたいと思い参加しました！SREにおけるStackdriverの活用方法について、運用におけるフェーズごとに適切なプロダクトとその利用方法を解説してくれるセッションでした</p><h3 id="DevOpsとSRE"><a href="#DevOpsとSRE" class="headerlink" title="DevOpsとSRE"></a>DevOpsとSRE</h3><ul><li>DevOpsからSREへ。SREはDevOpsの実践方法である</li><li>SREとは、意思決定にデータを用い、人間の主観で判断しない。また、運用の課題(スケーラビリティ、信頼性、効率)をソフトウェア・エンジニアリングで解決する</li><li>オブザーバビリティ（可観測性）とは、システムを運用する上で判断に必要な情報が取得可能な状態であること</li></ul><h3 id="SREにおけるStackdriverについて"><a href="#SREにおけるStackdriverについて" class="headerlink" title="SREにおけるStackdriverについて"></a>SREにおけるStackdriverについて</h3><p>各運用プロセスで必要なデータは異なります。</p><ul><li>通常運用<ul><li>全体感のわかる統計データを取得</li><li>SLO違反が発生した際にアラートが飛ぶよう設定する</li><li>Istioを使ってるのであれば、Cloud Service Meshも有益</li></ul></li><li>高負荷時・調査<ul><li>パフォーマンスモニタリングにはAPMなど専用のメトリクスが容易されているのでそれらを活用する</li><li>Stackdriver Profiler</li><li>Stackdriver Trace</li></ul></li><li>その他障害対応<ul><li>Stackdriver Error Reporting</li></ul></li></ul><h3 id="セッションの感想-3"><a href="#セッションの感想-3" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>アプリのパフォーマンス検証において有用なサービスを知ることができたので、プロジェクトでもどしどし使っていきたいなと思いました。あと、IstioはStackdriverへの詳細メトリクス連携を目的としたモニタリングの観点のみだけだとしてもぜひ導入したいと思います。</p><h2 id="☁デモで魅せます！GCP-で生産ラインにおける検査工程の効率化"><a href="#☁デモで魅せます！GCP-で生産ラインにおける検査工程の効率化" class="headerlink" title="☁デモで魅せます！GCP で生産ラインにおける検査工程の効率化"></a>☁デモで魅せます！GCP で生産ラインにおける検査工程の効率化</h2><blockquote><p>GCP のデータ関連サービスを利用したスピード開発により、<br>生産ラインにおける製品の品質チェックを、どのように実現するか解説します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-8-OS2" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-8-OS2</a></p></blockquote><p>7月から工場系の案件に携わることになったため参加しました。工場の品質管理という課題をGCPでデータ分析や機械学習を用いて解決する方法について、デモを交え解説していました。</p><h3 id="製造業の課題"><a href="#製造業の課題" class="headerlink" title="製造業の課題"></a>製造業の課題</h3><ul><li>製造業では人不足が深刻になっている</li><li>人不足のため品質管理に注力したくてもできていない</li><li>欠陥品が見つかっても何が原因であるかを分析することに時間がかかる</li><li>ラインセンサーを使用してもその場限りのデータになっていて、分析目的に利用できていない</li></ul><h3 id="どのようにデータを分析すべきか"><a href="#どのようにデータを分析すべきか" class="headerlink" title="どのようにデータを分析すべきか"></a>どのようにデータを分析すべきか</h3><ul><li>欠陥品ができた時の工場各センサーのデータをもとに原因分析する</li><li>例1<ul><li>事象：欠陥品が出た時に振動センサーが異常値を示していた</li><li>原因：地震が発生していた</li></ul></li><li>例2<ul><li>事象：欠陥品がでたときに温度変化の線サーバ異常値を示していた</li><li>原因：電気線がショートしていた</li></ul></li></ul><h3 id="GCPが提供する欠陥品の発見方法"><a href="#GCPが提供する欠陥品の発見方法" class="headerlink" title="GCPが提供する欠陥品の発見方法"></a>GCPが提供する欠陥品の発見方法</h3><ul><li>Auto MLを使って画像認識で欠陥を発見<ul><li>Googleの学習済みモデルを活用</li><li>すべての開発者が使用可能</li><li>フルカスタムモデルよりトレーニングデータ量、トレーニング時間、リソースを削減することが可能</li><li>クラウドでもオンプレでもモデル活用が可能</li></ul></li></ul><h3 id="GCPが提供する大量データ収集、分析"><a href="#GCPが提供する大量データ収集、分析" class="headerlink" title="GCPが提供する大量データ収集、分析"></a>GCPが提供する大量データ収集、分析</h3><ul><li>ペタバイトスケールのフルマネージドサービス</li><li>SQL2011またはJDBC対応</li><li>BigQueryMLで機械学習モデル作成が簡単に実現可能</li><li>位置情報のサポート</li><li>Json形式、ネストされたデータの対応</li></ul><h3 id="デモ"><a href="#デモ" class="headerlink" title="デモ"></a>デモ</h3><ul><li>小さなベルトコンベアと車のラジコンを使って工場のラインを再現</li><li>部品(車体)に傷がついたという想定でマジックで線を書き、画像認識で検知</li></ul><h2 id="☁Transform-your-work-culture-テクノロジーが可能にするイノベーションと-Diversity-amp-Inclusion"><a href="#☁Transform-your-work-culture-テクノロジーが可能にするイノベーションと-Diversity-amp-Inclusion" class="headerlink" title="☁Transform your work culture テクノロジーが可能にするイノベーションと Diversity &amp; Inclusion"></a>☁Transform your work culture テクノロジーが可能にするイノベーションと Diversity &amp; Inclusion</h2><blockquote><p>Google re:work の実践的なプログラムをもとに、どのようにテクノロジーで働き方を変え、<br>Diversity &amp; Inclusion を実現する具体的なヒントをご紹介していきます<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-6-OS2" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-6-OS2</a></p></blockquote><p>働き方改革に興味があったため参加させていただきました。</p><h3 id="働き方改革の導入手法としての鍵"><a href="#働き方改革の導入手法としての鍵" class="headerlink" title="働き方改革の導入手法としての鍵"></a>働き方改革の導入手法としての鍵</h3><ol><li>Anywhere（在宅勤務）</li><li>Simply（業務効率化）</li><li>Shorter（退社時間の計画）</li></ol><h3 id="Anywhere"><a href="#Anywhere" class="headerlink" title="Anywhere"></a>Anywhere</h3><p>実現のためには、まずテーマを1つに定め、モデル部署を選択し、期間を1ヶ月などと定め、トライアルをすることが重要だそう。効果は事後アンケートで効果測定するのが良いとのことです。まずは1回で良いので実施してみると効果が見えるそうです。</p><h3 id="Simply"><a href="#Simply" class="headerlink" title="Simply"></a>Simply</h3><p>主に会議の効率化について説明されていました。<strong>グランドルール</strong> と呼ばれるシンプルなルールを徹底し、会議時間を短縮、参加メンバーを厳選することが良いとのことです。</p><ul><li>最初にアジェンダを会議前に上げる</li><li>議事録をみんなで会議中に作る</li><li>会議中に次のTODO、決定事項が決まっている</li></ul><h3 id="Shorter"><a href="#Shorter" class="headerlink" title="Shorter"></a>Shorter</h3><p>個人的に興味深かったのですが、いわゆるノー残業デーにするのではなく、個々人で自分が帰る時間を宣言するモデルが有効だそうです。この「自分」で「自分の勤務時間」を「決める」ということの方が、一斉なノー残業デーより効果があったそうです。結果として、平均勤務時間が8-9h –&gt; 7-8h に減ったとのこと。</p><h3 id="全体を通して特に記憶に残ったこと"><a href="#全体を通して特に記憶に残ったこと" class="headerlink" title="全体を通して特に記憶に残ったこと"></a>全体を通して特に記憶に残ったこと</h3><ul><li><a href="https://www.womenwill.com/japan/" target="_blank" rel="noopener">Woman Will</a>に、Playbookがあるのでご参考に。調査結果もここに記載されている</li><li>トップダウンだけではなく、ボトムアップの動きも重要。トライアルなど実施の前にメンバーへのヒアリングをすること。納得しないと人間は動かない、変わらない</li><li>「育児・介護」など事情がある人だけのものではなく、みんなのもの</li></ul><p>とても参考になりました。スピーカーの山本 裕介さん、ありがとうございました！</p><h2 id="☁Google-Kubernetes-Engine-によるコンテナ-セキュリティの道"><a href="#☁Google-Kubernetes-Engine-によるコンテナ-セキュリティの道" class="headerlink" title="☁Google Kubernetes Engine によるコンテナ セキュリティの道"></a>☁Google Kubernetes Engine によるコンテナ セキュリティの道</h2><blockquote><p>このセッションでは Binary Auth、Container Analysis、GKE Sandbox など、GKE のコンテナ セキュリティの機能を紹介します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=320063-141088" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=320063-141088</a></p></blockquote><p>DXチームは日頃からGKEをバリバリ使っているので、GKE×セキュリティ、を考えようと参加しました。コンテナのリリースフローに合わせて、各フェーズで利用すべきセキュリティサービスを紹介してくれるセッションでした</p><h3 id="コンテナの導入による新しいセキュリティの課題"><a href="#コンテナの導入による新しいセキュリティの課題" class="headerlink" title="コンテナの導入による新しいセキュリティの課題"></a>コンテナの導入による新しいセキュリティの課題</h3><ul><li>アプリリリースの手順をおさらい<ul><li>コンテナ導入前は、「ほとんどが手動」で「サーバに直接モジュールをデプロイ」</li><li>アプリは1つのマシン上に置かれて動いているので、他のシステムアプリケーションやOSへもアクセスできてしまう</li></ul></li><li>セキュリティ上の課題<ul><li>k8sへのアクセス権限の管理が煩雑</li><li>より複雑なFW設定やネットワークポリシー</li></ul></li></ul><h3 id="コンテナによる新しいセキュリティの可能性"><a href="#コンテナによる新しいセキュリティの可能性" class="headerlink" title="コンテナによる新しいセキュリティの可能性"></a>コンテナによる新しいセキュリティの可能性</h3><ul><li>統一したモニタリング<ul><li>コンテナに不正侵入されてないか</li></ul></li><li>イメージスキャン<ul><li>脆弱性のあるモジュールを含んでいないか</li></ul></li><li>イメージ署名<ul><li>署名済みイメージから変更はないか</li></ul></li><li>サービスメッシュ<ul><li>コンテナ間のアクセス権限は正しいか、不正アクセスはないか</li></ul></li></ul><h3 id="CI-CD・ビルド"><a href="#CI-CD・ビルド" class="headerlink" title="CI/CD・ビルド"></a>CI/CD・ビルド</h3><ul><li>GCR: Container Analysis<ul><li>検出した脆弱性の内容と重要度を表示</li></ul></li><li>GKE: Binary Authorization<ul><li>信頼できるコンテナのみをGKEにデプロイ</li><li>信頼チェック済みのイメージと異なるイメージがデプロイされようとすることを防ぐ</li></ul></li></ul><h3 id="アプリケーション運用"><a href="#アプリケーション運用" class="headerlink" title="アプリケーション運用"></a>アプリケーション運用</h3><ul><li>GKE Sandbox<ul><li>GKEコンテナのセキュリティを更に強化</li><li>他人の書いたコードを自分の環境で実行するとして、信頼性のチェックは必要</li><li>パフォーマンスをすこし落としてでもセキュリティを高める思想</li></ul></li><li>gVisor<ul><li>ホストとコンテナ間に1枚かますことで脅威の影響範囲を狭めセキュアに保つ</li></ul></li><li>Event Threat Detection<ul><li>GCP環境に存在する脅威を検出</li><li>クラウドベースの脅威を迅速に検出</li></ul></li></ul><h3 id="ユーザ管理"><a href="#ユーザ管理" class="headerlink" title="ユーザ管理"></a>ユーザ管理</h3><ul><li>Cloud Identity &amp; Access Management<ul><li>きめ細かいアクセス制御</li></ul></li><li>Cloud Security Command Center<ul><li>複数PJの包括的な脅威検出情報を一元管理できる</li></ul></li></ul><h3 id="セッションの感想-4"><a href="#セッションの感想-4" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>以前参加したGoogle Kubernetes Dayでも、GCPはセキュリティ的にむしろ安全である、という主張がありましたが、まさにそれが体現されていることを実サービスの紹介によって理解できました！<br>ただやはりコンテナのランタイムポリシーチェックなどをしてくれるGCPサービスはまだ登場してこないですね…(あるいはコンテナランタイムチェックは必要ない、というGCPからのメッセージなのだろうか)</p><h2 id="☁TwitterでのGCP事例"><a href="#☁TwitterでのGCP事例" class="headerlink" title="☁TwitterでのGCP事例"></a>☁TwitterでのGCP事例</h2><blockquote><p>Twitter のデータアーキテクチャを、GCP に焦点を当てて解説します。<br><a href="https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-4-S08" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/sessions?session=D1-4-S08</a></p></blockquote><p>Twitter好きなので参加しました。このセッションのハッシュタグは <code>#GoogleNext19Twitter</code> だそうです。</p><h3 id="Twitterの規模"><a href="#Twitterの規模" class="headerlink" title="Twitterの規模"></a>Twitterの規模</h3><p>とても大きいということが数値ベースで実感としてよくわかりました。</p><ul><li>2013年天空の城ラピュタで “14万TPS”のツイート。50万コア、12万ノード、1日平均5億ツイート</li><li>Webページにembedされていたりするので、1日1兆を超えるメッセージが飛ぶ</li></ul><h3 id="オンプレミスからGCPへの移行"><a href="#オンプレミスからGCPへの移行" class="headerlink" title="オンプレミスからGCPへの移行"></a>オンプレミスからGCPへの移行</h3><p><strong>Partly Cloudy</strong> というPJ名が指す通り、まずはHadoopクラスタから段階的なクラウドリフトをしたそうです。</p><ul><li>Twitterにとって戦略的な決断で、Googleであればずっと一緒に成長し続けられると信じた</li><li>GCP移行でHadoopのクラスタの、ストレージとコンピュートを分離できた</li><li>オンプレミスとGCPの接続のため、1.6Tbpsのネットワーク帯域幅が必要！</li><li>クラスタの規模をどうするか。10ノードだと細かすぎるし、1000ノードだと大きすぎる</li><li><a href="https://cloud.google.com/twitter/" target="_blank" rel="noopener">cloud.google.com/twitter</a> にも移行について記載しているよ</li></ul><h3 id="セッションの感想-5"><a href="#セッションの感想-5" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>システム規模が私にとって異次元過ぎてクラクラしちゃいましたが、この規模のクラウドマイグレーションを成功させることができたということは、素晴らしい事例だと感じました。</p><h2 id="☁Google-Cloud-Platform-でゲノム解析"><a href="#☁Google-Cloud-Platform-でゲノム解析" class="headerlink" title="☁Google Cloud Platform でゲノム解析"></a>☁Google Cloud Platform でゲノム解析</h2><blockquote><p>GCP上で、GATK や DeepVariant、ワークフローエンジン などのオープンソースを使用し、ゲノムデータをエンドツーエンドで解析する方法を学びます<br><a href="https://cloud.withgoogle.com/next/tokyo/my-schedule?session=D1-5-S03" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/my-schedule?session=D1-5-S03</a></p></blockquote><p>畑違いなのですが、好奇心を刺激され参加させていただきました。</p><h3 id="公開データセット"><a href="#公開データセット" class="headerlink" title="公開データセット"></a>公開データセット</h3><p>バイオメディカルリサーチのためのゲノム関連の公開データセットがあります。</p><ul><li>未アノテーション系（1000人ゲノムなど）</li><li>アノテーション済みの（CinVarアノテーションなど）</li></ul><h3 id="ゲノム解析の手法"><a href="#ゲノム解析の手法" class="headerlink" title="ゲノム解析の手法"></a>ゲノム解析の手法</h3><ol><li>一時解析（サンプル、シーケンサ、生データ）<ul><li>物理的な解析</li></ul></li><li>二次解析（FASTQ, BAM, VCF）<ul><li>Pipelines APIを用いて業界標準のツールやフレームワークを利用可能</li><li>GATK, dsub/SAMtools, DeepVariant, NextflowをCloudShellから簡単に実行していました</li></ul></li><li>三次解析（解釈、アノテーション）<ul><li>アノテーション処理はBigQuery, Dataprep, AI Platform Notebooksがオススメ</li><li><a href="https://github.com/googlegenomics/gcp-variant-transforms" target="_blank" rel="noopener">Variant Transforms</a>をGCP上で動かせば、 8000万行というそこそこ大きなデータ量も、並列処理を行うことで2hで完了できる</li><li>BigQueryを用いたTi/Tv比（ゲノムの品質を見るための指標らしい）のクエリでは、1万人サンプルだと、23TB、行数が3.6億レコードになるが、BigQueryだと1SQLで計算できる。チューニングしなくても8minほどで終わるが、さらにクラスタ化と不要データを削除することで、1min以内に処理が完了</li><li>DataprocはSpark/Hadoopのマネージドサービスだが、ゲノム解析ツールのHailも実行可能</li><li>ParabricksでGPUを用いたディープバリアントでき、マーケットプレースから簡単に実行可能</li></ul></li></ol><h3 id="セッションの感想-6"><a href="#セッションの感想-6" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>ゲノム領域は文字通り何も知識がありませんでしたが、単語レベルで知らないことばかりで楽しかったです。<br>ゲノム解析の仕事をしている人は？という質問で手を上げた人が少なかったので、日本でこの領域を攻めると先駆者になれそうだと思いました。</p><h2 id="☁マイクロサービス、サービスメッシュ（Istio）導入により迅速な開発を実現"><a href="#☁マイクロサービス、サービスメッシュ（Istio）導入により迅速な開発を実現" class="headerlink" title="☁マイクロサービス、サービスメッシュ（Istio）導入により迅速な開発を実現"></a>☁マイクロサービス、サービスメッシュ（Istio）導入により迅速な開発を実現</h2><blockquote><p>マイクロサービス、サービスメッシュ（Istio）導入により、開発、運用の方法が変わります。<br>このセッションでは、アプリケーション開発の効率を高めるために Istio がどのように既存のネットワークやセキュリティを変えるかについて解説します。<br><a href="https://cloud.withgoogle.com/next/tokyo/my-schedule?session=D1-6-S11" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/my-schedule?session=D1-6-S11</a></p></blockquote><p>Istioの機能説明というよりは、なぜそれが必要になったかといった背景などを詳しく説明していただけました。サービスメッシュという考えをより深く理解できると思います。</p><h3 id="サービスメッシュの背景"><a href="#サービスメッシュの背景" class="headerlink" title="サービスメッシュの背景"></a>サービスメッシュの背景</h3><ul><li>MicroServiceが犠牲にしている部分に、オペレーションの負荷増大がある<ul><li>Service as a Serviceを実現するために、サービスのオペレーション部分を同じ形式にする</li></ul></li><li>よくあるシステムの課題として「脆弱である」・「透明性の低い」・「成長への足かせになる」といったことがある<ul><li>IPベースのFirewallルールはどのシステムがどのシステムにアクセスしているか分からない</li><li>複数のシステムを経由する時に本当の送信元が分からない</li><li>サービスの追加に、NW（Firewall）、認証、認可、モニタリングが追加で時間がかかる</li></ul></li><li>k8sを使っているからと言って解決されない領域<ul><li>通信時の暗号化が義務付けられていますか？鍵変更の頻度は？</li></ul></li><li>これからは、<em>サービスメッシュ</em><ul><li>これを管理するためのもの、全てのサービスを同じにする、認証、認可、モニタリングも同じにする</li><li>透明性が高く、言語非依存、柔軟かつ簡単にNW機能を自動化する仕組み</li></ul></li></ul><h3 id="サービスメッシュの効果"><a href="#サービスメッシュの効果" class="headerlink" title="サービスメッシュの効果"></a>サービスメッシュの効果</h3><ul><li>観測性やアジリティが高くなる。ゴールデンシグナル（全サービス共通的なエラーレート、レイテンシ、APIコール数などの指標）が見れる。ロールアウト時に徐々に新サービスにリクエストを転送し、エラーバジェットを使い潰さないようにする</li><li>サービスメッシュの重要な点は、<em>統一性の獲得</em> できること</li><li>アプリケーションからインフラから切り離すことができる。例えば、リトライのロジックを書く時、アプリ開発者はインフラのコードを書くことが無くなる。リトライ回数、バックオフ、ジッター追加などの運用が、サービスメッシュにしておけば操作できる</li><li>k8sを導入していてもほとんどのサービスVM上で動いているのでは？ VMにサービスメッシュを入れて、k8sにサービスメッシュを入れて、通信させることで柔軟性が増し、モダナイゼーションを迅速に行える</li></ul><h3 id="セッションの感想-7"><a href="#セッションの感想-7" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>Kubernetesを導入するだけでは解決しない点は、「確かに..」と納得でした。<br>既存のVMにサービスメッシュを導入しモダナイゼーションへ繋げる点は興味深いと思いました。</p><h2 id="☁GCP-で稼働する-Go-アプリケーションのパフォーマンスチューニング"><a href="#☁GCP-で稼働する-Go-アプリケーションのパフォーマンスチューニング" class="headerlink" title="☁GCP で稼働する Go アプリケーションのパフォーマンスチューニング"></a>☁GCP で稼働する Go アプリケーションのパフォーマンスチューニング</h2><blockquote><p>このセッションではレイテンシに問題がある Go 言語のアプリを例にあげて、App Engine と Kubernetes Engine といったクラウドコンポーネントを最適化していく手法を詳細にご紹介します<br><a href="https://cloud.withgoogle.com/next/tokyo/my-schedule?session=D1-7-S03" target="_blank" rel="noopener">https://cloud.withgoogle.com/next/tokyo/my-schedule?session=D1-7-S03</a></p></blockquote><p>最適化の中でも、レイテンシ（応答性能）を小さくすることにフォーカスするセッションでした。<br>「機械より人間の時間のほうが大事だからね」というイケメン発言が素敵でした。</p><h3 id="計測"><a href="#計測" class="headerlink" title="計測"></a>計測</h3><ul><li><strong>「計測」は 直感に反する！</strong></li><li>Goのコードは通常はサーバコンポーネントなので、その部分だけ高速化しても効果薄の場合があるので注意。<strong>ユーザーファースト</strong>を掲げ、サーバメトリクスだけに依存せず、ブラウザ中のJS、キャッシュ、レンダリングも測定すること。</li><li>Stackdriverのでウォーターフォールトレースが可能。どのようなAPIコールをどのような順番で出力されるのか。シーケンシャルか、コンカレントかが分かる</li></ul><h3 id="改善"><a href="#改善" class="headerlink" title="改善"></a>改善</h3><ul><li>RDBが支配的な場合インデックスを貼るなどで対応しよう</li><li>サービスがバッチコールを受け入れる場合ば、NWレイテンシや認証が短縮できるのでバッチ実行しよう</li><li>関連しないやつはコンカレントに実行しよう</li><li>メールの送信を、CloudTaskを用いて非同期化しよう</li></ul><h3 id="Go-Tooling"><a href="#Go-Tooling" class="headerlink" title="Go Tooling"></a>Go Tooling</h3><ul><li>性能計測はベンチマークのテストコードを書き、 <code>go test -bench=.</code> で取得できる</li><li>逐次処理のトレースは、<code>go test -bench=. -trace a.trace</code> と <code>go tool trace --http :6060 a.trace</code> で可視化できる</li><li>CPUプロファイリングは、比較的ランタイム負荷が小さい処理で、実行中のgorutineのコールトレースを収集する。<code>go test -bench=. -cpuprofile a.prof</code> や<code>go tool pprof -http :6060 a.prof</code></li></ul><h3 id="セッションの感想-8"><a href="#セッションの感想-8" class="headerlink" title="セッションの感想"></a>セッションの感想</h3><p>ユーザファーストという言葉は何度強調しても足りない！とか、ボトルネックになっていない箇所を最適化しようとするのは自転車置き場議論だ！といったワードがとても面白かったセッションでした。また、go toolを活用して解析した結果、ボトルネックが標準ライブラリにあるという事がわかり、だったら出力のバッファリングをあえてなくしたほうがユーザ体験が良くなるよといった流れが、実に直感に反した最適化で学びでした。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>前回のGoogle Next in Tokyoにも増してKubernetesとそのエコシステムについてのセッションが増えてきたように思います。Kubernetes, Istio, Knativeなどデファクトスタンダートになりつつある、これらOSS群をフルマネージドで利用できる環境を整えるんだ、というクラウドプラットフォーマーとしての強い意志を感じました。</p><p>ちょうどDXチーム内でもKubernetesについて持ち回りで5分話す会というのを先月から始めたのですが、直近学んだことがセッションの中でも多数登場し、予習復習の意を含めとても有意義なイベントなったのは非常に良い収穫でした。</p><p>今後は9/3に開催されるGoogle Kubernetes Dayが控えており、これからの動向がより一層楽しみです！</p><p>ぜひDXユニットに興味を持っていただけたら、 <a href="https://jobs.qiita.com/employers/future/development_teams/109" target="_blank" rel="noopener">Qiita Jobs</a>や<a href="https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=344" target="_blank" rel="noopener">このあたりの職種</a> もご覧いただけると幸いです。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。その中でもDXチームは特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">https://future-architect.github.io/articles/20190723/ あたりを参考ください</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">ちなみに2018年は2日間開催で130セッションでした。</span><a href="#fnref:3" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h2&gt;&lt;p&gt;こんにちは、TIG DXチーム&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="GCP" scheme="https://future-architect.github.io/tags/GCP/"/>
    
  </entry>
  
  <entry>
    <title>俺のインフラデザインパターン　～過去の失敗に学ぶニッチなインフラの話～</title>
    <link href="https://future-architect.github.io/articles/20190731/"/>
    <id>https://future-architect.github.io/articles/20190731/</id>
    <published>2019-07-31T00:47:37.000Z</published>
    <updated>2019-07-31T04:04:31.863Z</updated>
    
    <content type="html"><![CDATA[<h1 id="１．自己紹介"><a href="#１．自己紹介" class="headerlink" title="１．自己紹介"></a>１．自己紹介</h1><p>2014年キャリア入社、TIG<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>所属の二木です。読み方は「フタキ」ではなく「ニキ」と読みます。メンバーからは「N i K i」といった雰囲気で呼ばれています。入社後は、流通・小売業界の案件にて、インフラ全体を設計/構築/運用するチームに所属し、日々成長を実感しながら過ごしています。</p><p>本記事では、フューチャーにおける <strong>インフラ設計技法の知財化</strong> を進める活動について報告します。</p><p>ちなみに、タイトルの「俺の～」は、二木が整理した内容を中心にまとめるよという意思表示と、目を惹くようなタイトルにしたかったための命名です。</p><h1 id="２．はじめに"><a href="#２．はじめに" class="headerlink" title="２．はじめに"></a>２．はじめに</h1><p>早速ですが、システム構築におけるインフラとは何を指すでしょうか？<br>色々な解釈が可能かと思いますが、フューチャーにおけるインフラとは、以下のように定義されています。</p><ul><li><strong>『!!!!!! ソースコード以外は全てインフラ領域である !!!!!!』</strong> <ul><li>※詳細は<a href="https://future-architect.github.io/articles/20170109/">こちらの記事</a>をどうぞ</li></ul></li></ul><p>もう一度いいます。「ソースコード以外は全てインフラ領域である」です。<br>この無限大にスコープが広がりそうな定義のため、私の入社当初は、カバー範囲の広さ・その影響力の大きさに振り回され、プロジェクト規模の大きさもあいまって、うまく立ち回れない日々もありました。</p><p>もちろん、フューチャーではこのカバー範囲の広さに対抗するため、多くのシステム開発PJで培った設計成果物が、テンプレートのような形で、だれでも利用可能な形で存在します。</p><p>では、すでに過去の成果物が存在するにも関わらず、なぜインフラ設計技法の知財化を進めるかについては、次章で説明します。</p><h1 id="３．インフラ知財の整備に取り組むきっかけ"><a href="#３．インフラ知財の整備に取り組むきっかけ" class="headerlink" title="３．インフラ知財の整備に取り組むきっかけ"></a>３．インフラ知財の整備に取り組むきっかけ</h1><p>2019年8月時点で、私が対応中のプロジェクトは2019年秋にリリースです。</p><p>日々品質向上に取り組んでいますが、その中で反省すべきことがありました。</p><p>過去プロジェクトのインフラ知財（設計書、ツールなど）を活用して、高品質なシステムを短納期で構築する予定でしたが、その設計背景・意図を読み解くことをしなかったため、後々の工程で手戻りが発生してしまいました。</p><h2 id="３－１．あるべきディレクトリ設計"><a href="#３－１．あるべきディレクトリ設計" class="headerlink" title="３－１．あるべきディレクトリ設計"></a>３－１．あるべきディレクトリ設計</h2><p>一例として、オンプレミス環境のディレクトリ設計構築で発生した問題を簡単に説明します。<br>インフラ知財では、Tomcatディレクトリ配下に、環境・システム種別のディレクトリを作成しています。</p><p><strong>図1:インフラ知財のディレクトリ構成</strong><br><img src="/images/20190731/photo_20190731_01.png"></p><p>プロジェクト過渡期の環境維持や、運用・保守まで見据えたホスピタリティのある設計になっていました。</p><h2 id="３－２．手戻りが発生したディレクトリ設計"><a href="#３－２．手戻りが発生したディレクトリ設計" class="headerlink" title="３－２．手戻りが発生したディレクトリ設計"></a>３－２．手戻りが発生したディレクトリ設計</h2><p>インフラ知財をプロジェクトで利用する際、構成をシンプルにしようと、不要と思った環境・システム種別のディレクトリを削除しました。</p><p><strong>図2:プロジェクトで設計構築したディレクトリ構成</strong><br><img src="/images/20190731/photo_20190731_02.png"></p><p>Tomcatディレクトリ配下に、環境・システム種別のディレクトリがないため、環境維持を行うには非常に分かりづらい設計となっていました。</p><p>プロジェクト過渡期にテスト環境が複数面必要となり、現行のディレクトリ構成では環境維持が困難になりました。<br>結果、本来あるべきディレクトリ構成に変更が必要と気付き、以下のような手戻りが発生しました。</p><ul><li>ローカルディレクトリの再作成</li><li>NFS領域のディレクトリの再作成</li><li>アプリケーションのデプロイ先変更</li><li>アプリケーション、ミドルウェア、スクリプトのログ出力先変更</li><li>アプリケーション、ミドルウェア、スクリプトの環境変数の設定変更</li><li>アプリケーション、ミドルウェア、スクリプトのリリース処理の変更</li><li>ジョブ定義の設定変更</li><li>監視定義の設定変更</li><li>ログ収集の設定変更</li><li>ログ参照の設定変更</li></ul><p>さくっと書きましたが、それぞれがそこそこ時間が掛かる作業だったので大変な思いをしました。</p><h1 id="４．本活動のゴール"><a href="#４．本活動のゴール" class="headerlink" title="４．本活動のゴール"></a>４．本活動のゴール</h1><p>現在、同じ失敗繰り返さないために、 <strong>利用者が設計背景・意図をしっかりと理解できる</strong> よう、インフラ知財の整備を進めています。</p><p>タイトルにあるようにインフラデザインパターンのパターンとは、「状況」「問題」「解決」「名前」の4要素で構成されているかと思います<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。ここでいう「解決」「名前」の部分は過去資産でまとまっていましたが、「状況」「問題」の部分も、その設計背景や意図をキチンと明文化することで整理していきます。</p><p>この活動により、インフラ知財を誰がどのプロジェクトで利用しても、一定の品質を担保し、かつ、設計・構築やレビューの工数を削減することを実現します。</p><h2 id="４－１．対象技術要素"><a href="#４－１．対象技術要素" class="headerlink" title="４－１．対象技術要素"></a>４－１．対象技術要素</h2><p>フューチャーでは、オープンな技術を要素別に整理した技術マップがあり、Winners‘ Circleと呼んでいます。</p><p><strong>図3:Winners‘ Circle</strong><br><img src="/images/20190731/photo_20190731_03.png" style="border:solid 1px #000000"><br>※全く見せられなくてすいません…</p><p>ボカシが強めですが、Winners‘ Circleは以下のような構成になっています。</p><ul><li>内側ほどプロジェクトでの利用実績が多数ある<strong>Mainカテゴリ</strong><ul><li>現時点で顧客への導入実績・ノウハウともに充実しているフューチャーにおける主要技術です</li></ul></li><li>外側ほど今後の利用を前提に技術検証を進めていく<strong>Watchカテゴリ</strong><ul><li>導入実績がなく、品質担保の手法や非機能要件がまだ把握できていない技術要素です</li></ul></li></ul><p>Watchカテゴリにあるような、新技術の検証ってわくわくしますし、最先端の技術導入をするような取り組みは、時代を切り開いているようでドヤ顔したくなりますよね。</p><p>しかし、本活動ではプロジェクトで利用することを想定しているので、Winners‘ CircleにおけるMainカテゴリを対象としています。</p><p>まずは、直近のプロジェクトで扱った技術要素からスタートします。</p><h2 id="４－２．実施計画"><a href="#４－２．実施計画" class="headerlink" title="４－２．実施計画"></a>４－２．実施計画</h2><p>Winners‘ CircleのMainカテゴリにはまだまだ多数の技術要素が存在するので、以下のようなサイクルを通して、インフラ知財のカバー範囲を拡大していき、全社で利用できるインフラ知財へと発展させて行きたいと考えています。</p><p><strong>図4:インフラ知財整備活動の計画</strong><br><img src="/images/20190731/photo_20190731_04.png"></p><ol><li>インフラ知財の整備を行う（β版）</li><li>インフラエンジニアの興味を引きそうな内容をフューチャー技術ブログに投稿する（仲間を見つける）</li><li>2019年を目途にインフラ知財β版を完成させ、正式版ver1.0にする</li><li>各プロジェクトにインフラ知財を展開し一緒に育てる</li><li>各プロジェクトで育ったインフラ知財をmasterにマージし、バージョンアップしていく</li></ol><p>社員の皆さまも、興味がある方はぜひ声をかけてください！一緒にやりましょう。</p><h1 id="５．記事掲載予定"><a href="#５．記事掲載予定" class="headerlink" title="５．記事掲載予定"></a>５．記事掲載予定</h1><p>本活動を通して、フューチャーのインフラエンジニアがどう品質を高めているか、ニッチな領域を題材として記事を書いていこうと思います。</p><ul><li>俺の『ユーザ管理・ディレクトリ管理』</li><li>俺の『スクリプト設計・ジョブ管理』</li><li>俺の『ログ管理』</li><li>俺の『運用監視』</li></ul><h1 id="６．おわりに"><a href="#６．おわりに" class="headerlink" title="６．おわりに"></a>６．おわりに</h1><p>最後まで読んでいただきありがとうございます。<br>インフラエンジニアとして頑張っている方に共感いただければ幸いです。<br>そして、俺のシリーズの記事を見て、一緒に働いてみたいと思っていただければ、是非<a href="https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=187" target="_blank" rel="noopener">このあたりの職種でエントリー</a>お願いします！</p><p>ご意見、ご感想を頂戴できますと、執筆者のモチベーションが上がります。（褒めてください笑）<br>また、こんな内容を記事に取り上げてほしいなどあればお気軽にご連絡お願いします。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略です</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">http://creativeshift.co.jp/pattern-lang/</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;１．自己紹介&quot;&gt;&lt;a href=&quot;#１．自己紹介&quot; class=&quot;headerlink&quot; title=&quot;１．自己紹介&quot;&gt;&lt;/a&gt;１．自己紹介&lt;/h1&gt;&lt;p&gt;2014年キャリア入社、TIG&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/tags/Infrastructure/"/>
    
  </entry>
  
  <entry>
    <title>社内技術書輪読会とSite Reliability Engineering</title>
    <link href="https://future-architect.github.io/articles/20190729/"/>
    <id>https://future-architect.github.io/articles/20190729/</id>
    <published>2019-07-28T23:08:56.000Z</published>
    <updated>2019-07-28T23:12:35.625Z</updated>
    
    <content type="html"><![CDATA[<p>TIG/DXユニット<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>所属のLEEです。</p><p>2019年より社内で輪読会を企画運営し、このたび初回の課題図書になってた<a href="https://www.oreilly.co.jp/books/9784873117911/" target="_blank" rel="noopener">Site Reliability Engineering</a> を全10回で無事読破できました。</p><p>これを記念に実施概況をまとめさせていただきます。</p><h1 id="Who-am-I"><a href="#Who-am-I" class="headerlink" title="Who am I"></a>Who am I</h1><p>名前から分かる通り韓国出身で、入社してちょうど1年くらいになりました。前職がWeb系の会社のエンジニアだったのでITコンサルティングを生業とするフューチャーに入社したのは、ある意味エンジニア界隈のトレンドに逆走した感じかもしれませんが、外には出せない情報ばかりの貴重な経験をさせてもらえているので良い決断だったと思っています。</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>入社して今までの会社と違う環境で戸惑いながらも、自分が慣れているWeb系のテイストを取り入れようとしました。</p><p>その一つが社内勉強会の企画でしたが、すでにいくつか定期開催済みということもあり、もう少しひねりを加えてと始めたのが輪読会でした。</p><p>輪読会は登壇スタイルの勉強会と比べて以下の特徴があると思います。</p><ul><li>毎回のテーマは本の内容に限定され特別に悩む必要がなく</li><li>忙しい業務の中の準備の手間が発表者一人に集中させない</li><li>勉強パーティー的なイベント性を排除しやすい</li></ul><p>参加型でライトでありながらみんなの成長に繋がるような勉強会になれたらと思ってました。</p><h1 id="書籍の選定"><a href="#書籍の選定" class="headerlink" title="書籍の選定"></a>書籍の選定</h1><p>まず初回にどの本にするかと、これからの書籍選定ポリシーを決めました。<br>経験者などに話を聞きながら以下のように決めました。</p><ul><li>古すぎなく、最新のトレンドが取り入れられ<ul><li>過去の名著はすでに読破したヒトがいる</li></ul></li><li>一人で読むには負担が多く分厚い本<ul><li>簡単な本は一人で読めば良い</li></ul></li><li>明日業務に役立つことは無いけど、将来的に地力を伸ばせること<ul><li>ちょっと背伸びした内容で、達成感も得やすい</li></ul></li></ul><p>他には、別のエンジニアコミュニティのオンライン読書会の経験から、<em>数式や図式が重要なファクターじゃない読み物</em> を条件に加えました。</p><p>初回としては人を可能な限り呼び寄せるべく、エンジニア界隈のビッグウェーブに乗り、Googleの<a href="https://landing.google.com/sre/books/" target="_blank" rel="noopener">Site Reliability Engineering</a>を選びました。これに関しては後で詳しく話します。</p><h1 id="運営ポリシー"><a href="#運営ポリシー" class="headerlink" title="運営ポリシー"></a>運営ポリシー</h1><p>輪読会をやるとしたら自然に思い浮かぶ要素を決めるだけでした。</p><ul><li>開催頻度<ul><li>週1</li></ul></li><li>1回にかける時間<ul><li>集中力が必要になるので1時間以下にした</li></ul></li><li>1回でどれくらいの量・ページを消化するか<ul><li>その分量の担当者の人数</li></ul></li><li>1冊の本を何回に分けて終わらせるか<ul><li>長すぎると消化しきれず飽きられてしまう</li></ul></li></ul><p>あと一つ、自分は一応社歴が浅かったため、以下の根回しをしておきました。</p><ul><li>ユニット内のサクラ募集</li><li>社内に顔が利く真野<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>さんを利用して開催の告知</li></ul><h1 id="当日の運用"><a href="#当日の運用" class="headerlink" title="当日の運用"></a>当日の運用</h1><p>進行としてはSRE本の場合は全34章だったので一人当たり1章ずつ担当、1回に2〜3章を1時間する計画で10週〜3ヶ月で終わらせる目標で勧めました。実際の輪読会は以下のような感じに進めました。</p><ul><li>前回の終わり頃に担当者を募集</li><li>担当者はみんなが見れる章の要約資料を事前に用意</li><li>皆に本を片手に内容を噛み砕いて説明する</li><li>理解できなかった部分をみんなに質問を投げかける</li><li>関連する自分の経験を共有する</li><li><strong>やらなくてもいいと思った章は飛ばす</strong><ul><li>一部のケーススタディなど</li><li>自分でざっくり読んで5分以内にまとめるなど</li></ul></li></ul><p>「輪読会はこれが初めて！」というメンバーが多かったですが、第1回目から予め決めておいたルールに従い運営したため、特に問題が発生しなかったので良かったです。</p><h1 id="輪読会の雰囲気"><a href="#輪読会の雰囲気" class="headerlink" title="輪読会の雰囲気"></a>輪読会の雰囲気</h1><p>あれこれの根回しのおかげて、ユニットメンバー含め、あらゆるところのプロジェクトから参加してくれました。弊社AIグループの方や同じTIGではないインフラに興味のある若手の方、他にも10年以上なるベテランまで、あらゆる客層から輪を広げることができたのは嬉しかったです。</p><p>ということで、参加者はバラエティ豊かでした。</p><p>1年目の新人さんから、オンプレミス～クラウドまで構築し続けたインフラスペシャリスト、Oracleの全てを知り尽くすDBスペシャリスト、データ解析プラットフォームの構築エンジニアや、Webフロントエンドのスペシャリストまで様々。</p><p>彼らが輪読会中のちょっと専門用語に反応して、自らの経験を話してくれたのは非常に勉強になりました。</p><p>ここだけの話、1番盛り上がったのは「11章のオンコール対応」や「13章　緊急対応」です。<br>みなさん、システムのグランドデザインから保守運用まで対応されているメンバーが多かったので、実感が伴った「わかるわかる」とか、「あるよねー」と同意が連発していました。</p><p>他にも、リスクの管理手法として「エラーバジェット」という概念は、全てにおいて数値というファクトベースに改善サイクルを回るGoogleらしいなとみんなで感心していました。</p><p>また、輪読会の中では、こういったGoogleの物語を聞いて「さすがぐーぐる、言ってることが違うな」とか「それぐーぐるだからできるもんっしょ」といった雰囲気でところどころ茶々を入れながら進められたので和気あいあいです。</p><h1 id="効果"><a href="#効果" class="headerlink" title="効果"></a>効果</h1><p>輪読会の効果として<strong>積読の解消</strong>は言うこともないでしょう。</p><p>興味があって買ったはいいものの、手をつけるにはあまりにも分厚い技術書が本棚に溜まっていく経験が多くのエンジニアにはあるはずです。その中の一冊をみんなと協力して分担して読み終えていくのは、勉強会的な要素も含めると、シナジー効果があり効率的だと思います。</p><p>実際こういった輪読会の読書法は、ある程度ざっくりした内容を頭の中に掴んでおいて、必要になった時に必要な部分を思い出して熟読するスタイルの<em>カタログのような技術書</em>にはぴったりだなと思っているところです。</p><p>その他にも、勉強会でも得られる以下のような効果がありました。</p><ul><li>関連経験・知見の共有</li><li>人脈を広げる</li><li>内容の批評</li><li>コミュニケーションコストを節約できるコンテキストの共有<ul><li>本に出ているコンセプトと用語(バジェット・トイル・ポストモーテムなど)</li></ul></li></ul><p>週1ペースで1時間にも満たない時間でこれだけの効果があるということで、これからも継続しようと話しています。</p><h1 id="個人の所感"><a href="#個人の所感" class="headerlink" title="個人の所感"></a>個人の所感</h1><p>1冊の本で数回を繰り返す輪読会というのは<em>「本の読解」「要約」「プレゼンテーション」</em>というフローなのですが、完全に国語能力が要求されると感じました。回を繰り返すにつれ、斜め読みなどで読書の効率を上げたり、聞く人のコンテキストに合わせてうまく説明するなど工夫をこらしましたが、慣れるまでは冗長な説明をしてしまうなど大変でした。</p><h1 id="Site-Reliability-Engineeringについて"><a href="#Site-Reliability-Engineeringについて" class="headerlink" title="Site Reliability Engineeringについて"></a>Site Reliability Engineeringについて</h1><p>Googleが提唱したSREとはどういったもので、どういう道のりをたどって現在に至ったのかを記した知人曰く<em>インフラエンジニアのバイブル</em>のような内容です。</p><p>インプラエンジニア、もしくは運用エンジニアの要素として自動化・モニタリング・SLO・オンコール対応・リリースなどに加えマネジメント・ポストモーテム・教育などにも触れています。</p><p>感想としては、なんというかイマドキのインフラエンジニアならばこういったものは当たり前だろといった感じでした。</p><p>しかし、実際こういった当たり前のことを当たり前のようにやることも大変難しいものですし、Googleの場合、それをはるか以前から研究・実践し、当たり前というトレンドを自ら先導し、エンジニア界隈に拡散させたと考えることもできるではないでしょうか。</p><p>あと、これは弊社<a href="https://twitter.com/shibu_jp" target="_blank" rel="noopener">渋川さん</a>からの引用で、会のみんなも同意した話ですが<strong>Google SREのみんなが書きあげた同人誌の総集編</strong>と一言で言えるものでした。各章はまるである勉強会の一つのセッションのような感覚で読めると思います。</p><h1 id="System-Performance、それから…"><a href="#System-Performance、それから…" class="headerlink" title="System Performance、それから…"></a>System Performance、それから…</h1><p>SRE本を無事終えて、2冊目は<a href="https://www.oreilly.co.jp/books/9784873117904/" target="_blank" rel="noopener">詳解 システム・パフォーマンス</a>が選ばれ絶賛輪読中です。次の本はもう少し軽いものがいいなと願ってましたがSRE本より厚くなるとは皮肉なものですね。</p><img src="/images/20190729/photo_20190729_01.png"><p>今後はConnpassなどで外部の人を招待し、もっと輪を広げていこうと考えています。</p><h1 id="さいごに"><a href="#さいごに" class="headerlink" title="さいごに"></a>さいごに</h1><p>TIG/DXユニットでは社外の勉強会への参加以外にも、様々な社内勉強会を企画運営しています。</p><p>ぜひDXユニットに興味を持っていただけたら、 Qiita Jobsもご覧いただけると幸いです。<br><a href="https://jobs.qiita.com/employers/future/development_teams/109" target="_blank" rel="noopener">https://jobs.qiita.com/employers/future/development_teams/109</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。DXユニットはTIGの中でも特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">フューチャー技術ブログの運営をしていたり、過去には新人研修に関わっていたため、比較的顔が広いと思われたようです。</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;TIG/DXユニット&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;所属のLEEです。&lt;/p&gt;
&lt;p&gt;2019年より社内で輪読会を企画運営し、このたび初回の課題図書になってた&lt;a href=&quot;https
      
    
    </summary>
    
      <category term="Culture" scheme="https://future-architect.github.io/categories/Culture/"/>
    
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/tags/Infrastructure/"/>
    
  </entry>
  
  <entry>
    <title>Future IoTのstackshareを公開しました</title>
    <link href="https://future-architect.github.io/articles/20190723/"/>
    <id>https://future-architect.github.io/articles/20190723/</id>
    <published>2019-07-22T23:35:13.000Z</published>
    <updated>2019-07-22T23:43:43.509Z</updated>
    
    <content type="html"><![CDATA[<p>こんにちは。TIG<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> DXユニット<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> の武田です。</p><p>先日「Future IoT」のstackshareを公開しました。<br><a href="https://stackshare.io/future-corporation/futureiot" target="_blank" rel="noopener">https://stackshare.io/future-corporation/futureiot</a>  </p><img src="/images/20190723/photo_20190723_01.png" style="border:solid 1px #000000"><p>Futureとしてstackshareを活用するのは初めての試みとなりますが、本記事では公開に至った経緯や技術スタックの採用戦略について簡単にお伝えできればと思います。</p><h2 id="stackshareとは"><a href="#stackshareとは" class="headerlink" title="stackshareとは"></a>stackshareとは</h2><img src="/images/20190723/photo_20190723_02.png"><p><a href="https://stackshare.io" target="_blank" rel="noopener">https://stackshare.io</a><br>世界中のツールやサービスがどのような技術スタックを使っているかチェックできるサービスになります。FacebookやTwitterといった有名企業もstackshareで自社の技術スタックを公開しています。  </p><p>また「The Top 50 Developer Tools」という形で毎年、各企業が利用したツールのランキングも発表されています。<br><a href="https://stackshare.io/posts/top-developer-tools-2018" target="_blank" rel="noopener">https://stackshare.io/posts/top-developer-tools-2018</a><br>世の中の技術的なトレンドを掴むことが求められるエンジニアにとって非常に有用なサービスとなっています。</p><h2 id="Future-IoT-とは"><a href="#Future-IoT-とは" class="headerlink" title="Future IoT とは"></a>Future IoT とは</h2><p>Futureが提供するIoTの活用に特化したコンサルティングサービスです。<br>Future IoTは「トータルデザイン」をコンセプトにしており、ハードウェアデバイス、通信、データ解析などのアーキテクチャ全体のデザインから構築までを一貫して提供します。</p><p>詳細については次の記事で紹介されてますので、ぜひご覧ください。</p><blockquote><p>IoT/M2M展へ「Future IoT」出展してきました！<br><a href="https://future-architect.github.io/articles/20190509/">https://future-architect.github.io/articles/20190509/</a></p></blockquote><h2 id="なぜ公開に至ったか"><a href="#なぜ公開に至ったか" class="headerlink" title="なぜ公開に至ったか"></a>なぜ公開に至ったか</h2><p>昨今の技術トレンドとしてオープンな技術がますます主役になってきていますが、それはコンサルティングサービスとて例外ではありません。</p><p>DXユニットでは「オープンであること」を組織のテーマとしており、自分たちが採用している技術についても積極的に世の中に発信することで、技術力をアピールし、プレゼンスを向上させていきたいと考えています。<br>また、自分たちの採用技術に精通した世の中のエンジニアにアプローチし、積極的に採用につなげていくといった狙いもあります。</p><p>このような経緯からstackshareの公開に至りました。</p><h2 id="技術採用戦略について"><a href="#技術採用戦略について" class="headerlink" title="技術採用戦略について"></a>技術採用戦略について</h2><p>stackshareを見るとFuture IoTでは下記のようなプロダクト、サービスを採用しています。（抜粋）</p><table><thead><tr><th>分類</th><th>プロダクト、サービス</th></tr></thead><tbody><tr><td>Messaging</td><td>Apache Kafka, Mosquitto</td></tr><tr><td>Data Processing</td><td>Spark Streaming, Hadoop</td></tr><tr><td>Data Store</td><td>HBase, Google Big Query, Google Cloud SQL, Elasticsearch</td></tr><tr><td>Language</td><td>Golang, Java</td></tr><tr><td>Business Tools</td><td>Slack, Confluence, drawio</td></tr></tbody></table><p>ここで記載した技術スタックはあくまで実績に基づいた一例であり、この技術に縛られるということはありません。Future IoT、ひいてはDXユニットでは下記のコンセプトに基づいてお客様にとって最適な技術を選定しています。</p><h4 id="オープンであること"><a href="#オープンであること" class="headerlink" title="オープンであること"></a>オープンであること</h4><p>先にも述べましたがオープンな技術を積極的に採用します。<br>これはコスト面での優位性だけでなく、ベンダロックインを避けることなどを目的としています。</p><p>一方で各種クラウドベンダのフルマネージドサービスのようなものを選択しないということではありません。コスト面、拡張性、移植性、ロックインのリスクといったさまざまな要素を考慮し、OSSとマネージドサービスをフラットに比較し最適なものを選択しています。</p><h4 id="モダンかつ高度な技術であること"><a href="#モダンかつ高度な技術であること" class="headerlink" title="モダンかつ高度な技術であること"></a>モダンかつ高度な技術であること</h4><p>最新の技術スタックを積極的に採用し、常に最先端の技術にキャッチアップします。<br>これはお客さまに最先端のコンサルティングサービスを提供するということはもちろん、社内エンジニアの技術力やモチベーションを向上していくことも狙いとしています。<br>DXユニットは社内組織の中でも特に最先端の技術にチャレンジする文化を大切にしています。</p><h4 id="選択可能、交換可能であること"><a href="#選択可能、交換可能であること" class="headerlink" title="選択可能、交換可能であること"></a>選択可能、交換可能であること</h4><p>疎結合なアーキテクチャを尊重します。<br>これはシステム全体として特定のサービス、プロダクトに密に依存することを避け、特定の領域においてプロダクトやサービスを切り替え可能にすることを意味しています。</p><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><p>stackshareについてはひとまず公開してみたというレベルですが、これから技術スタックの拡充や各プロダクトの選定理由の記載も進めていきたいと考えています。<br>選定理由の記載を進めると「Stack Profile Strength」というランクがアップしていくみたいですね。</p><p>ぜひDXユニットに興味を持っていただけたら、 Qiita Jobsもご覧いただけると幸いです。<br><a href="https://jobs.qiita.com/employers/future/development_teams/109" target="_blank" rel="noopener">https://jobs.qiita.com/employers/future/development_teams/109</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">TIGの中でも特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;こんにちは。TIG&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; DXユニット&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 
      
    
    </summary>
    
      <category term="IoT" scheme="https://future-architect.github.io/categories/IoT/"/>
    
    
      <category term="IoT" scheme="https://future-architect.github.io/tags/IoT/"/>
    
  </entry>
  
  <entry>
    <title>― 脱RDB脳 ― Cassandraのデータモデルについて考えてみる</title>
    <link href="https://future-architect.github.io/articles/20190718/"/>
    <id>https://future-architect.github.io/articles/20190718/</id>
    <published>2019-07-18T00:11:12.000Z</published>
    <updated>2019-07-17T23:36:27.495Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは、Technology Innovation Group所属 DBチームの岩崎です。</p><p>私はDBチームとして様々なプロジェクトでOracleやPostgreSQLなどRDBの設計・構築に携わってきました。<br>現在は、Cassandraの導入とデータモデルを設計しています。</p><p>本稿ではDBネタとしてRDB脳から脱却して、KVSならではのテーブル設計の勘所をお伝えいたします。</p><h1 id="Cassandraはどのようなデータベースなのか"><a href="#Cassandraはどのようなデータベースなのか" class="headerlink" title="Cassandraはどのようなデータベースなのか"></a>Cassandraはどのようなデータベースなのか</h1><p>CassandraはKVS(Key-ValueStore）と呼ばれ、KeyとValueを組み合わせる単純な構造からなるDBです。<br>データアクセスはkeyに対して行い、Keyに関連付けられたValueが呼び出されます。</p><p>KVSは一般的にスキーマレスを採用することが多いと思いますが、Cassandraではアプリケーションの観点から見て、データは構造的に扱える方が開発・運用・管理していく上でメリットがあるとのスタンスを取っているため、スキーマレスではなくスキーマ定義を必要としています。</p><p>また、keyに対して複数のカラムを定義することが可能で、カラム型にはListやMapのようなコレクション型、いわゆるオブジェクト型のようなユーザ定義型（UDT:User Defined Type）の使用に対応しているため、JSONのような階層的なデータをスキーマ定義して柔軟に扱うことができるのが特徴です。</p><p>その他、本稿では触れませんが下記のような特徴を持っており、スケーラビリティ・アベイラビリティに重きを置いたデータベースと言えます。</p><ol><li>データをクラスタ内の複数ノードで分散保持しているため、性能・容量のリニアにスケール可能  </li><li>マスタレスアーキテクチャで、単一障害点がなくノード障害時のマスタ切り替え不要で可用性を厳格に保証  </li><li>データセンターを跨ぐクロスリージョン構成を取ることができ、広域災害時の高いBCP要求を満たすことが可能  </li></ol><h1 id="Cassandraのデータモデルを理解する"><a href="#Cassandraのデータモデルを理解する" class="headerlink" title="Cassandraのデータモデルを理解する"></a>Cassandraのデータモデルを理解する</h1><p>Cassandraにおいてデータをどのように定義して扱うことができるのかということを説明していきます。<br>CassandraはCQLというSQLライクなクエリ言語を用いて記述できるためRDB脳でも直感的に扱えます。<br>なお、本項ではCassandraのバージョンは3.11.4を利用します。</p><h2 id="テーブル作成"><a href="#テーブル作成" class="headerlink" title="テーブル作成"></a>テーブル作成</h2><p>CassandraではRDBと同様にデータをテーブルという単位で管理を行います。<br>KVSではデータの管理、アクセスはkeyに対して行うため、PRIMARY KEYとして定義する必要があります。<br>Valueに相当するカラムは複数定義可能で配列やMapなどのコレクション型もデータ型として定義することが可能です。</p><h3 id="テーブル定義"><a href="#テーブル定義" class="headerlink" title="テーブル定義"></a>テーブル定義</h3><p>PRIMARY KEYに指定したカラムがKVSにおけるkey項目です。</p><figure class="highlight sql"><figcaption><span>テーブル定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_table (</span><br><span class="line">   <span class="keyword">id</span>      <span class="built_in">text</span></span><br><span class="line"> , <span class="keyword">body</span>    <span class="built_in">text</span></span><br><span class="line"> , tag     <span class="keyword">list</span>&lt;<span class="built_in">text</span>&gt;</span><br><span class="line"> , keyword <span class="keyword">map</span>&lt;<span class="built_in">text</span>, <span class="built_in">text</span>&gt;</span><br><span class="line"> , PRIMARY <span class="keyword">KEY</span>(<span class="keyword">id</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="レコード作成"><a href="#レコード作成" class="headerlink" title="レコード作成"></a>レコード作成</h3><figure class="highlight sql"><figcaption><span>レコード作成</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_table (</span><br><span class="line">   <span class="keyword">id</span></span><br><span class="line"> , <span class="keyword">body</span></span><br><span class="line"> , tag</span><br><span class="line"> , keyword</span><br><span class="line">) <span class="keyword">VALUES</span> (</span><br><span class="line">   <span class="string">'01'</span></span><br><span class="line"> , <span class="string">'Cassandraデータモデリングの紹介'</span></span><br><span class="line"> , [<span class="string">'Future'</span>,<span class="string">'Tech Blog'</span>]</span><br><span class="line"> , &#123;<span class="string">'author'</span>: <span class="string">'Iwasaki'</span>, <span class="string">'nosql'</span>:<span class="string">'cassandra'</span>&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>このようにCassandraでは扱うデータをテーブルとしてスキーマ定義して管理します。<br>次にデータアクセス方法について見ていきましょう。</p><h2 id="データアクセス-PRIMARY-KEY"><a href="#データアクセス-PRIMARY-KEY" class="headerlink" title="データアクセス(PRIMARY KEY)"></a>データアクセス(PRIMARY KEY)</h2><p>データベース内に作成したテーブルにアクセスするにはkeyをWHERE句に指定してアクセスを行います。<br>KVSの特徴は基本的にはkey以外をWHERE句の絞り込み条件に指定できないという点です。</p><h3 id="keyを指定してデータアクセス"><a href="#keyを指定してデータアクセス" class="headerlink" title="keyを指定してデータアクセス"></a>keyを指定してデータアクセス</h3><figure class="highlight"><figcaption><span>Key指定のデータアクセス</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> test_table <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'01'</span>;</span><br><span class="line"></span><br><span class="line"> id | body                            | keyword                                     | tag</span><br><span class="line"><span class="comment">----+---------------------------------+---------------------------------------------+-------------------------</span></span><br><span class="line"> 01 | Cassandraデータモデリングの紹介 | &#123;'author': 'Iwasaki', 'nosql': 'cassandra'&#125; | ['Future', 'Tech Blog']</span><br></pre></td></tr></table></figure><h3 id="key以外を指定してデータアクセス"><a href="#key以外を指定してデータアクセス" class="headerlink" title="key以外を指定してデータアクセス"></a>key以外を指定してデータアクセス</h3><figure class="highlight"><figcaption><span>Key以外を指定した場合のデータアクセス</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> test_table <span class="keyword">where</span> <span class="keyword">body</span> = <span class="string">'Cassandraデータモデリングの紹介'</span>;</span><br><span class="line"></span><br><span class="line">-&gt; key以外をWHERE句に指定したためクエリの実行に失敗する</span><br></pre></td></tr></table></figure><p>このようにRDBでは当たり前のようにできたWHERE句による絞り込みが、KVSではできないということを念頭にデータモデルを設計する必要があります。</p><p>実際は全くできないというわけではないものの制限があるため、できないというスタンスにたって設計したほうが無難と考えられます。</p><h2 id="データアクセス-PARTITION-KEY"><a href="#データアクセス-PARTITION-KEY" class="headerlink" title="データアクセス(PARTITION KEY)"></a>データアクセス(PARTITION KEY)</h2><p>CassandraはKVSのため基本的には上記のPRIMARY KEYによるデータアクセスになりますが、もう一つの特徴としてPARTITION KEYによるデータアクセスが可能です。</p><p>PARTITION KEYとはレコードをカラム単位で集約するキーのことを意味します。</p><p>先ほど作成したtest_tableに対して日付単位で集約できるようにPARTITION KEYを追加してみましょう。</p><h3 id="テーブル定義-1"><a href="#テーブル定義-1" class="headerlink" title="テーブル定義"></a>テーブル定義</h3><p>PRIMARY KEYの先頭項目がPARTITION KEYと認識されます。<br>下記の例ではPARTITION KEYがdate、PRIMARY KEYはdateとidの複合になります。  </p><figure class="highlight sql"><figcaption><span>パーティションキー付きのテーブル定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_part_table (</span><br><span class="line">   <span class="built_in">date</span>    <span class="built_in">text</span></span><br><span class="line"> , <span class="keyword">id</span>      <span class="built_in">text</span></span><br><span class="line"> , <span class="keyword">body</span>    <span class="built_in">text</span></span><br><span class="line"> , tag     <span class="keyword">list</span>&lt;<span class="built_in">text</span>&gt;</span><br><span class="line"> , keyword <span class="keyword">map</span>&lt;<span class="built_in">text</span>, <span class="built_in">text</span>&gt;</span><br><span class="line"> , PRIMARY <span class="keyword">KEY</span>((<span class="built_in">date</span>), <span class="keyword">id</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="レコード作成-1"><a href="#レコード作成-1" class="headerlink" title="レコード作成"></a>レコード作成</h3><figure class="highlight sql"><figcaption><span>レコード作成</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_part_table (</span><br><span class="line">   <span class="built_in">date</span></span><br><span class="line"> , <span class="keyword">id</span></span><br><span class="line"> , <span class="keyword">body</span></span><br><span class="line"> , tag</span><br><span class="line"> , keyword</span><br><span class="line">) <span class="keyword">VALUES</span> (</span><br><span class="line">   <span class="string">'2019-07-01'</span></span><br><span class="line"> , <span class="string">'01'</span></span><br><span class="line"> , <span class="string">'パーティションキーテスト1'</span></span><br><span class="line"> , [<span class="string">'Future'</span>,<span class="string">'Tech Blog'</span>]</span><br><span class="line"> , &#123;<span class="string">'author'</span>: <span class="string">'Iwasaki'</span>, <span class="string">'nosql'</span>:<span class="string">'cassandra'</span>&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_part_table (</span><br><span class="line">   <span class="built_in">date</span></span><br><span class="line"> , <span class="keyword">id</span></span><br><span class="line"> , <span class="keyword">body</span></span><br><span class="line"> , tag</span><br><span class="line"> , keyword</span><br><span class="line">) <span class="keyword">VALUES</span> (</span><br><span class="line">   <span class="string">'2019-07-01'</span></span><br><span class="line"> , <span class="string">'02'</span></span><br><span class="line"> , <span class="string">'パーティションキーテスト2'</span></span><br><span class="line"> , [<span class="string">'Future'</span>,<span class="string">'Tech Blog'</span>]</span><br><span class="line"> , &#123;<span class="string">'author'</span>: <span class="string">'Iwasaki'</span>, <span class="string">'nosql'</span>:<span class="string">'cassandra'</span>&#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_part_table (</span><br><span class="line">   <span class="built_in">date</span></span><br><span class="line"> , <span class="keyword">id</span></span><br><span class="line"> , <span class="keyword">body</span></span><br><span class="line"> , tag</span><br><span class="line"> , keyword</span><br><span class="line">) <span class="keyword">VALUES</span> (</span><br><span class="line">   <span class="string">'2019-07-02'</span></span><br><span class="line"> , <span class="string">'01'</span></span><br><span class="line"> , <span class="string">'パーティションキーテスト3'</span></span><br><span class="line"> , [<span class="string">'Future'</span>,<span class="string">'Tech Blog'</span>]</span><br><span class="line"> , &#123;<span class="string">'author'</span>: <span class="string">'Iwasaki'</span>, <span class="string">'nosql'</span>:<span class="string">'cassandra'</span>&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="PARTITION-KEYを指定してデータアクセス"><a href="#PARTITION-KEYを指定してデータアクセス" class="headerlink" title="PARTITION KEYを指定してデータアクセス"></a>PARTITION KEYを指定してデータアクセス</h3><p>PARTITION KEYのdateをWHERE句の条件に指定してデータアクセスしてみると、PARTITION KEY単位で集約されたデータを取得することができます。</p><figure class="highlight"><figcaption><span>パーティションキーを指定してのデータアクセス</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> test_part_table <span class="keyword">where</span> <span class="built_in">date</span> = <span class="string">'2019-07-01'</span>;</span><br><span class="line"></span><br><span class="line"> date       | id | body                      | keyword                                     | tag</span><br><span class="line"><span class="comment">------------+----+---------------------------+---------------------------------------------+-------------------------</span></span><br><span class="line"> 2019-07-01 | 01 | パーティションキーテスト1 | &#123;'author': 'Iwasaki', 'nosql': 'cassandra'&#125; | ['Future', 'Tech Blog']</span><br><span class="line"> 2019-07-01 | 02 | パーティションキーテスト2 | &#123;'author': 'Iwasaki', 'nosql': 'cassandra'&#125; | ['Future', 'Tech Blog']</span><br><span class="line"></span><br><span class="line">-&gt; 2019-07-01のレコード2件が取得可能</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> test_part_table <span class="keyword">where</span> <span class="built_in">date</span> = <span class="string">'2019-07-02'</span>;</span><br><span class="line"></span><br><span class="line"> date       | id | body                      | keyword                                     | tag</span><br><span class="line"><span class="comment">------------+----+---------------------------+---------------------------------------------+-------------------------</span></span><br><span class="line"> 2019-07-02 | 01 | パーティションキーテスト3 | &#123;'author': 'Iwasaki', 'nosql': 'cassandra'&#125; | ['Future', 'Tech Blog']</span><br><span class="line"></span><br><span class="line">-&gt; 2019-07-02のレコード1件が取得可能</span><br></pre></td></tr></table></figure><p>このようにCassandraではPARTITION KEY単位による列ごとに集約されたデータアクセスが可能なため、KVSの中でもワイドカラムストア(列指向型)と呼ばれることがあります。</p><p>CassandraではPARTITION KEYのハッシュ値を基に物理的なデータ配置箇所を決定しています。</p><p>Cassandraは複数ノードでクラスタ構成を取ることが一般的ですが、同一PARTITION KEYのデータは、（複数の）特定ノード内に集約されてデータが格納されます。</p><p>そのため、検索条件にPARTITION KEYを指定することで対象のキーのデータをどのノードが保持しているかということが分かるため、サーバーの並列数やデータ量が増えても高速にデータアクセスすることが可能になります。</p><p>言い換えれば、PARTITION KEYが無いと全ノードの全レコードを舐めないと条件に一致するかを評価することができないので、KVSはキーアクセスしか行えないということになります。</p><p>ちなみに複合PRIMARY KEYを定義する場合、特に指定がなければ先頭のキーがPARTITION KEYとなり、単一PRIMARY KEYの場合はPRIMARY KEY = PARTITION KEYとして認識されています。  </p><p>また、PARTITION KEY以外のPRIMARY KEYはCLUSTERING KEYと呼ばれ、パーティション内のデータのソートキーとなっています。</p><p>PARTITION KEYのみを指定してデータを取得する際の動作は、RDB脳にはなじみ深いB*TreeインデックスをRANGE SCANする動作と同様です。</p><p>本記事のなかではあまりふれませんが、CLUSTERING KEYによるソート順に従って先頭の〇〇件を取得する、といったことも可能です。</p><h2 id="データ更新"><a href="#データ更新" class="headerlink" title="データ更新"></a>データ更新</h2><p>Cassandraはテーブル構造を事前に定義しているため、RDB同様に特定のカラムに対する更新が可能です。<br>また、配列やMapで定義した項目に対しても要素の追加や削除など柔軟に更新を行うことができます。</p><h3 id="Map型のデータ更新"><a href="#Map型のデータ更新" class="headerlink" title="Map型のデータ更新"></a>Map型のデータ更新</h3><p>先ほど作成したtest_tableのMap型で定義したkeywordに対して要素の追加や更新を行ってみましょう。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> keyword <span class="keyword">from</span> test_table <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'01'</span>;</span><br><span class="line"></span><br><span class="line"> keyword</span><br><span class="line"><span class="comment">---------------------------------------------</span></span><br><span class="line"> &#123;'author': 'Iwasaki', 'nosql': 'cassandra'&#125;</span><br></pre></td></tr></table></figure><p>Mapのkey要素であるauthorを指定してvalueを書き換えてみます。</p><figure class="highlight"><figcaption><span>Mapの要素を書き換え</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> test_table <span class="keyword">SET</span> keyword[<span class="string">'author'</span>] = <span class="string">'Yuta'</span> <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="string">'01'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> keyword <span class="keyword">from</span> test_table <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'01'</span>;</span><br><span class="line"></span><br><span class="line"> keyword</span><br><span class="line"><span class="comment">------------------------------------------</span></span><br><span class="line"> &#123;'author': 'Yuta', 'nosql': 'cassandra'&#125;</span><br></pre></td></tr></table></figure><p>Mapの要素を足してみます。</p><figure class="highlight"><figcaption><span>Mapの要素を追加</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> test_table <span class="keyword">SET</span> keyword = keyword + &#123;<span class="string">'category'</span>: <span class="string">'db'</span>&#125; <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="string">'01'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> keyword <span class="keyword">from</span> test_table <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'01'</span>;</span><br><span class="line"></span><br><span class="line"> keyword</span><br><span class="line"><span class="comment">------------------------------------------------------------</span></span><br><span class="line"> &#123;'author': 'Yuta', 'category': 'db', 'nosql': 'cassandra'&#125;</span><br></pre></td></tr></table></figure><h1 id="Cassandraのデータモデリングについて考える"><a href="#Cassandraのデータモデリングについて考える" class="headerlink" title="Cassandraのデータモデリングについて考える"></a>Cassandraのデータモデリングについて考える</h1><p>なんとなくCassandraでデータをどのように扱うか理解できましたでしょうか。</p><p>ここからはどのようにデータモデルを考えていくべきかをチャットテーブルを例に説明していきます。</p><h2 id="チャットのデータモデル概要"><a href="#チャットのデータモデル概要" class="headerlink" title="チャットのデータモデル概要"></a>チャットのデータモデル概要</h2><p>チャット管理に関するリレーショナルモデルのテーブル設計を元に考えてみましょう。</p><ul><li>チャットルーム<ul><li>ユーザ、グループ毎にチャットを管理するテーブル。</li></ul></li><li>チャット<ul><li>チャットの投稿内容の詳細を管理するテーブル</li></ul></li><li>リアクション<ul><li>チャットの投稿に対するスタンプなどのリアクションを管理するテーブル</li></ul></li></ul><img src="/images/20190718/photo_20190718_01.png" class="img-middle-size"><p>例えばRDBであれば上記のままの3つのテーブルを作成することが考えられます。</p><p>しかし、KVSは単一テーブルに対するキーアクセスのみを可能にしたデータベースであるため、RDBのように複数テーブル間を結合することができないという点がKVSとRDBとの最大の違いです。</p><p>KVSにおけるテーブル設計では、ある機能を実現するためのテーブルは基本的に1つで足りる（であろう）というスタンスに立ち、まず上記のテーブルを1テーブルに集約できないかを考えます。</p><p>また、KVSでは結合だけでなくトランザクションも存在しないため(単一レコードに対する軽量トランザクションのみ)テーブルを分割すると、アプリケーションの作りが複雑化してしまうという問題もあります。</p><p>そのため、まずはテーブルを集約することを意識していきましょう。</p><h2 id="テーブル集約のポイント"><a href="#テーブル集約のポイント" class="headerlink" title="テーブル集約のポイント"></a>テーブル集約のポイント</h2><p>RDBのようにフラットな階層でデータモデルを表現するためには結合が必須です。<br>しかし、KVSは配列やMapのようなコレクション型を扱えるという点が集約のポイントになります。</p><p>例えばチャットとリアクションの関係をコレクション型を利用して１つのテーブルとして表現してみましょう。<br>チャットに対してリアクションをコレクション型で定義することで1チャットに対してN数のリアクションを表現できます。</p><h3 id="Map型を利用した集約"><a href="#Map型を利用した集約" class="headerlink" title="Map型を利用した集約"></a>Map型を利用した集約</h3><p>reactionをMap型で定義することでユーザ別のリアクションを表現できるようになりました。<br>更新時もMap要素を指定して行えるため追加や削除を柔軟に行えます。</p><figure class="highlight sql"><figcaption><span>Map型を利用したチャットテーブル定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> chat (</span><br><span class="line">    <span class="keyword">id</span>        <span class="built_in">text</span>              <span class="comment">-- チャットID</span></span><br><span class="line">  , <span class="keyword">body</span>      <span class="built_in">text</span>              <span class="comment">-- チャット本文</span></span><br><span class="line">  , <span class="keyword">user</span>      <span class="built_in">text</span>              <span class="comment">-- 投稿者</span></span><br><span class="line">  , send_date <span class="built_in">text</span>              <span class="comment">-- 投稿日付</span></span><br><span class="line">  , reaction  <span class="keyword">map</span>&lt;<span class="built_in">text</span>, <span class="built_in">text</span>&gt;   <span class="comment">-- リアクション</span></span><br><span class="line">  , PRIMARY <span class="keyword">KEY</span>(<span class="keyword">id</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>次にチャットルームとチャットの関係を1つのテーブルとして表現してみましょう。</p><p>チャットルームには最終投稿日付やチャットルーム参加者などチャットにとっての付随情報を管理をするため、RDBではチャットルームIDをFKとしてチャット側に持たせるという考え方になると思います。</p><p>ここもコレクションを利用してチャットルームにチャット情報を集約してみましょう。</p><p>chatをMap型で定義することでチャットテーブルにチャットの情報を持たせることができます。</p><figure class="highlight sql"><figcaption><span>Map型を利用したチャットルームテーブル定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> chatroom (</span><br><span class="line">    <span class="keyword">id</span>            <span class="built_in">text</span>              <span class="comment">-- チャットルームID</span></span><br><span class="line">  , last_update   <span class="built_in">text</span>              <span class="comment">-- 最終更新日付</span></span><br><span class="line">  , <span class="keyword">member</span>        <span class="keyword">set</span>&lt;<span class="built_in">text</span>&gt;         <span class="comment">-- 参加者</span></span><br><span class="line">  , chat          <span class="keyword">map</span>&lt;<span class="built_in">text</span>, <span class="built_in">text</span>&gt;   <span class="comment">-- チャット情報</span></span><br><span class="line">  , PRIMARY <span class="keyword">KEY</span>(<span class="keyword">id</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>しかし、上記のようなMap型（map&lt;text, text&gt;）では単一項目のvalueしか持てないためチャットの情報を表現しきることができません。</p><p>そこでユーザ定義型(UDT)という複数のフィールドと型を定義して利用します。</p><h3 id="UDT型を利用した集約"><a href="#UDT型を利用した集約" class="headerlink" title="UDT型を利用した集約"></a>UDT型を利用した集約</h3><p>chatの情報をUDTとして定義してみましょう。</p><p>UDTはテーブルではなくタイプとして定義（CREATE）されます。タイプにはPKを指定する必要はありません。</p><p>UDTのフィールドにMapなどのコレクション型を定義することもできます。</p><figure class="highlight sql"><figcaption><span>UDT型の定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TYPE</span> chat_type (</span><br><span class="line">    <span class="keyword">body</span>      <span class="built_in">text</span>              <span class="comment">-- チャット本文</span></span><br><span class="line">  , <span class="keyword">user</span>      <span class="built_in">text</span>              <span class="comment">-- 投稿者</span></span><br><span class="line">  , send_date <span class="built_in">text</span>              <span class="comment">-- 投稿日付</span></span><br><span class="line">  , reaction  <span class="keyword">map</span>&lt;<span class="built_in">text</span>, <span class="built_in">text</span>&gt;   <span class="comment">-- リアクション</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>上記で作ったUDTを利用してチャットルームとチャットを集約してみましょう。<br>先ほどの作ったUDTをデータ型として指定することができます。</p><p>ただし注意しなければならない点は、コレクション型の中でUDTを定義する場合、frozenという指定が必要になります。frozenの制約事項は後述します。</p><figure class="highlight sql"><figcaption><span>UDT型を利用したチャットルーム定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> chatroom (</span><br><span class="line">    <span class="keyword">id</span>            <span class="built_in">text</span></span><br><span class="line">  , chatroom_name <span class="built_in">text</span></span><br><span class="line">  , last_update   <span class="built_in">text</span></span><br><span class="line">  , <span class="keyword">member</span>        <span class="keyword">set</span>&lt;<span class="built_in">text</span>&gt;</span><br><span class="line">  , chat          <span class="keyword">map</span>&lt;<span class="built_in">text</span>, frozen&lt;chat_type&gt;&gt;</span><br><span class="line">  , PRIMARY <span class="keyword">KEY</span>(<span class="keyword">id</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> chatroom <span class="keyword">JSON</span></span><br><span class="line">  <span class="string">'&#123;</span></span><br><span class="line"><span class="string">    "id": "1",</span></span><br><span class="line"><span class="string">    "chatroom_name": "DB Tech Blog",</span></span><br><span class="line"><span class="string">    "last_update": "2019-07-01:12:00",</span></span><br><span class="line"><span class="string">    "member": ["iwasaki","sugiyama","mano"],</span></span><br><span class="line"><span class="string">    "chat": &#123;</span></span><br><span class="line"><span class="string">        "01": &#123;</span></span><br><span class="line"><span class="string">          "body" : "chat message 1",</span></span><br><span class="line"><span class="string">          "user" : "iwasaki",</span></span><br><span class="line"><span class="string">          "send_date" : "2019-07-01:10:00",</span></span><br><span class="line"><span class="string">          "reaction" : &#123; "sugiyama" : "reaction 1"&#125;</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        "02": &#123;</span></span><br><span class="line"><span class="string">          "body" : "chat message 2",</span></span><br><span class="line"><span class="string">          "user" : "iwasaki",</span></span><br><span class="line"><span class="string">          "send_date" : "2019-07-01:11:00"</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        "03": &#123;</span></span><br><span class="line"><span class="string">          "body" : "chat message 3",</span></span><br><span class="line"><span class="string">          "user" : "sugiyama",</span></span><br><span class="line"><span class="string">          "send_date" : "2019-07-01:12:00",</span></span><br><span class="line"><span class="string">          "reaction" : &#123; "iwasaki" : "reaction 1"&#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;'</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> chat <span class="keyword">from</span> chatroom <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line"> chat</span><br><span class="line"><span class="comment">----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span></span><br><span class="line"> &#123;'01': &#123;body: 'chat message 1', user: 'iwasaki', send_date: '2019-07-01:10:00', reaction: &#123;'sugiyama': 'reaction 1'&#125;&#125;, '02': &#123;body: 'chat message 2', user: 'iwasaki', send_date: '2019-07-01:11:00', reaction: null&#125;, '03': &#123;body: 'chat message 3', user: 'sugiyama', send_date: '2019-07-01:12:00', reaction: &#123;'iwasaki': 'reaction 1'&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><p>UDTを利用することでチャットルームとチャットを集約することができました。</p><p>しかし、上記の集約例だと2つの問題点が存在します。</p><h3 id="問題点1-投稿数-要素数となるためコレクションサイズが肥大化し過ぎる"><a href="#問題点1-投稿数-要素数となるためコレクションサイズが肥大化し過ぎる" class="headerlink" title="問題点1. 投稿数 = 要素数となるためコレクションサイズが肥大化し過ぎる"></a>問題点1. 投稿数 = 要素数となるためコレクションサイズが肥大化し過ぎる</h3><p>Cassandraのドキュメントによると、mapコレクションのキーの最大数は65,535しか持てないと記述されています。</p><p>また、コレクション要素全てを読み込んでしまうのでアクセス効率も悪くなります。</p><p>つまり、チャットルームにチャットの情報をコレクション型で集約してしまうと1チャットルーム内で投稿できるチャット数が制限されてしまい、要件を満たせなくなる可能性があります。</p><p>チャットとリアクションのようにそこまでコレクションの要素が肥大化しない関係であれば積極的に集約していく価値がありますが、上記のパターンには注意が必要です。</p><h3 id="問題点2-chatの情報をfrozenで定義しているため柔軟な更新が行えなくなる"><a href="#問題点2-chatの情報をfrozenで定義しているため柔軟な更新が行えなくなる" class="headerlink" title="問題点2. chatの情報をfrozenで定義しているため柔軟な更新が行えなくなる"></a>問題点2. chatの情報をfrozenで定義しているため柔軟な更新が行えなくなる</h3><p>Cassandraではコレクション型の中でさらにコレクション型を定義するようなネスト構造を表現する際にfrozenを利用して定義します。</p><p>frozenを利用することで深い階層のデータを定義していくことができますが、frozenされた項目の値はBLOBと同様に処理されるようになるため、frozenされた項目に対して部分更新ができなくなります。</p><p>つまり先ほどのchatroomの例だと、chatがfrozenで定義されているためchatの項目を更新するためには、下記のようにchatの全項目を指定して更新する必要があります。</p><h3 id="frozen項目の更新"><a href="#frozen項目の更新" class="headerlink" title="frozen項目の更新"></a>frozen項目の更新</h3><p>chatのbodyだけ更新するとbody以外の項目は全てnullとして扱われるのでデータロストしてしまいます。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> chatroom <span class="keyword">SET</span> chat[<span class="string">'01'</span>] = fromJson(</span><br><span class="line"><span class="string">'&#123; "body" : "chat message update 1"&#125;'</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="string">'1'</span></span><br><span class="line"></span><br><span class="line">cqlsh:<span class="keyword">test</span>&gt; <span class="keyword">select</span> chat <span class="keyword">from</span> chatroom <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line"> chat</span><br><span class="line"><span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span></span><br><span class="line"> &#123;'01': &#123;body: 'chat message update 1', user: null, send_date: null, reaction: null&#125;, '02': &#123;body: 'chat message 2', user: 'iwasaki', send_date: '2019-07-01:11:00', reaction: null&#125;, '03': &#123;body: 'chat message 3', user: 'sugiyama', send_date: '2019-07-01:12:00', reaction: &#123;'iwasaki': 'reaction 1'&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><p>下記のようにfrozen項目全体を含めて更新する必要があります。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> chatroom <span class="keyword">SET</span> chat[<span class="string">'01'</span>] = fromJson(</span><br><span class="line"><span class="string">'&#123;</span></span><br><span class="line"><span class="string">  "body" : "chat message update 1",</span></span><br><span class="line"><span class="string">  "user" : "iwasaki",</span></span><br><span class="line"><span class="string">  "send_date" : "2019-07-01:13:00",</span></span><br><span class="line"><span class="string">  "reaction" : &#123; "sugiyama" : "reaction 1"&#125;</span></span><br><span class="line"><span class="string">  &#125;'</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="string">'1'</span></span><br></pre></td></tr></table></figure><p>このように一見便利なfrozenですが安易に利用してネストを深くすると更新要件を満たすことができなくなる可能性があるので、注意が必要です。</p><h3 id="staticカラムを利用してテーブルを集約する"><a href="#staticカラムを利用してテーブルを集約する" class="headerlink" title="staticカラムを利用してテーブルを集約する"></a>staticカラムを利用してテーブルを集約する</h3><p>コレクション型を利用してチャットルームとチャットを集約するのは制約事項があることがわかりました。</p><p>Cassandraにおいてテーブル集約を考える際にもう一つ有効な手法としてstaticカラムというものがあります。</p><p>staticカラムとして定義することで対象のカラムはパーティション単位で同じデータが保持されるようになります。</p><figure class="highlight sql"><figcaption><span>staticカラムを利用したテーブル定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> static_test(</span><br><span class="line">  <span class="keyword">id</span>                <span class="built_in">text</span>,</span><br><span class="line">  <span class="keyword">no</span>                <span class="built_in">text</span>,</span><br><span class="line">  static_data       <span class="built_in">text</span> <span class="keyword">static</span>,</span><br><span class="line">  non_static_data   <span class="built_in">text</span>,</span><br><span class="line">  primary <span class="keyword">key</span>((<span class="keyword">id</span>),<span class="keyword">no</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> static_test <span class="keyword">json</span> <span class="string">'&#123;"id":"1","no":"1","static_data":"static_1","non_static_data":"non_static_1"&#125;'</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> static_test <span class="keyword">json</span> <span class="string">'&#123;"id":"1","no":"2","static_data":"static_1","non_static_data":"non_static_1"&#125;'</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> static_test <span class="keyword">json</span> <span class="string">'&#123;"id":"2","no":"1","static_data":"static_2","non_static_data":"non_static_2"&#125;'</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> static_test <span class="keyword">json</span> <span class="string">'&#123;"id":"2","no":"2","static_data":"static_2","non_static_data":"non_static_2"&#125;'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> static_test ;</span><br><span class="line"></span><br><span class="line"> id | no | static_data | non_static_data</span><br><span class="line"><span class="comment">----+----+-------------+-----------------</span></span><br><span class="line">  1 |  1 |    static_1 |    non_static_1</span><br><span class="line">  1 |  2 |    static_1 |    non_static_1</span><br><span class="line">  2 |  1 |    static_2 |    non_static_2</span><br><span class="line">  2 |  2 |    static_2 |    non_static_2</span><br></pre></td></tr></table></figure><h3 id="staticカラムを更新する"><a href="#staticカラムを更新する" class="headerlink" title="staticカラムを更新する"></a>staticカラムを更新する</h3><p>staticとして定義したstatic_dataを更新すると同一パーティション内のstatic_dataも更新されます。</p><figure class="highlight"><figcaption><span>staticカラムの更新</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> static_test <span class="keyword">set</span> static_data = <span class="string">'static_test_1'</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> static_test;</span><br><span class="line"></span><br><span class="line"> id | no | static_data   | non_static_data</span><br><span class="line"><span class="comment">----+----+---------------+-----------------</span></span><br><span class="line">  1 |  1 | static_test_1 |    non_static_1</span><br><span class="line">  1 |  2 | static_test_1 |    non_static_1</span><br><span class="line">  2 |  1 |      static_2 |    non_static_2</span><br><span class="line">  2 |  2 |      static_2 |    non_static_2</span><br><span class="line"></span><br><span class="line">-&gt; PARTITION KEY = '01'に対する更新だが、同パーティション内のstatic_dataも更新される</span><br></pre></td></tr></table></figure><p>staticで定義すると下記のように同一パーティション内のデータはstaticカラムを参照するようなデータ構造になるため、static項目を更新すると同一パーティション内のデータは全て更新されたように見えていたわけです。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123; <span class="attr">"id"</span> : <span class="number">1</span>, <span class="attr">"static_data"</span> : <span class="string">"static_test_1"</span>  &#123; </span><br><span class="line">        <span class="attr">"no"</span> : <span class="number">1</span>  &#123; <span class="attr">"non_static_data"</span> : <span class="string">"non_static_1"</span>&#125;,</span><br><span class="line">        <span class="attr">"no"</span> : <span class="number">2</span>  &#123; <span class="attr">"non_static_data"</span> : <span class="string">"non_static_1"</span>&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">&#125;,</span><br><span class="line">&#123; <span class="attr">"id"</span> : <span class="number">2</span>, <span class="attr">"static_data"</span> : <span class="string">"static_2"</span>  &#123; </span><br><span class="line">        <span class="attr">"no"</span> : <span class="number">1</span>  &#123; <span class="attr">"non_static_data"</span> : <span class="string">"non_static_2"</span>&#125;,</span><br><span class="line">        <span class="attr">"no"</span> : <span class="number">2</span>  &#123; <span class="attr">"non_static_data"</span> : <span class="string">"non_static_2"</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>このstaticカラムを利用することで同一パーティションキー間でテーブル結合することなく共有することができます。</p><p>チャットとチャットルームにおける関係にも利用できそうです。</p><h3 id="staticカラムを利用してテーブルを集約する-1"><a href="#staticカラムを利用してテーブルを集約する-1" class="headerlink" title="staticカラムを利用してテーブルを集約する"></a>staticカラムを利用してテーブルを集約する</h3><p>チャットにチャットルームIDをFKとして持たせてチャットルームの情報を引っ張ってくるRDB的な結合を、チャットテーブルにstatcカラムとしてチャットルームの情報を定義することでテーブル集約を実現することができます。</p><figure class="highlight sql"><figcaption><span>staticカラムを利用したチャットテーブル定義</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> chat (</span><br><span class="line">    chatroom_id         <span class="built_in">text</span>               <span class="comment">-- チャットルームID</span></span><br><span class="line">  , chat_id             <span class="built_in">text</span>               <span class="comment">-- チャットID</span></span><br><span class="line">  , chatroom_name       <span class="built_in">text</span> <span class="keyword">static</span>        <span class="comment">-- チャットルーム名</span></span><br><span class="line">  , last_update         <span class="built_in">text</span> <span class="keyword">static</span>        <span class="comment">-- 最終更新日付</span></span><br><span class="line">  , <span class="keyword">member</span>              <span class="keyword">set</span>&lt;<span class="built_in">text</span>&gt; <span class="keyword">static</span>   <span class="comment">-- チャット参加者</span></span><br><span class="line">  , <span class="keyword">body</span>                <span class="built_in">text</span>               <span class="comment">-- チャット本文</span></span><br><span class="line">  , <span class="keyword">user</span>                <span class="built_in">text</span>               <span class="comment">-- 投稿者</span></span><br><span class="line">  , send_date           <span class="built_in">text</span>               <span class="comment">-- 投稿日付</span></span><br><span class="line">  , reaction            <span class="keyword">map</span>&lt;<span class="built_in">text</span>, <span class="built_in">text</span>&gt;    <span class="comment">-- リアクション</span></span><br><span class="line">  , PRIMARY <span class="keyword">KEY</span>((chatroom_id), chat_id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>staticカラムでテーブル集約したことにより、コレクション型で集約した時に比べて、投稿数 = レコード数となるため、投稿数の制約が無くなります。</p><p>また、レコード更新時もネストが1段階浅くなりfrozenを利用せずチャットの情報を保持することができるため、個別更新にも対応できる柔軟なデータモデルになったと言えます。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>Cassandraのデータモデルを考える際にはついついRDB的な思考で結合ありきのデータモデルでテーブル設計を行ってしまいますが、まずはテーブルを集約できるかを念頭に見つめ直してみましょう。</p><p>最後にデータモデルを考える上での考慮点をまとめてみました。</p><ul><li>結合ありきのテーブル設計になっていないか</li><li>コレクション型を利用してテーブル間の関係を集約できるか</li><li>集約時にネストが深くなりすぎないか、また更新要件を満たすことができるか</li><li>staticカラムを利用してパーティション単位の情報を共有させることで集約できるか</li></ul><p>他にもデータモデル設計時に検討した項目はありますが、それはまた別の機会に紹介できれば幸いです。<br>ぜひ皆さんもRDB脳から脱却してKVSを使いこなしてみましょう！！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちは、Technology Innovation Group所属 DBチームの岩崎です。&lt;/p&gt;
&lt;p&gt;私はDBチーム
      
    
    </summary>
    
      <category term="DB" scheme="https://future-architect.github.io/categories/DB/"/>
    
    
      <category term="DB" scheme="https://future-architect.github.io/tags/DB/"/>
    
  </entry>
  
  <entry>
    <title>GCPインスタンスを自動で停止させるツールの公開</title>
    <link href="https://future-architect.github.io/articles/20190716/"/>
    <id>https://future-architect.github.io/articles/20190716/</id>
    <published>2019-07-16T00:12:58.000Z</published>
    <updated>2019-07-16T00:20:09.725Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは、TIG DXユニットの真野です。2019年時点ではフューチャーに入社して9年目、主にバックエンド側の設計や開発をしています。</p><blockquote><p>TIG: Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。<br>DXユニット: TIGの中でも特にデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</p></blockquote><p>GCPのインスタンス（GCE, SQL, GKE）を自動で停止させるGoで書かれたツールをGitHubに公開しました。<br><a href="https://github.com/future-architect/gcp-instance-scheduler" target="_blank" rel="noopener">https://github.com/future-architect/gcp-instance-scheduler</a></p><p>このツールの実装はアルバイト社員の<a href="https://qiita.com/donkomura" target="_blank" rel="noopener">donkomura</a>さんが主体的に開発を進めていただいました。<br>別の機会にdonkomuraさんにはアルバイトブログを書いてもらおうと思うので、工夫した点などはそこで述べてもらおうと思います。</p><p>このツールを用いてGCPを利用しない時間帯を上手く指定することで、クラウドの運用費用を節約できます。</p><h1 id="ツールの概要"><a href="#ツールの概要" class="headerlink" title="ツールの概要"></a>ツールの概要</h1><p><code>state-scheduler:true</code> というラベルがついた、GCE, SQL, GKEなどのインスタンスを停止します。<br>GKEの場合は、ノードプールを構成するインスタンスグループのサイズを0にすることで実現します。</p><p>定期的なシャットダウンを避けたい場合は、<code>state-scheduler:false</code>と指定すれば、対象から除外させることもできます。</p><p>構成は下図の通り、Pub/SubトリガーのCloud Functionとして動作します。</p><img src="/images/20190713/photo_20190713_01.png"><p>起動タイミングはCloud Schedulerで制御する構成です。<br>そのため、「0 21 * * *」のようにCRON形式でスケジュールを定義すれば、毎日21時に停止させることができます。</p><p>ちなみに、Cloud FunctionをHTTPトリガーにせずPub/Subを挟んでいる理由は、認証を挟みたかったためです。<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><h1 id="デプロイ方法"><a href="#デプロイ方法" class="headerlink" title="デプロイ方法"></a>デプロイ方法</h1><p>ツールのデプロイ手順を1~3の順に説明します。</p><h2 id="1-ラベルの設定"><a href="#1-ラベルの設定" class="headerlink" title="1. ラベルの設定"></a>1. ラベルの設定</h2><p>停止したいインスタンスのラベルに <code>state-scheduler:true</code> を設定する必要があります。<br>ラベルの設定はもちろん管理コンソールから手動で行っても良いですし、下記のようなgcloudコマンドでも設定できます。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GCE</span></span><br><span class="line">gcloud compute instances update &lt;insntance-name&gt; \</span><br><span class="line">  --project &lt;project-id&gt; \</span><br><span class="line">  --update-labels state-scheduler=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Cloud SQL (master must be running)</span></span><br><span class="line">gcloud beta sql instances patch &lt;insntance-name&gt; \</span><br><span class="line">  --project &lt;project-id&gt; \</span><br><span class="line">  --update-labels state-scheduler=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># GKE</span></span><br><span class="line">gcloud container clusters update &lt;cluster-name&gt; \</span><br><span class="line">  --project &lt;project-id&gt; \</span><br><span class="line">  --zone &lt;cluster-master-node-zone&gt; \</span><br><span class="line">  --update-labels state-scheduler=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="2-Cloud-Functionのデプロイ"><a href="#2-Cloud-Functionのデプロイ" class="headerlink" title="2. Cloud Functionのデプロイ"></a>2. Cloud Functionのデプロイ</h2><p>デプロイには <a href="https://cloud.google.com/sdk/gcloud/" target="_blank" rel="noopener">gcloud</a> が必要ですのでインストールしておきます。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/future-architect/gcp-instance-scheduler.git</span><br><span class="line"><span class="built_in">cd</span> gcp-instance-scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># Deploy Cloud Function</span></span><br><span class="line">gcloud <span class="built_in">functions</span> deploy ReceiveEvent --project &lt;project-id&gt; \</span><br><span class="line">  --runtime go111 \</span><br><span class="line">  --trigger-topic instance-scheduler-event</span><br></pre></td></tr></table></figure><h2 id="3-Cloud-Schedulerの設定"><a href="#3-Cloud-Schedulerの設定" class="headerlink" title="3. Cloud Schedulerの設定"></a>3. Cloud Schedulerの設定</h2><p>最後にスケジューラの設定を行います。</p><p>今回は仮に、「毎日21時」に停止することにします。タイムゾーンをUTCにしたい場合は適時書き換えください。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Cloud Scheduler Job</span></span><br><span class="line">gcloud beta scheduler <span class="built_in">jobs</span> create pubsub shutdown-workday \</span><br><span class="line">  --project &lt;project-id&gt; \</span><br><span class="line">  --schedule <span class="string">'0 21 * * *'</span> \</span><br><span class="line">  --topic instance-scheduler-event \</span><br><span class="line">  --message-body <span class="string">'&#123;"command":"stop"&#125;'</span> \</span><br><span class="line">  --time-zone <span class="string">'Asia/Tokyo'</span> \</span><br><span class="line">  --description <span class="string">'automatically stop instances'</span></span><br></pre></td></tr></table></figure><p>以上で適用できました。<br>これで、毎日21時に指定したインスタンスのシャットダウンが行われます。</p><p>テキストでは長いですが、コマンド数として少ないので簡単に適用できると思います。</p><h1 id="こぼれ話（ツール設計について）"><a href="#こぼれ話（ツール設計について）" class="headerlink" title="こぼれ話（ツール設計について）"></a>こぼれ話（ツール設計について）</h1><p>このGCP停止ツールの特徴として、Goの<a href="https://godoc.org/cloud.google.com/go" target="_blank" rel="noopener">GCP SDK</a>経由でインスタンスの制御を行っています。</p><p>これには理由があって、当初は、インフラ構築をTerraformで行っていたため、インスタンスのステータスを<a href="https://www.terraform.io/docs/configuration/override.html" target="_blank" rel="noopener">override variables</a>で上書いた上で、terraform applyによって停止させる想定でした。<br>この方式だと、既存のTerraform資産を活かしつつ手堅く実装できるんじゃないかという目論見です。</p><p>しかし、実は費用がかかっていたのはTerraform管理対象外である、サンドボックス的なDevelopment環境であったことが判明。<br>そこで方向転換し、Terraform定義が無い環境においても稼働できるように、GCPのAPIを直接呼び出すことによってシャットダウンすることにしました。</p><p>通常だとgcloudコマンドでガンバリそうですが、レポーティング機能やSlack連携機能が将来的に求められそうだったので、Goで開発することにしました。</p><p>結果として、個人的なプライベートの小さなGCP環境にでも簡単に適用できるので、これはこれで良かったなと思っています。</p><h1 id="今後"><a href="#今後" class="headerlink" title="今後"></a>今後</h1><p>まだまだ、稼働し始めたところで作りが甘いところがあり、継続的に改善していきます。<br>例えば、2019年7月時点では以下のような面を機能拡張していこうとなっています。</p><ul><li>停止したインスタンスや、停止をスキップしたインスタンス数のSlackへの通知</li><li>停止処理の高速化（並列化）</li><li>インスタンスの再起動機能の追加</li></ul><p>今後も有益だと思われるツールはドンドン公開していこうと考えています。</p><p>この記事が少しでも皆さんの役にたてば幸いです。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">参考: https://cloud.google.com/scheduler/docs/start-and-stop-compute-engine-instances-on-a-schedule</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちは、TIG DXユニットの真野です。2019年時点ではフューチャーに入社して9年目、主にバックエンド側の設計や開発を
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="gcp" scheme="https://future-architect.github.io/tags/gcp/"/>
    
  </entry>
  
  <entry>
    <title>Goを学ぶときにつまずきやすいポイントFAQ</title>
    <link href="https://future-architect.github.io/articles/20190713/"/>
    <id>https://future-architect.github.io/articles/20190713/</id>
    <published>2019-07-13T01:00:00.000Z</published>
    <updated>2019-07-12T06:02:47.532Z</updated>
    
    <content type="html"><![CDATA[<p>他の言語になれた人が、初めてGoを書いた時にわかりにくいな、と思った部分はどういうところがあるのか、難しいポイントはどこか、という情報を自分の経験や、会社の内外の人に聞いたりしてまとめてみました。まだまだたくさんあるのですが、多すぎるのでまずはこんなところで。コンテナで開発することがこれからますます増えていくと思われますし、その時にコンテナとの相性が抜群なGoをこれから使い始める人もどんどん増えていくと思います。</p><p>Goは特に言語のコアをシンプルに、何かを実現するときはそのシンプルな機能を組み合わせて実現しよう、というコンセプトです。つまり、他の言語で実現したいこと・できていることに比べて、Goは組み合わせ（イディオム）でカバーする領域が広くなります。そのあたりのとっかかりになる情報を提供することが、これからGoを触る人にとってつまずきを減らすことになると思います。</p><p>Go Conference’19 Summer in Fukuokaではこちらの中からいくつかピックアップをしましたが、こちらが今の所の完全版です。</p><h1 id="見え方の違い"><a href="#見え方の違い" class="headerlink" title="見え方の違い"></a>見え方の違い</h1><p>Goになれている人となれていない人では、同じコードを見た時にも見えている景色がだいぶ違いますし、コードを書くときの頭の使い方もだいぶ違います。</p><h2 id="再生-vs-再認"><a href="#再生-vs-再認" class="headerlink" title="再生 vs 再認"></a>再生 vs 再認</h2><p>認知心理学では、2つの記憶のモード、再生と再認を考えます。</p><p>再生は、過去の記憶を何もインプットがなくても思い出せる状態です。再認は、「これは体験したことがありますか？」と問われたら「ああ、これは体験したことがある」と思い出せる状態です。</p><p>再生をするには完全に記憶しきっている状態にならないとダメです。慣れている人は、数多くのパターンを記憶しており、それを再生することでコードが書けますし、他の人のコードを見た時にも、過去のパターンと照らし合わせて「より良いコード」パターンを思いついたりします。</p><p>再認の方が難易度は低いです。ドキュメント、サンプルコード、ネットで調べた情報などを辿りながら、それを組み合わせて実装します。時間もかかりますし、検索で出てこないパターンだとパフォーマンスが落ちます。ですが、なんどもなんどもコードを見て繰り返し再認していくと、再生でコードが書けるようになります。このドキュメントは再認の効率アップがゴールです。</p><p>とはいえ、必ずしも全員が再生レベルになる必要はありません。たとえGoに慣れていても、普段使わないパッケージ（cryptoパッケージの暗号化とか）を使う場合は再認で（サンプルのコピペで）コードを書くことになるでしょう。上級者でも、自分用のスニペット集を作ることで、記憶の能力の節約しつつパフォーマンスは落とさないということをしますね。</p><h2 id="アンラーニング"><a href="#アンラーニング" class="headerlink" title="アンラーニング"></a>アンラーニング</h2><p>すでに学んでいる知識がかえって学習の妨げになりがちです。このバイアスを除外して（客観化して）、あらためて学ぶというのはなかなか難易度の高いことです。自分の知識をリセットして（組み替えて）楽しむSF好きとか、逆転裁判好きとか何かしらのプラスアルファの能力が必要じゃないでしょうか？</p><p>受けての言葉で差分を表現して教えて上げるというのはこのスタートのつまずきを解消するてっとり早い方法です。そして一通り自分で手が動くようになればそこでどんどん新しい考えが定着していきます。それまでは温かい目で見守る必要があるでしょう。</p><p>なお、うまくアンラーニングできるということは、自分がそれまで持っていた知識が客観化されることになるので、過去に学んだ言語が勝手に上達することもありえます。</p><h1 id="実装パターン集"><a href="#実装パターン集" class="headerlink" title="実装パターン集"></a>実装パターン集</h1><p>では説明していきましょう。そのうちカテゴリーに分けるかもしれません。以下のような形式で統一します。</p><ul><li>これを使うときのGoの作法はなにか？（慣れている人がよく選ぶものはなにか）</li><li>この言語でやっていたように〇〇したいがどうすればいいのか？<ul><li>できない場合はその理由</li><li>複数ある場合はそれぞれの選択肢とトレードオフ</li></ul></li><li>Goにこの機能があるけどどう使うのか？</li></ul><h2 id="パッケージ"><a href="#パッケージ" class="headerlink" title="パッケージ"></a>パッケージ</h2><h3 id="Q-リポジトリはそもそもどこにおけば良いですか？"><a href="#Q-リポジトリはそもそもどこにおけば良いですか？" class="headerlink" title="Q: リポジトリはそもそもどこにおけば良いですか？"></a>Q: リポジトリはそもそもどこにおけば良いですか？</h3><p>適当なフォルダを作業フォルダにするのは可能ですか？</p><hr><p><strong>A: Goは<code>$GOPATH</code>という環境変数のところにいろいろ置きます。デフォルトでは<code>$HOME/go</code>です。これはソースコードだけではなく、ビルド済みのライブラリなどです。とりあえず作業フォルダを作ったら、そこが<code>$GOPATH</code>となるように、direnvなりで設定されるようにしましょう。</strong></p><p>プロジェクトごとに完全に分けたいのであれば、トップの<code>$GOPATH</code>用のフォルダを必要なだけ切って利用します。そこまで厳密でなければデフォルトの<code>$HOME/go</code>で良いと思います。</p><p><code>$GOPATH</code>以下は次のようになっています。appが自分の作りたいアプリケーションだとしたら、そこにフォルダを作り、git initしてしまえば良いです。go getを行ってもここにダウンロードされます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$GOPATH</span><br><span class="line">+ bin</span><br><span class="line">| ... go getで取得してビルドした実行ファイル</span><br><span class="line">+ pkg</span><br><span class="line">| + [os_arch]</span><br><span class="line">| | + ...ビルド済みのライブラリ</span><br><span class="line">| + mod</span><br><span class="line">| | + ...go modでダウンロードしたパッケージのキャッシュ</span><br><span class="line">| + dep</span><br><span class="line">|   + ...今となっては古いdepコマンドでダウンロードしたパッケージのキャッシュ </span><br><span class="line">+ src</span><br><span class="line">  + github.com</span><br><span class="line">    + user</span><br><span class="line">      + app</span><br><span class="line">      + library</span><br></pre></td></tr></table></figure><p>複数のリポジトリに分離したプロジェクトを作るときも同じ場所に置きます。ただし、依存ライブラリ側は、github等からダウンロードされて、pkg/mod以下に入れられたバージョンを利用しようとします。一緒に開発したい場合、わざわざ不安定なバージョンをgit pushしなければならない、というのは不便でしょう。幸い、go.modにはreplaceという機能が使えます。appがlibraryを使う場合は、appのgo.modに次の行を加えておくと、同じ場所にあるフォルダを参照してくれます。複数リポジトリを一緒に変更しつつ動作検証するにはこの方法がベストです。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">replace (</span><br><span class="line">    github.com/user/library =&gt; ../library</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><strong>memo:</strong> Go 1.12では<code>$GOPATH</code>以下はgo.modが自動では有効にならないため、環境変数設定で、<code>GO111MODULE=on</code>を入れておきましょう。あと数ヶ月で不要になりますが。</p><p>環境構築にはあまり凝りすぎないで、デフォルト多めの方が、世間の情報とのずれが少なく、後から見返すときに楽です。凝りすぎたMakefileやらシェルスクリプトやらは引き継ぎのコストが多くなったりするし、自分でも忘れてしまったりしがちです。</p><h3 id="Q-関数や構造体は、パッケージ（ディレクトリ）やファイルにどのように配置していけばいいか？"><a href="#Q-関数や構造体は、パッケージ（ディレクトリ）やファイルにどのように配置していけばいいか？" class="headerlink" title="Q: 関数や構造体は、パッケージ（ディレクトリ）やファイルにどのように配置していけばいいか？"></a>Q: 関数や構造体は、パッケージ（ディレクトリ）やファイルにどのように配置していけばいいか？</h3><p>各言語で、パッケージ、モジュール、ファイルの扱いがかなり違います。Goでは関数をどのように格納していけばいいのですか？例えば、Javaではフォルダがパッケージ。ファイルがクラスと対応づけられています。JavaScriptやPythonはファイル単位でモジュール、ディレクトリはデフォルトのファイル（<code>index.js</code>や<code>__init__.py</code>）を自動で読み込む動作をします。</p><hr><p><strong>A: Goではディレクトリがパッケージになります。ディレクトリに含まれるすべてのファイルは同一のパッケージ名でなければなりません。一方、ファイル間で要素を移動してもビルド時には差はありません。</strong></p><p>関数や構造体、変数などはディレクトリ内部のファイルに書きます。1つのファイルには1つの何かを書くというルールはありません。このあたりはPythonやJavaScriptに近いと言えます。</p><p>a.goとb.goが同じディレクトリ内にあった場合、a.goで定義された要素はb.goから何も宣言せずに利用できます。スコープに関してはどちらかというとJavaに近い感じです。そういった点で、ファイルに関してはどこに何をおいても、ファイル間で移動してもビルド時には差はありません。最初は1ファイルでなんでも入れておいて、大きくなってきたときに、パッケージの中で、コードなどをグルーピング化する単位でファイルに分ければ良いでしょう。</p><p>唯一、条件コンパイルで、Windowsの場合だけ、Linuxの場合だけ利用される関数といった条件コンパイルを実現するときは、ファイル単位でビルドに含めたり除外したりしますので、その単位で分けます。</p><h3 id="Q-プロジェクトを作るときのフォルダ構成の定番はどういう構成ですか？"><a href="#Q-プロジェクトを作るときのフォルダ構成の定番はどういう構成ですか？" class="headerlink" title="Q: プロジェクトを作るときのフォルダ構成の定番はどういう構成ですか？　"></a>Q: プロジェクトを作るときのフォルダ構成の定番はどういう構成ですか？　</h3><p>新規で作るときにどのようなプロジェクト構成にすればよいでしょうか？</p><hr><p><strong>A: ライブラリなのか、ライブラリ＋CLIツールも提供するのか、ウェブサーバーなのかで変わります。</strong></p><p>これはGoのリファレンスなどには書かれていませんが、一般的な慣習として使われているフォルダ構成です。</p><p>ライブラリの場合は、トップフォルダがライブラリのルートになります。リポジトリのルートで、go mod initをします。code.goの先頭は <code>pakckage yourlib</code>になり、go.modの方は<code>module github.com/yourname/yourlib</code> になります。READMEには <code>go get -u github.com/yourname/yourlib</code>でインストールしてねって書きます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+ github.com</span><br><span class="line">  + yourname </span><br><span class="line">    + yourlib    ←ここがリポジトリのルート</span><br><span class="line">      + code.go</span><br><span class="line">      + go.mod</span><br><span class="line">      + go.sum</span><br><span class="line">      + README</span><br></pre></td></tr></table></figure><p>ライブラリが、おまけでCLIツールを提供する場合は、cmdフォルダを作ってその中にコマンド名のフォルダを作り、その中に実行ファイルのソースをおきます。Goの場合ビルドを実行したフォルダ名がデフォルトで実行ファイルの名前になります。go modulesで成果物の名前を設定できるようになりましたが、それ以前からの慣習として一般的に使われています。</p><p>複数のコマンドを提供するときはcmd以下に複数フォルダを作ります。各実行ファイルは当然<code>package main</code>になります。READMEには <code>go get -u github.com/yourname/yourlib/...</code>でインストールしてねって書きます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+ github.com</span><br><span class="line">  + yourname </span><br><span class="line">    + yourlib    ←ここがリポジトリのルート</span><br><span class="line">      + cmd</span><br><span class="line">      | + yourcmd</span><br><span class="line">      |   + main.go</span><br><span class="line">      + code.go</span><br><span class="line">      + go.mod</span><br><span class="line">      + go.sum</span><br></pre></td></tr></table></figure><p>ウェブサービスのプロジェクトの場合は、トップフォルダがアプリケーションのルートになります。リポジトリのルートで、go mod initをします。実行ファイルなのでmain.goの先頭は <code>pakckage main</code>になり、go.modの方は<code>module github.com/yourname/yourapp</code> になります。あるいは、<code>go mod init yourapp</code>と実行しても良いです。その場合は、<code>module yourapp</code>となります。READMEには <code>go get -u github.com/yourname/yourapp</code>でインストールしてねって書きます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+ github.com</span><br><span class="line">  + yourname </span><br><span class="line">    + yourapp    ←ここがリポジトリのルート</span><br><span class="line">      + main.go</span><br><span class="line">      + go.mod</span><br><span class="line">      + go.sum</span><br><span class="line">      + README</span><br></pre></td></tr></table></figure><h3 id="Q-パッケージやフォルダの名前には何を使えばいいか？"><a href="#Q-パッケージやフォルダの名前には何を使えばいいか？" class="headerlink" title="Q: パッケージやフォルダの名前には何を使えばいいか？"></a>Q: パッケージやフォルダの名前には何を使えばいいか？</h3><p>パッケージやフォルダには自分で名前を設定できますが、何を使うのが良いでしょうか？</p><hr><p><strong>A: 基本的にはEffective Goで説明されている作法（簡潔な何をするパッケージ化が明確になる一つの単語、小文字、フォルダ名と同じ）に従えば良いでしょう。</strong></p><p>なお、この推奨はフォルダ名と同じというのが入っているので、フォルダ名も必然的に同じルールが適用されます。複数の単語で構成させたい場合は、 <code>encoding/json</code> のようにフォルダを分け、末端のパッケージは <code>pakcage json</code> とするのが一般的です。</p><p>パッケージはインポートしたあとに利用するシンボル名としてデフォルトで利用されます。簡潔で短い方が、プログラムが短くなります。GoはJavaのようななるべく明示的な名前を使う作法とは逆に、記憶の再認が可能な限り短くするのが作法です。また、フォルダ名と違うと、<code>import</code>文とプログラム中で利用されるシンボルがずれるため、コードを読むときに困ります。</p><p>ただし、この1単語に沿わないケースが2つほどあります。</p><h4 id="テスト用パッケージ"><a href="#テスト用パッケージ" class="headerlink" title="テスト用パッケージ"></a>テスト用パッケージ</h4><p>たとえば、 <code>slices</code> という名前のフォルダを作り、 <code>pakcage slices</code> のような名前のパッケージでコードを書くとします。通常はGoの場合は同一フォルダ内のファイルはすべて同じパッケージにしなければなりませんが、 <code>_test</code> が末尾に入っている名前（ここでは<code>package slices_test</code>）だけは特別に設定可能です。</p><p>リリースされるライブラリには含まれない、テスト用の共通処理を書いたり、ユニットテスト自体をこの<code>_test</code>パッケージで書くことができます。ただこの場合は本体の<code>slices</code>とは別のパッケージ扱いになるのでimport文を書かないと<code>slices</code>の提供する関数や構造体にはアクセスできませんし、公開されているものしかアクセスできません。exampleテストなどのブラックボックステストには逆にメリットですが、プライベートな要素のテストはできません。</p><h4 id="xxxx-go-go-xxxx-xxxx-goフォルダ"><a href="#xxxx-go-go-xxxx-xxxx-goフォルダ" class="headerlink" title="xxxx-go, go-xxxx, xxxx.goフォルダ"></a>xxxx-go, go-xxxx, xxxx.goフォルダ</h4><p>たまに見かけるケースです。何か既製のライブラリのGoラッパーとか、Go移植とかで見られるものです。たとえばlxc開発元自体が提供している<a href="https://github.com/lxc/go-lxc" target="_blank" rel="noopener">go-lxc</a>なんかは、GitHubの同一階層に本体のlxcがあるので、それと区別するためにgo-が入っています。</p><p>なお、ハイフンとかピリオドはパッケージ名には使えません。この場合は <code>package xxxx</code>のように、-goとかgo-とか.go部分を外した名前をパッケージ名につけることが多いです。</p><h2 id="ビルド環境・ツール"><a href="#ビルド環境・ツール" class="headerlink" title="ビルド環境・ツール"></a>ビルド環境・ツール</h2><h3 id="Q-Goについて調べるといろいろなツールが出てきますが、何が本当に必要なんでしょうか？"><a href="#Q-Goについて調べるといろいろなツールが出てきますが、何が本当に必要なんでしょうか？" class="headerlink" title="Q: Goについて調べるといろいろなツールが出てきますが、何が本当に必要なんでしょうか？"></a>Q: Goについて調べるといろいろなツールが出てきますが、何が本当に必要なんでしょうか？</h3><p>それぞれのツールの役割、入れた場合のメリットとか、入れなかった時のデメリットについて教えてください。</p><hr><p><strong>A: とりあえず、go fmtだけはエディタの保存時に実行されるように設定しておけば良いです。</strong></p><ul><li>go fmt: コードのスタイルを標準スタイルの設定する純正ツール。他の言語でいうところのPythonのblackとかJS/TSのprettier。gitのマージでのトラブルが減ります。やらないとコンフリクト等が増えるかもしれません。</li><li>go vet: コンパイルはできるんだけど、静的解析で問題が起きそうな箇所を見つけてくれる純正ツール。Go 1.10からはユニットテスト実行時に一緒に実行されるようになったので特に何もしなくてもご利益が得られる（当然テストはしてますよね？）</li><li>その他のツール群: 基本的に静的チェックでエラーを見つけてくれるものが多いです。<a href="https://github.com/alecthomas/gometalinter" target="_blank" rel="noopener">これらのツールをまとめてチェックしてくれるツール</a>もあります。</li></ul><p>Goはそもそもコンパイル言語であるので、変なコードはビルドすればわかります。型の整合性もいろいろわかります。何も入れなくてもスタート地点がかなり高いしgo vet自動実行もあるので、他の動的言語で徒手空拳で戦うのに比べたら遥かに安心感を持ってコードを書くことができます。</p><p>それ以上にいろいろチェックしたければ入れると良いと思います。</p><h2 id="ドキュメント"><a href="#ドキュメント" class="headerlink" title="ドキュメント"></a>ドキュメント</h2><h3 id="Q-Goはドキュメントが充実していると聞いたのですが、リファレンスを見ても使いたい機能にどうアプローチすれば良いのかわかりません。"><a href="#Q-Goはドキュメントが充実していると聞いたのですが、リファレンスを見ても使いたい機能にどうアプローチすれば良いのかわかりません。" class="headerlink" title="Q: Goはドキュメントが充実していると聞いたのですが、リファレンスを見ても使いたい機能にどうアプローチすれば良いのかわかりません。"></a>Q: Goはドキュメントが充実していると聞いたのですが、リファレンスを見ても使いたい機能にどうアプローチすれば良いのかわかりません。</h3><p>便利そうな関数あっても、それの利用方法がドキュメントを読んでも想像できません。ついつい、Qiitaなどのサンプルコードを探してしまいます。あと、どのようにソートされているのかわからず、探しにくいです。</p><hr><p><strong>A: ファクトリー関数とインタフェースの2つがわかると、読みやすくなります。</strong></p><p>まず、Goは構造体そのものを使うときには、何も初期化しないで使うか、ファクトリー関数を使って初期化します。例えば、syncのWaitGroupとかRWMutexはゼロ初期化でも正常に動きます。一方、初期化が必要なものはファクトリー関数を使って初期化します。ゼロ初期化でも動くけどユーザーの利便性のためにファクトリー関数を用意しているものもあります。</p><p>ファクトリー関数（その構造体のポインタを返す）はgo docはその構造体のメソッドリストの中に入れてくれます。なので、「この構造体が使いたい」というときはまずファクトリー関数を見つけると、そこが解決の糸口になります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ゼロ初期化</span></span><br><span class="line">wg := &amp;sync.WaitGroup&#123;&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// ファクトリー関数で初期化</span></span><br><span class="line">f, _ := os.Create(<span class="string">"new.zip"</span>)</span><br><span class="line">w := zip.NewWriter(f)</span><br></pre></td></tr></table></figure><p>ただ、その「ファクトリー関数を整列する」go docの機能が仇になって、読みにくくなるケースも多少あります。net/httpのGet/Postなどは単独で使ってHTTPアクセスをする関数ですが、Responseのファクトリー関数としてリストされてしまっています。少し、使い手側の感覚とはちょっと違いますよね？関数と構造体の順番にソートされていて、単独で使える機能は関数のところだけを探しがちですが、構造体のファクトリーメソッドのところにも使える機能が隠されている可能性があります。</p><p>次はインタフェースです。例えば、先程の <code>zip.Writer</code> を使いたい場合、 <code>io.Writer</code> というものが必要というのはわかります。で、 <code>io.Writer</code> を見ても、どう作っていいのかわからず、ここでお手上げになってしまう、というのがGoではありがちです。知識がついてくると、「os.Createで作ればOK、テスト用にはbytes.Bufferを使おうとかわかってくるのですが、どうしてもここは引っかかりがちです。</p><p>go docをローカルで動かして静的解析するとインタフェースを実装している構造体一覧とかもわかったりはします。Goが標準で提供している外部入出力系はこれでだいたいカバーできますが、io.Reader/io.Writerとかこのあたりはある程度暗記は必要かな、と思います。</p><p>しかし、例えば、 <code>sort</code> パッケージの<code>sort.Interface</code>なんかは、利用者がそのインタフェースを実装するのを期待しています（ので、そのインタフェースを作成してくれる関数はどこにもありません）。また、いくつか、ライブラリが提供する構造体のみが来ることを想定して引数がインタフェースになっていることがあります。作るにしても、ライブラリが提供する構造体を利用するにしても、ライブラリの提供者がきちんと動作可能なサンプルコードをドキュメントとして提供すべきですね。場合によってはソースコードのテストコードを読むとかが必要になるかもしれません。</p><p>ドキュメントが充実している文化とはいっても、書く人によって差がでたりわかりやすかったりわかりにくかったりするのはどうしても仕方がない面があります。</p><h2 id="型・変数"><a href="#型・変数" class="headerlink" title="型・変数"></a>型・変数</h2><h3 id="Q-ウェブアプリケーションを開発しているが、型の恩恵がわかりません"><a href="#Q-ウェブアプリケーションを開発しているが、型の恩恵がわかりません" class="headerlink" title="Q: ウェブアプリケーションを開発しているが、型の恩恵がわかりません"></a>Q: ウェブアプリケーションを開発しているが、型の恩恵がわかりません</h3><p>JSONのマッピングのための型など構造体を実装する手間ばかりが多く、面倒です。</p><hr><p><strong>A: たしかに、型のメリットを一番体感しやすいのは他人の書いてくれたものを利用するときです。自分で書いたものを自分で利用する場合はメリットを感じにくいこともありますが、後から助かる保険になります。</strong></p><p>特にJavaScriptからGoに来ると、今時のVisual Studio Codeが賢すぎて、型情報とか定義しなくても推論してしまうので、Goが面倒に感じる場面もあります。しかし、確実に後から助けてくれます。</p><ul><li>他の人が書いたコードを読み解く時に、型情報がヒントになります。Visual Studio CodeやGoLandなどのエディタを使って入れば、「定義元にジャンプ」という機能が使えます。Goはすべての型をきちんと判定するため、確実に定義元にジャンプできます（ただしインタフェースから実装の構造体には飛べません）</li><li>1ヶ月以上たって自分のコードを読み解く時に、型情報がヒントになります。</li><li>コード整理のためにあっちこっちに移動するときに、不一致があるとエディタがその場でエラーを教えてくれます。既存のコードに手を加えるのが楽になります。</li></ul><p>あとは、歳をとって記憶力がなくなってくるとか、風邪をひいた、二日酔いがつらい、という状況では短期記憶能力が下がります。まずはビールを何杯か飲んでからコードを書いてみると良いかもしれません（ダメ絶対）。</p><p>おまけですが、JSONから構造体へのマッピングを作る場合などは、<a href="https://mholt.github.io/json-to-go/" target="_blank" rel="noopener">JSON to Go</a>みたいなツールを使うと楽ができます。</p><h3 id="Q-ポインタの記号がよくわかりません"><a href="#Q-ポインタの記号がよくわかりません" class="headerlink" title="Q: ポインタの記号がよくわかりません"></a>Q: ポインタの記号がよくわかりません</h3><p><code>*</code>と<code>&amp;</code>があって使い方がよくわかりません。</p><hr><p><strong>A: ポインタなのか、インスタンス（実体）なのかをまず区別することが大切です。</strong></p><p>インスタンスはメモリ上に確保されているデータの本体です。100バイトの文字列であれば100バイトぶんのメモリを消費しています。一方、ポインタはインスタンスの場所情報です。64ビット機であれば8バイトです。</p><p>インスタンスがメモリ上にあれば、そのメモリのアドレスはかならず1つあるので、インスタンスからポインタを作ることができます。また、ポインタは特定のアドレスを指しているので、ポインタからインスタンスを取り出すこともできます。相互に変換できる、というのは大切な特性です。</p><p><code>&amp;</code>は、インスタンスからポインタを取り出す操作です。下のコードのうち、下の方には<code>&amp;</code>がついています。これはインスタンスをメモリ上に作った後にポインタを取り出して変数に入れています。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// personIにはインスタンスが入る</span></span><br><span class="line">personI := Person&#123;</span><br><span class="line">  Name: <span class="string">"小動物"</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// personPはインスタンスを作ってからポインタを取り出してそれを格納</span></span><br><span class="line">personP := &amp;Person&#123;</span><br><span class="line">  Name: <span class="string">"小山駅"</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>*</code>には2つの意味があります。1つはポインタから、インスタンスを取り出す「操作」です。<code>&amp;</code>の反対の操作です。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> name = <span class="string">"小椋佳"</span></span><br><span class="line"><span class="comment">// namePはポインタ</span></span><br><span class="line"><span class="keyword">var</span> nameP = &amp;name</span><br><span class="line"></span><br><span class="line"><span class="comment">// そのまま表示するとポインタ値が表示される</span></span><br><span class="line">fmt.Println(nameP)  <span class="comment">// 0x40c128</span></span><br><span class="line"><span class="comment">// *でインスタンスに戻すときちんと表示される</span></span><br><span class="line">fmt.Println(*nameP) <span class="comment">// 小椋佳</span></span><br></pre></td></tr></table></figure><p>もう1つはポインタを表す型です。変数、引数の型につきます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> person  Person <span class="comment">// personはPerson構造体のインスタンスが入る</span></span><br><span class="line"><span class="keyword">var</span> person *Person <span class="comment">// personはPerson構造体のインスタンスのポインタが入る</span></span><br></pre></td></tr></table></figure><p>ポインタに関する記号にはもうひとつあります。それが<code>.</code>です。構造体はインタフェースのメンバーへのアクセスで使いますが、この場合はポインタだろうがインスタンスだろうが気にしないで「使える」という特別な特性があります。C/C++の場合はポインタのメンバーにアクセスする場合は<code>-&gt;</code>を使っていましたが、Goはどちらも<code>.</code>でOKです。</p><h3 id="Q-と-の使い分けがわかりません"><a href="#Q-と-の使い分けがわかりません" class="headerlink" title="Q: :=と=の使い分けがわかりません"></a>Q: <code>:=</code>と<code>=</code>の使い分けがわかりません</h3><p>代入に記号が2つありますが、いまいち使い分けでいつも悩んでしまいます。</p><hr><p><strong>A: 何が必要かはエディタが教えてくれます。エディタに従いましょう。</strong></p><p>明示的に型を指定して変数を作りたい場合はvarを使って<code>=</code>を使います。ここで<code>:=</code>を書くとエラーになります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 右辺は文字列だけど、interface&#123;&#125;にしたい</span></span><br><span class="line"><span class="keyword">var</span> name <span class="keyword">interface</span>&#123;&#125; = <span class="string">"小中大"</span></span><br></pre></td></tr></table></figure><p>変数宣言なしで宣言と代入を同時にやろうとすると<code>:=</code>を使います。ここで<code>=</code>を書くとエラーになります。</p><p>既存の変数に代入するときは<code>=</code>を使います。ここで<code>:=</code>を書くとエラーになります。</p><p>間違ったらコンパイラが教えてくれますし、エディタやIDEも赤線をひいいてくれますので、悩む前に手を動かしてしまうのが楽です。</p><p>注意すべきは新しいスコープを作る場合です。次のコードはif文のところの記号は<code>:=</code>でも<code>=</code>でも動作します。ifの条件節は新しいスコープの中になるため、新しい変数を重複してもエラーになりません。また、親のスコープで同名の変数があれば、<code>=</code>にしても動作します（ただし、親側の変数が書き換わる）。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">ok := <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ここ</span></span><br><span class="line"><span class="keyword">if</span> ok := test(); ok &#123;</span><br><span class="line">fmt.Println(<span class="string">"a"</span>, ok)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(<span class="string">"b"</span>, ok)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-返り値の宣言で変数名を入れるのはどういった意味がありますか？"><a href="#Q-返り値の宣言で変数名を入れるのはどういった意味がありますか？" class="headerlink" title="Q: 返り値の宣言で変数名を入れるのはどういった意味がありますか？"></a>Q: 返り値の宣言で変数名を入れるのはどういった意味がありますか？</h3><p>返り値の宣言で変数名を入れる記法がありますが、横に長くなってメリットを感じません。どういったご利益がありますか？</p><hr><p><strong>A: メソッドの引数をn番目でアクセスしないで、名前でアクセスするのと同じで、返り値の意味を利用者や実装者に伝えるためのものです。</strong></p><p>特に、データを外部から読み込みをするが、データ、行、列、エラーと返り値がたくさんある、みたいなケースで数が多くなってくるとプログラムのreturn文がわかりにくくなってきます。ドキュメントも読みやすくなります。</p><p>名前付きの返り値は関数開始時にゼロ値で初期化されますので、文字列の場合は空文字列、数値系の型はゼロ、bool型はfalse、errorなどのインタフェースやポインタはnilになります。エラーなんかは発生しなければそのままreturnすれば問題ありません。</p><h3 id="Q-関数の引数に型名が書かれていないものがあるのですが、どう解釈すればいいですか？"><a href="#Q-関数の引数に型名が書かれていないものがあるのですが、どう解釈すればいいですか？" class="headerlink" title="Q: 関数の引数に型名が書かれていないものがあるのですが、どう解釈すればいいですか？"></a>Q: 関数の引数に型名が書かれていないものがあるのですが、どう解釈すればいいですか？</h3><p><code>func Func(a, b, c []byte)</code>のような宣言がありました。aとbの型はなんでしょうか？</p><hr><p><strong>A: Goでは省略した引数は後ろに宣言した型が自動で入ります。</strong></p><p>変数宣言で次のような宣言があった場合に違和感を感じる人はあまりいないのではないでしょうか？これが引数のところでも使える、と考えればOKです。もちろん、最後の変数に宣言がないとエラーになります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a, b <span class="keyword">int</span></span><br></pre></td></tr></table></figure><h3 id="Q-immutableなコーディングがしたいのですがどうすればいいでしょうか？"><a href="#Q-immutableなコーディングがしたいのですがどうすればいいでしょうか？" class="headerlink" title="Q: immutableなコーディングがしたいのですがどうすればいいでしょうか？"></a>Q: immutableなコーディングがしたいのですがどうすればいいでしょうか？</h3><p>最近のプログラミング言語では変更不可能であると宣言することで、デバッグなどがしやすくなっており、Goでもやりたいと思っています。</p><hr><p><strong>A: Goにはあまりimmutableに実現する手法はありません。諦めてください。</strong></p><p>TypeScriptの<code>const</code>は再代入禁止なので、結構気軽に使えました。変数宣言をすべて<code>const</code>に揃えるという方法で機械的にimmutableスタイルに近づけます。Goの<code>const</code>は整数や文字列などのプリミティブには使えますが、スライス、配列、map、構造体のインスタンス、構造体のポインタなどには使えません。</p><p>また、map、スライスなどは一部の要素を変更するたびに全コピーというのは遅いためコードレビューで集中砲火を浴びることになるでしょう。</p><p>構造体のメソッドのレシーバをポインタではなくてインスタンスにすると、変更した内容がインスタンスには伝搬しなくなるため、予期せぬ変更を防げるぐらいの機能はあります（が、これも変更したつもりで変わっていないというわかりにくい挙動になるので注意）。</p><h2 id="構文"><a href="#構文" class="headerlink" title="構文"></a>構文</h2><h3 id="Q-三項演算子が使いたい"><a href="#Q-三項演算子が使いたい" class="headerlink" title="Q: 三項演算子が使いたい"></a>Q: 三項演算子が使いたい</h3><p>条件付きの初期化処理などで、三項演算子が使いたいです。</p><hr><p><strong>A: Goにはありませんので、if文を書いてください。</strong></p><h2 id="リテラル・スライス・map"><a href="#リテラル・スライス・map" class="headerlink" title="リテラル・スライス・map"></a>リテラル・スライス・map</h2><h3 id="Q-“sss”-1とか、暗黙的型変換してくれない"><a href="#Q-“sss”-1とか、暗黙的型変換してくれない" class="headerlink" title="Q: “sss” + 1とか、暗黙的型変換してくれない"></a>Q: “sss” + 1とか、暗黙的型変換してくれない</h3><p>他の言語だと、文字列と数値の結合とかをしても、適切に変換してくれます。Goの場合は文字列と数値の結合はおろか、整数と小数の計算もエラーになって不便です。</p><hr><p><strong>A: 暗黙の型変換は予想外のバグを産むことがあるため、すべて明示的に書くのがGoの考え方です。つまり、これは実現不可能です。</strong></p><h4 id="fmt-Sprintfで文字列に変換する"><a href="#fmt-Sprintfで文字列に変換する" class="headerlink" title="fmt.Sprintfで文字列に変換する"></a><code>fmt.Sprintf</code>で文字列に変換する</h4><p>結果が文字列であれば、<code>fmt.Sprintf</code>を使ってあげるのが簡単です。<code>%v</code>はどんな型でもそれなりに変換してくれます。細かい指定が必要であれば他のフラグを使って指定もできます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fmt.Sprintf(<span class="string">"%v%v"</span>, <span class="string">"abc"</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// abc1</span></span><br></pre></td></tr></table></figure><h4 id="文字列→数値、数値→文字列なら-strconv-パッケージを使う"><a href="#文字列→数値、数値→文字列なら-strconv-パッケージを使う" class="headerlink" title="文字列→数値、数値→文字列なら strconv パッケージを使う"></a>文字列→数値、数値→文字列なら <code>strconv</code> パッケージを使う</h4><p><a href="https://golang.org/pkg/strconv" target="_blank" rel="noopener">strconv</a>パッケージには文字列と他のプリミティブ型の相互変換の関数がもろもろ定義されています。<code>Format</code>で始まる関数は文字列への変換、<code>Parse</code>で始まる関数は文字列から変換です。<code>fmt.Sprintf</code>よりはコードは長くなりがちですが、こちらの方が高パフォーマンスが期待できます。</p><h4 id="キャストで数値にする"><a href="#キャストで数値にする" class="headerlink" title="キャストで数値にする"></a>キャストで数値にする</h4><p>数値型同士の変換はキャストします。誤差がどうなるかも考えて、実装者が責任を持って選ぶ必要があります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">price := <span class="number">1000</span></span><br><span class="line">taxRate := <span class="number">0.08</span></span><br><span class="line">totalPrice := <span class="keyword">int</span>(<span class="keyword">float64</span>(price) * taxRate)</span><br></pre></td></tr></table></figure><h3 id="Q-配列を返す関数を実装するときに、空の配列のreturnが面倒ですが簡単に書けませんか？"><a href="#Q-配列を返す関数を実装するときに、空の配列のreturnが面倒ですが簡単に書けませんか？" class="headerlink" title="Q: 配列を返す関数を実装するときに、空の配列のreturnが面倒ですが簡単に書けませんか？"></a>Q: 配列を返す関数を実装するときに、空の配列のreturnが面倒ですが簡単に書けませんか？</h3><p>例えば、検索してマッチした要素のインデックスの一覧を返す関数を作るとします。通信エラーの場合に空スライスとエラーを返したいのですが冗長になってしまいます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FindIndexes</span><span class="params">(name <span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">int</span>, error)</span></span> &#123;</span><br><span class="line">    :</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> []<span class="keyword">int</span>&#123;&#125;, errors.New(<span class="string">"Network error"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><figure class="highlight plain"><figcaption><span>Goではnilが空スライスとして使えるようになっています。```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">``append()``やforループにnilの空スライスを渡してもメモリアクセスエラーになったりせずに、空のスライスとして振る舞うようにGoのランタイムはデザインされています。そのため、初期化時はわざわざ空スライスを作ってあげる必要はありません。</span><br><span class="line"></span><br><span class="line">```go</span><br><span class="line">var indexes []int             // この段階では何も代入してないのでnil</span><br><span class="line">indexes = append(indexes, 10) // nilだとこの時に配列が自動で作られて帰ってくる</span><br><span class="line"></span><br><span class="line">if err != nil &#123;</span><br><span class="line">    // nilを返せば空スライスに</span><br><span class="line">    return nil, errors.New(&quot;Network error&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>単なるnilでは型情報がないのでエラーになりますので、returnで型が決まっている場合以外は変数宣言は最低限必要です。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index = <span class="built_in">append</span>(<span class="literal">nil</span>, <span class="number">10</span>)  <span class="comment">// first argument to append must be typed slice; have untyped nil</span></span><br></pre></td></tr></table></figure><p>なお、<code>[]int{}</code>と初期化すると、空とはいえ実態が作られますので、nilと比較するとfalseになります。空スライスかどうかの判定はlen()を使いましょう。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">indexes := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> indexes == <span class="literal">nil</span> &#123; <span class="comment">// 常にfalse</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(indexes) == <span class="number">0</span> &#123; <span class="comment">// 期待通りの動作</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-GoにはJavaやPythonやJavaScriptにあるSetがありませんが、どうするんでしょうか？"><a href="#Q-GoにはJavaやPythonやJavaScriptにあるSetがありませんが、どうするんでしょうか？" class="headerlink" title="Q: GoにはJavaやPythonやJavaScriptにあるSetがありませんが、どうするんでしょうか？"></a>Q: GoにはJavaやPythonやJavaScriptにあるSetがありませんが、どうするんでしょうか？</h3><hr><p><strong>A: 一番簡単な（他への依存がない）方法はmapで代用する方法です。</strong></p><p>例えば、キーが文字列であれば、<code>map[string]bool</code>みたいにするのがもっとも簡単でしょう。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 作成</span></span><br><span class="line">set := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">bool</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// セット</span></span><br><span class="line">set[<span class="string">"exists"</span>] = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ある？</span></span><br><span class="line"><span class="keyword">if</span> set[<span class="string">"exists"</span>] &#123;</span><br><span class="line">fmt.Println(<span class="string">"exists"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ない？</span></span><br><span class="line"><span class="keyword">if</span> !set[<span class="string">"not exists"</span>] &#123;</span><br><span class="line">fmt.Println(<span class="string">"not exists"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 削除</span></span><br><span class="line"><span class="built_in">delete</span>(set, <span class="string">"exists"</span>)</span><br></pre></td></tr></table></figure><p>もし、和集合とか積集合とか差集合が必要であれば<a href="https://godoc.org/github.com/golang-collections/collections/set" target="_blank" rel="noopener">github.com/golang-collections/collections</a>パッケージが使えるでしょう。</p><p>あるいは、順序の維持も必要であれば、ソート済み配列と<a href="https://golang.org/pkg/sort/#Search" target="_blank" rel="noopener">sort.Search</a>などを駆使する手もあります（楽ではありませんが）。<a href="https://shibukawa.github.io/slices/" target="_blank" rel="noopener">ソート済み配列を対象にしたアルゴリズムのコードジェネレータ</a>もあります。</p><h2 id="関数・ロジック"><a href="#関数・ロジック" class="headerlink" title="関数・ロジック"></a>関数・ロジック</h2><h3 id="Q-クロージャって何ですか？何がうれしいんですか？"><a href="#Q-クロージャって何ですか？何がうれしいんですか？" class="headerlink" title="Q: クロージャって何ですか？何がうれしいんですか？"></a>Q: クロージャって何ですか？何がうれしいんですか？</h3><p>クロージャという言葉をよく聞きます。クロージャとはなんですか？ループの変数でトラブルが起きやすいとも聞きます。使うとどのようなメリットがあるんでしょうか？</p><hr><p><strong>A: クロージャというのは、自分が作られた環境の外の変数への参照を保持した（閉じ込めた）関数で、主に2つの用途があります。</strong></p><p>多くの言語では無名関数やラムダと呼ばれる文法を使って作られます。Goは無名関数（funcで作る名前のない関数）です。関数の中で関数を定義すると、その関数は当然外の変数にアクセスできて当然である、と誰しもが思うでしょう。しかし、これはコンパイラが気を利かせて、関数に隠れた引数を追加して、中からアクセスしている変数のポインタを渡すようにコードを改変しているのです（Pythonは親の名前空間として持っていて、ローカルで参照できない場合は親の名前空間に順番に探しに行くことで解決）。</p><p>たとえ、親の関数を抜けて、クロージャだけが存在する状態になっても、ローカル変数のnameが残り続け、あとからクロージャを実行してもその変数が残ります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Function</span><span class="params">()</span> <span class="title">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">   name = <span class="string">"小太刀"</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">// これがクロージャ</span></span><br><span class="line">   closure := <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">       <span class="comment">// クロージャの外の変数が扱える</span></span><br><span class="line">       fmt.Printf(<span class="string">"name=%v\n"</span>, name)</span><br><span class="line">   &#125; </span><br><span class="line">   <span class="keyword">return</span> closure</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">closure := Function()</span><br><span class="line">closure()</span><br><span class="line"><span class="comment">// name=小太刀</span></span><br></pre></td></tr></table></figure><p>要素に分けてこれから説明しますが、普段使うときはここまで考える必要はあまりないでしょう。大抵のイディオムの中で知らずに使っていることが多いです。</p><h4 id="クロージャを使って遅延実行・コールバックをする"><a href="#クロージャを使って遅延実行・コールバックをする" class="headerlink" title="クロージャを使って遅延実行・コールバックをする"></a>クロージャを使って遅延実行・コールバックをする</h4><p>クロージャは定義されたタイミングと実行されるタイミングが少しずれます。何か実行の準備が整ったタイミング、何かイベントがあったタイミングでコールバックされます。</p><p>単なる関数を別に定義しても結果は同じですが、その定義したところのスコープの変数へのアクセスが保持されるため、引数リストを短くできます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// スコープを抜けたタイミングで後から実行されるクロージャ</span></span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"関数実行が終了しました"</span>)</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="comment">// goroutineを作成して並列動作が可能になったときに実行されるクロージャ</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"並列動作しています"</span>)</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="comment">// フォルダを探索し、ディレクトリやファイルを見つけるたびに実行されるクロージャ</span></span><br><span class="line">err := filepath.Walk(<span class="string">"/path/to/count/files"</span>, <span class="function"><span class="keyword">func</span><span class="params">(path <span class="keyword">string</span>, info os.FileInfo, err error)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Printf(<span class="string">"path=%s is-dir=%v\n"</span>, path, info.IsDir())</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h4 id="クロージャの中に変数やデータを閉じ込める"><a href="#クロージャの中に変数やデータを閉じ込める" class="headerlink" title="クロージャの中に変数やデータを閉じ込める"></a>クロージャの中に変数やデータを閉じ込める</h4><p>乱暴な言い方をしてしまえば、構造体を作らずに、構造体のようなものを作ることです。Tour of Goのクロージャの説明はここにフォーカスしていましたね。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fibonacci</span><span class="params">()</span> <span class="title">func</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    prev, next := <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">        prev, next = next, prev+next</span><br><span class="line">        <span class="keyword">return</span> next</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f := fibonacci()</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">    fmt.Println(f())</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 1</span></span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line"><span class="comment">// 3</span></span><br><span class="line"><span class="comment">// 5</span></span><br><span class="line"><span class="comment">// 8</span></span><br><span class="line"><span class="comment">// 13</span></span><br><span class="line"><span class="comment">// 21</span></span><br><span class="line"><span class="comment">// 34</span></span><br><span class="line"><span class="comment">// 55</span></span><br><span class="line"><span class="comment">// 89</span></span><br></pre></td></tr></table></figure><p>引数の数が多かったり、呼び出し条件が複雑だったりする場合、なおかつ、定義場所と遠く離れたところで呼び出される場合（ただし、フレームワークにユーザー定義の振る舞いを設定するケース以外）は構造体とメソッドにしてもいいかもしれません。実行場所と定義場所が離れているクロージャの本体を探すよりは、構造体を使った方がIDEで定義を探すのは簡単です。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> fibonacci <span class="keyword">struct</span> &#123;</span><br><span class="line">prev, next <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *fibonacci)</span> <span class="title">calc</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">f.prev, f.next = f.next, f.prev+f.next</span><br><span class="line"><span class="keyword">return</span> f.next</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newFibonacci</span><span class="params">()</span> *<span class="title">fibonacci</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;fibonacci&#123;</span><br><span class="line">prev: <span class="number">0</span>,</span><br><span class="line">next: <span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f := newFibonacci()</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">fmt.Println(f.calc())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ただ、Tour of Goのような無限配列のようなコードの場合はクロージャ単体よりも、チャネルとgoroutineを使った方が良いでしょう。なお、このコードは、サンプルをシンプルにするために無限ループになっており、外から中断できるようになっていないため、goroutineリークするコードになっていますので、このままコピーはしないでください。非同期処理・並列処理の書き方を参照してください。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fibonacci</span><span class="params">()</span> &lt;-<span class="title">chan</span> <span class="title">int</span></span> &#123;</span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">prev, next := <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="comment">// ループ一回ごとにチャネルに書き出し</span></span><br><span class="line">prev, next = next, prev+next</span><br><span class="line">c &lt;- next</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f := fibonacci()</span><br><span class="line"><span class="comment">// チャネルならforループに直接置ける</span></span><br><span class="line"><span class="keyword">for</span> next := <span class="keyword">range</span> f &#123;</span><br><span class="line">fmt.Println(next)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-タイムアウトのエラーと並列の重い処理をどう組み合わせていいかわかりません"><a href="#Q-タイムアウトのエラーと並列の重い処理をどう組み合わせていいかわかりません" class="headerlink" title="Q: タイムアウトのエラーと並列の重い処理をどう組み合わせていいかわかりません"></a>Q: タイムアウトのエラーと並列の重い処理をどう組み合わせていいかわかりません</h3><p>タイムアウトがチャネルになっています。複数の処理の待ち合わせは <code>sync.WaitGroup</code>を使いたいのですが、どのように組み立てれば良いかわかりません。</p><hr><p><strong>A: Goには、待ち合わせには関数呼び出しによるブロックと、チャネルと主に2種類あります。まずはすべてをチャネルに集約して、<code>select</code>に持ち込むのがポイントです。</strong></p><p>例えば、<code>sync.WaitGroup</code>を使う場合は、終了した時にそれを通知するチャネルをあらかじめ作り、<code>Wait()</code>完了後にそのチャネルに送信することで、関数呼び出しのブロックをチャネルに変換できます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">func NewWaitGroup(count int) (done func(), allDone &lt;-chan struct&#123;&#125;) &#123;</span><br><span class="line">wait := make(chan struct&#123;&#125;)</span><br><span class="line">allDone = wait</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">wg.Add(count)</span><br><span class="line">done = wg.Done</span><br><span class="line">go func() &#123;</span><br><span class="line">wg.Wait()</span><br><span class="line">wait &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;()</span><br><span class="line">return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>チャネルどうしであれば<code>select</code>が使え、どちらか先に解決したほうが実行される、ということが簡単に実現できます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">done, allDone := NewWaitGroup(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">timeout := time.After(<span class="number">5</span> * time.Second)</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">//何か重い処理</span></span><br><span class="line">done()</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-allDone:</span><br><span class="line">fmt.Println(<span class="string">"全部終了"</span>)</span><br><span class="line"><span class="keyword">case</span> &lt;-timeout:</span><br><span class="line">fmt.Println(<span class="string">"タイムアウト"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>なお、チャネルをラップしたデータ構造としては<code>context</code>があります。<code>context</code>は終了通知用に特化したチャネルをラップして、関数間でやり取りをしやすくしたものです。</p><h3 id="Q-コンテキストを受け取る関数ってどんなものなんでしょうか？"><a href="#Q-コンテキストを受け取る関数ってどんなものなんでしょうか？" class="headerlink" title="Q: コンテキストを受け取る関数ってどんなものなんでしょうか？"></a>Q: コンテキストを受け取る関数ってどんなものなんでしょうか？</h3><p>あと、コンテキストとはどのようなもので、どのように使えばいいのでしょうか？</p><hr><p><strong>A: コンテキストを受け取る関数は、処理に長い時間のかかる関数です。もし呼び出し側の都合で中断させたいときに<code>context</code>を使います。時間がかかるという点では、他の言語で言う所のasync関数と同じようなものと言えます。</strong></p><p>コンテキストは、goroutineを使って非同期に柔軟に仕事を行うGoで、まとめて中断したり、他の言語でいうスレッドローカルな、一つの処理単位に閉じた並列処理用の情報共有の手段としてGo 1.7から導入されました。</p><p>ウェブサービスは1つのHTTPリクエストを起点に処理がスタートしますが、その中で多数のAPIリクエストを並行して行ったりします。この「リクエスト単位の処理」を識別し、情報共有やら中断の通知をするために、<code>context.Context</code>のインタフェースのインスタンスを共有します。他の言語だと、1リクエストは1スレッドとして、スレッドローカルなストレージを使ったりスレッドのIDを使ったりしますが、Goのスタイルの方が柔軟です。</p><p>書き方は次の3つに分けて説明します。</p><ul><li>作って呼び出す側</li><li>外部プロセス起動、APIアクセスなどのOS由来の重い処理を投げる</li><li>プロセス内の複数のタスク呼び出しの結果取得などの重い処理を扱う</li></ul><p>まずは作って呼び出す側の書き方です。</p><p>コンテキストを受け取る関数は<code>ctx</code>という名前で第一引数で渡すのがGoの流儀です。<br>コンテキストはデフォルトの<code>context.Background()</code>で作り、必要に応じて手動キャンセルがしたい（<code>context.WithCancel()</code>）、一定時間経過したら中断したい（<code>context.WithTimeout()</code>）、指定した時間になったら中断したい（<code>context.Deadline()</code>）でラップします。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handler</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    <span class="comment">// Backgroundはキャンセル処理はせず、情報共有のためだけのcontext</span></span><br><span class="line">    ctx := context.Background()</span><br><span class="line">    <span class="comment">// WithCancelはキャンセルできるcontext</span></span><br><span class="line">    <span class="comment">// cancelは異常時で中断したい時以外にも、正常終了時に最後に呼ぶこと</span></span><br><span class="line">    ctx, cancel := context.WithCancel(ctx)</span><br><span class="line">    <span class="keyword">defer</span> cancel()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 子供の仕事を実行するときに第一引数で渡す</span></span><br><span class="line">    work1(ctx, r)</span><br><span class="line">    work2(ctx, r)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>次に外部プロセス起動、APIアクセスなどのOS由来の重い処理を投げる書き方の紹介です。標準ライブラリの<code>net/http</code>や<code>os/exec</code>は<code>context</code>を受け取って、終了通知が来たら通信を中断したり、外部コマンドにシグナルを送って中断させるキャンセル処理ができるAPIも提供しています。<code>net/http</code>は多少不便なので、非標準の<code>ctxhttp</code>を使うと簡単ですし、そのうち標準ライブラリも改善される予定ではあります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"https://godoc.org/golang.org/x/net/context/ctxhttp"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">accessSHS</span><span class="params">(ctx context.Context)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ctxを第一引数で渡す</span></span><br><span class="line">    res, err := ctxhttp.Get(ctx, <span class="literal">nil</span>, <span class="string">"https://shs.sh"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最後に、自分でコンテキストの中断をハンドリングさせる方法です。コンテキストの中はチャネルですので、重い処理をすべてチャネルとして取り出せるようにしておけば、<code>select</code>を使ってコンテキストの中断と一緒に扱うことができます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">launchBatch</span><span class="params">(ctx context.Context)</span></span> &#123;</span><br><span class="line">    resultChan := <span class="built_in">make</span>(<span class="keyword">chan</span> Result)</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> result := &lt;-resultChan:</span><br><span class="line">        <span class="comment">// 正常に終了</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">        <span class="comment">// 親の都合でキャンセル</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-省略可能な引数はどのように実現するのですか？"><a href="#Q-省略可能な引数はどのように実現するのですか？" class="headerlink" title="Q: 省略可能な引数はどのように実現するのですか？"></a>Q: 省略可能な引数はどのように実現するのですか？</h3><p>Pythonや最近のJavaScriptは引数を省略する、デフォルト値を設定する方法を提供しています。Javaはオーバーロードを駆使すれば変数の数によって似たことを実現できます。Goではどのようにするのでしょうか？</p><hr><p>Goには省略可能な引数もオーバーロードもありません。可変長引数や、メンバーが省略可能な構造体を利用してオプション引数を実現します。</p><p>なお、可変長引数で型を <code>interface{}</code> にして動的に型アサーションして読み込む方法もありますが、複雑になると破綻しがちなのと、引数の役割が呼び出し側でわかりにくいのでここでは紹介しません。</p><h4 id="名前違いの関数をいくつも提供する"><a href="#名前違いの関数をいくつも提供する" class="headerlink" title="名前違いの関数をいくつも提供する"></a>名前違いの関数をいくつも提供する</h4><p>たとえば、<code>strings</code>パッケージには、文字列の前後の指定された文字をカットする<code>strings.Trim(s, cutset)</code>関数と、文字列の前後のスペースを取り除く<code>strings.TrimSpace(s)</code>があります。</p><p>細かくたくさんの引数を受け取る関数を定義し、それをラップしてデフォルトの引数を付与する便利関数を定義する、というのがGoでよく利用される方法です。</p><h4 id="オプション構造体"><a href="#オプション構造体" class="headerlink" title="オプション構造体"></a>オプション構造体</h4><p>最近よく見るパターンです。実装が簡単なので実装者にとってはやりやすい方法です。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Option <span class="keyword">struct</span> &#123;</span><br><span class="line">    Host <span class="keyword">string</span></span><br><span class="line">    Port <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetData</span><span class="params">(o Option)</span> <span class="params">(<span class="keyword">string</span>, error)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 初期値を与える</span></span><br><span class="line">    <span class="keyword">if</span> o.Host == <span class="string">""</span> &#123;</span><br><span class="line">        o.Host = <span class="string">"localhost"</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> o.Port == <span class="number">0</span> &#123;</span><br><span class="line">        o.Port = <span class="number">65535</span></span><br><span class="line">    &#125;</span><br><span class="line">    res, err := http.Get(fmt.Sprintf(<span class="string">"http://%s:%d"</span>, o.Host, o.Port))</span><br><span class="line">    :</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 利用時</span></span><br><span class="line">d, e := GetData(Option&#123;</span><br><span class="line">  Host: <span class="string">"example.com"</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h4 id="Builderパターンの変形"><a href="#Builderパターンの変形" class="headerlink" title="Builderパターンの変形"></a>Builderパターンの変形</h4><p>JavaでおなじみのBuilderパターンの変形もたまにGoでみかけます。Builderパターンは本来は構造体などの初期化で使うパターンですが、関数呼び出しでも使えます。</p><p><a href="https://godoc.org/google.golang.org/api/drive/v3" target="_blank" rel="noopener">Google Drive API</a>では大々的に使われています。List()の返り値はDrivesListCallという構造体で、この構造体のメソッドを呼ぶたびに、構造体に引数が設定されていきます。最後に<code>Do()</code>を呼び出すと、処理が実行されます。それ以外にも<a href="https://gorm.io/docs/query.html" target="_blank" rel="noopener">ORマッパーのクエリーの組み立て</a>でも使われたりします。</p><p>難点としては、実装が多くなりがちなのと、このパターンを知らない人がいきなりドキュメントを見ても使い方が難しいと感じがちな点です。ただ、コード補完はバッチリ効くので、一度なれたら快適でしょう。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">driveService, err := drive.NewService(ctx)</span><br><span class="line"></span><br><span class="line">list, err := driveService</span><br><span class="line">    .List().PageSize(<span class="number">20</span>).Q(<span class="string">"name contains 'secret'"</span>).Do()</span><br></pre></td></tr></table></figure><p>Pythonの疑似コードで例えるなら次のような感じになります（実際のGoogle提供のAPIとは違いますが）。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list = drive_service.list(page_size=<span class="number">20</span>, Q=<span class="string">"name contains 'secret'"</span>)</span><br></pre></td></tr></table></figure><h4 id="設定値をグローバルな構造体に設定して、それを利用する関数を使用"><a href="#設定値をグローバルな構造体に設定して、それを利用する関数を使用" class="headerlink" title="設定値をグローバルな構造体に設定して、それを利用する関数を使用"></a>設定値をグローバルな構造体に設定して、それを利用する関数を使用</h4><p><code>net/http</code>の<code>http.Get()</code>などが利用しているパターンです。<br>HTTPアクセスには、アクセス経路（TCP/IPなのか、はたまたローカルのサーバーとUnixドメインソケットで直結なのか)とか、タイムアウトとか、TLSの設定とか、パラメータが大量にあります。簡単関数とそれらを1つずつ受ける関数を作るのも大変ですし、ちょっと高度な使い方を使用としたときに呼び出し先をすべて変更してまわらないといけないのは大変です。</p><p>Goの<code>net/http</code>パッケージは、<code>DefaultClient</code>という<code>Client</code>構造体のインスタンスがグローバル変数として定義されており、<code>http.Get()</code>などはこれのメソッドを間接的に呼び出します。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Get</span><span class="params">(url <span class="keyword">string</span>)</span> <span class="params">(resp *Response, err error)</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> DefaultClient.Get(url)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>この<code>DefaultClient</code>に、自作の<code>Client</code>のインスタンスを入れることで、プログラム全体が同じ通信設定を利用できます。大抵、通信設定が複数に必要になるケースはあまりないため、このようなAPIでも問題なることはいまのところ聞いていません。</p><p>単なるグローバル変数と何が違うかというと、構造体単体を初期化してそのメソッドを呼ぶと、他の設定に依存せずに独立して利用できます。いざという時に複数の設定が必要になっても機械的に移行できますし、ライブラリ側のテストもしやすいです。</p><h4 id="可変長引数を利用した方法"><a href="#可変長引数を利用した方法" class="headerlink" title="可変長引数を利用した方法"></a>可変長引数を利用した方法</h4><p>Goでは、すでに存在している型にも別名の型を定義でき、それを制約にすることができます。</p><p>Go Patternsの<a href="http://tmrts.com/go-patterns/idiom/functional-options.html" target="_blank" rel="noopener">Functional Options</a>はその応用例の一つです。Go Patternsのサンプルの完成形の部分だけ貼ります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fillerFile, err := file.New(</span><br><span class="line">    <span class="string">"/tmp/file.txt"</span>,</span><br><span class="line">    file.UID(<span class="number">1000</span>),</span><br><span class="line">    file.Contents(<span class="string">"Lorem Ipsum Dolor Amet"</span>))</span><br></pre></td></tr></table></figure><p>難点はコードの量が多くなる、パッケージのドキュメントが散らかる（New関数も引数の関数もフラットにソートされてしまう）ために、読みにくくなるといったことが挙げられます。あまり現実世界では見たことがありません。</p><h3 id="Q-goroutineの中から外の変数にアクセスすると値がおかしくなる"><a href="#Q-goroutineの中から外の変数にアクセスすると値がおかしくなる" class="headerlink" title="Q: goroutineの中から外の変数にアクセスすると値がおかしくなる"></a>Q: goroutineの中から外の変数にアクセスすると値がおかしくなる</h3><p>ループの中でループ変数などを参照するときになぜか変な値になってしまいます</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(i)</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 8</span></span><br><span class="line"><span class="comment">// 10</span></span><br><span class="line"><span class="comment">// 10</span></span><br></pre></td></tr></table></figure><hr><p><strong>A: 関数は定義されている外の情報にアクセスできます。ただし、ポインタを持っているだけなので、値が変更されると呼ばれたときではなく、最新の値を読み込んでしまいます。</strong></p><p>たいていのプログラミング言語では、「レキシカルスコープ」と呼ぶこの機能を実装しています。関数の中で関数を定義すると、その関数は当然外の変数にアクセスできて当然である、と誰しもが思うでしょう。しかし、これはコンパイラが気を利かせて、関数に隠れた引数を追加して、中からアクセスしている変数のポインタを渡すようにコードを改変しているのです（Pythonは親の名前空間として持っていて、ローカルで参照できない場合は親の名前空間に順番に探しに行くことで解決）。</p><p>Goのgroutineは高速とはいえ、forループが回る速度よりは低速です。そのため、goroutineが起動するころにはほとんどループが終わってしまっています。そのため、ほとんどの上記のgroutineではiが10になっています。</p><p>ポインタなのが問題なので、インスタンス化してコピーを保持するのがもっとも安全な解決方法です。コピーは関数の引数として渡す方がよいでしょう。これにより、goroutineが起動したときの変数の状態を固定化して、期待通りの結果が得られます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(i <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">fmt.Println(i)</span><br><span class="line">&#125;(i) <span class="comment">// ここで引数としてiを入れることでコピーが引数として残る</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 5</span></span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line"><span class="comment">// 1</span></span><br><span class="line"><span class="comment">// 3</span></span><br><span class="line"><span class="comment">// 7</span></span><br><span class="line"><span class="comment">// 6</span></span><br><span class="line"><span class="comment">// 0</span></span><br><span class="line"><span class="comment">// 9</span></span><br><span class="line"><span class="comment">// 4</span></span><br><span class="line"><span class="comment">// 8</span></span><br></pre></td></tr></table></figure><h3 id="Q-deferの中で変数の値が期待と違います"><a href="#Q-deferの中で変数の値が期待と違います" class="headerlink" title="Q: deferの中で変数の値が期待と違います"></a>Q: deferの中で変数の値が期待と違います</h3><p>deferは終了時に呼ばれるはずですが、変数が終了していない状態のものになってしまっています。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">finished := <span class="literal">false</span></span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">(finished <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">fmt.Println(finished)</span><br><span class="line"><span class="comment">// false</span></span><br><span class="line">&#125;(finished)</span><br><span class="line"></span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line"></span><br><span class="line">finished = <span class="literal">true</span></span><br></pre></td></tr></table></figure><hr><p><strong>A: 呼び出しはスコープを抜ける時に行われますが、引数の評価は宣言時に行われています。</strong></p><p>クロージャの時のケースの逆です。このケースではdefer文のところでfinishedのインスタンスのコピーが作られて固定化されてしまっているため、その後finishedを変更してもdeferの中では呼び出し時の状態に固定化されてしまっています。関数終了時の状態が必要であれば、クロージャにする、ポインタを引数で受け取るなどして最終状態にアクセスできるようにしなければなりません。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">finished := <span class="literal">false</span></span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(finished)</span><br><span class="line"><span class="comment">// true</span></span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line"></span><br><span class="line">finished = <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="Q-関数型スタイルのリスト処理がやりたいがGoではどうすれば良いですか？"><a href="#Q-関数型スタイルのリスト処理がやりたいがGoではどうすれば良いですか？" class="headerlink" title="Q: 関数型スタイルのリスト処理がやりたいがGoではどうすれば良いですか？"></a>Q: 関数型スタイルのリスト処理がやりたいがGoではどうすれば良いですか？</h3><p>JavaScriptのArrayのmap/reduce/forEach/filterのメソッドを利用したコーディングが好きです。Javaにもstreamが入りました。Pythonにはリスト内包表記があります。Goではどのようにすればいいでしょうか？</p><hr><p><strong>A: Goではそのスタイルをサポートする機能があまりないのであきらめてください。</strong></p><p>手続き型的にコードを書くのではなく、リストに入ったデータに対して、その加工方法（関数）を渡して（高階関数）すべての要素にパイプライン的に処理させる機能を充実させている言語は増えていますが、Goではそのようなサポートはありません。あきらめてforループを書きましょう。もちろん、末尾再帰もありません。パターンマッチもありません。</p><p>関数が一級オブジェクトではあるので、自分でmap相当の処理を書くことで似たことは実現できますが、あまり強力に推論してくれたりしないので、型アサーションの嵐になるか、リフレクションで頑張らざるを得ないため、必ずしもシンプルには実現できないでしょう。</p><h3 id="Q-外部のAPI呼び出しなどの時間のかかる処理でタイムアウトを実装するにはどうすれば良いでしょうか？"><a href="#Q-外部のAPI呼び出しなどの時間のかかる処理でタイムアウトを実装するにはどうすれば良いでしょうか？" class="headerlink" title="Q: 外部のAPI呼び出しなどの時間のかかる処理でタイムアウトを実装するにはどうすれば良いでしょうか？"></a>Q: 外部のAPI呼び出しなどの時間のかかる処理でタイムアウトを実装するにはどうすれば良いでしょうか？</h3><h2 id="構造体・インタフェース"><a href="#構造体・インタフェース" class="headerlink" title="構造体・インタフェース"></a>構造体・インタフェース</h2><h3 id="Q-Goの構造体とかインタフェースの定義の構文は冗長に見えます"><a href="#Q-Goの構造体とかインタフェースの定義の構文は冗長に見えます" class="headerlink" title="Q: Goの構造体とかインタフェースの定義の構文は冗長に見えます"></a>Q: Goの構造体とかインタフェースの定義の構文は冗長に見えます</h3><p>Javaとかだと、class { 実装 }だけど、キーワードが多いし順番に違和感を覚えます。</p><hr><p><strong>A: Goは構造体もインタフェースもインラインで定義できます。インラインの定義構文＋名前の定義の組み合わせになっています。</strong></p><p>例えば、テーブル駆動テストはたいてい、インラインで構造体を定義してその配列をその場でインスタンスまで作ってしまいます。1行でやってしまっています。関数内部でしか使われない型はこのようにつくってしまえるのがGoです。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestSum</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">    testcases := []<span class="keyword">struct</span> &#123;</span><br><span class="line">        name         <span class="keyword">string</span></span><br><span class="line">        a, b, result <span class="keyword">int</span></span><br><span class="line">    &#125;&#123;</span><br><span class="line">        &#123;name: <span class="string">"p + p"</span>, a: <span class="number">10</span>, b: <span class="number">10</span>, result: <span class="number">20</span>&#125;,</span><br><span class="line">        &#123;name: <span class="string">"p + 0"</span>, a: <span class="number">20</span>, b: <span class="number">0</span>, result: <span class="number">20</span>&#125;,</span><br><span class="line">        &#123;name: <span class="string">"n + p"</span>, a: <span class="number">-10</span>, b: <span class="number">10</span>, result: <span class="number">0</span>&#125;,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> _, testcase := <span class="keyword">range</span> testcases &#123;</span><br><span class="line">        t.Run(testcase.name, <span class="function"><span class="keyword">func</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">            actual := Sum(testcase.a, testcase.b)</span><br><span class="line">            <span class="keyword">if</span> actual != testcase.result &#123;</span><br><span class="line">                t.Fatalf(<span class="string">"expected: %d, actual %d"</span>, testcase.result, actual)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一方、既存の型に名前をつけるのがtypeです。<code>type 新しい名前 既存の型</code>で使います。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> ErrorFlag <span class="keyword">int</span></span><br></pre></td></tr></table></figure><p>Goの構造体定義の書き方はこの2つの合成です。既存の型部分にインラインの構造体定義がくっつているというわけです。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> SmallAnimal <span class="keyword">struct</span> &#123;</span><br><span class="line">    FavoriteDrink <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>インタフェースのインライン定義も使ったことはありませんが、osパッケージのerror.goで見ることができます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e, ok := err.(<span class="keyword">interface</span>&#123; Is(error) <span class="keyword">bool</span> &#125;)</span><br></pre></td></tr></table></figure><p>この一行で、errというポインタ変数が<code>func Is(error) bool</code>というメソッドを持っているかどうか、という判断ができます。</p><h3 id="Q-構造体をJSONに書き出そうとしているのですがメンバー変数の値が出力されません。なぜでしょうか？"><a href="#Q-構造体をJSONに書き出そうとしているのですがメンバー変数の値が出力されません。なぜでしょうか？" class="headerlink" title="Q: 構造体をJSONに書き出そうとしているのですがメンバー変数の値が出力されません。なぜでしょうか？"></a>Q: 構造体をJSONに書き出そうとしているのですがメンバー変数の値が出力されません。なぜでしょうか？</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="keyword">string</span> <span class="string">`json:"name"`</span></span><br><span class="line">age  <span class="keyword">int</span>    <span class="string">`json:"age"`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p><strong>A: 外部パッケージから利用できる名前は大文字スタートでないといけません。<code>encoding/json</code>パッケージはリフレクションでデータを読みに行きますが、大文字スタート以外の名前の変数は無視されます。</strong></p><p>そのため、name, ageの先頭を大文字にすれば出力されるようになります。</p><h3 id="Q-汎用的なロジックを実装したいが、Goの場合は型が決まってしまうため再利用がしにくい"><a href="#Q-汎用的なロジックを実装したいが、Goの場合は型が決まってしまうため再利用がしにくい" class="headerlink" title="Q: 汎用的なロジックを実装したいが、Goの場合は型が決まってしまうため再利用がしにくい"></a>Q: 汎用的なロジックを実装したいが、Goの場合は型が決まってしまうため再利用がしにくい</h3><p>複数のデータ変換用の構造体に対する処理とかを書くのが大変。どうすれば良いか？</p><hr><p><strong>A: 共通化を行うためには、共通化のための仕組みを作り込む必要があります。</strong></p><p>Goはなるべく高速に動作し、型のチェックをきちんと行いつつ、すばやくコンパイルが完了するというのを目指して作られた処理系です。柔軟性よりも、存在しないメンバーや変数へのアクセスがないかがすぐにわかって、実行時のメモリレイアウトがカチッと決まることがGoのコンパイラの価値です。</p><p>共通化のための仕組みを実現する方法はいくつかあります。</p><h4 id="インタフェースを実装する方法"><a href="#インタフェースを実装する方法" class="headerlink" title="インタフェースを実装する方法"></a>インタフェースを実装する方法</h4><p>処理対象の構造体の共通インタフェースを定義して、それに対する処理を書きます。インタフェースは構造体のメンバー変数へのアクセスができないため、まず、必要な読み書きのメソッドを用意します。その後、そのメソッドを持つインタフェースを定義して、共通処理をそのメソッドを使って行うようにします。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">  Name <span class="keyword">string</span></span><br><span class="line">  Age  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p Person)</span> <span class="title">GetName</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> p.Name</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Dog <span class="keyword">struct</span> &#123;</span><br><span class="line">  Name     <span class="keyword">string</span></span><br><span class="line">  Age      <span class="keyword">int</span></span><br><span class="line">  FurColor Color</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d Dog)</span> <span class="title">GetName</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> d.Name</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Living <span class="keyword">interface</span> &#123;</span><br><span class="line">  GetName() <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 共通処理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">PrintName</span><span class="params">(l Living)</span></span> &#123;</span><br><span class="line">  fmt.Println(l.GetName())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="構造体の埋め込みを使う方法"><a href="#構造体の埋め込みを使う方法" class="headerlink" title="構造体の埋め込みを使う方法"></a>構造体の埋め込みを使う方法</h4><p>共通の属性が一意に定まり、なおかつ共通処理はそこの情報にしか絶対にアクセスしないと保証できるなら、共通の属性を構造体として切り出し、それを各構造体に埋め込みます。</p><p>ただし、共通処理に対するコードを書く場合は、それ以外の要素にアクセスしようとか、メソッドのオーバーライドをしたいとか、一般的なオブジェクト指向言語のノリで扱うと想定通りに動かなくて時間を取られることになりますので、用法容量を守ってお使いください。</p><ul><li>参考: <a href="https://qiita.com/shibukawa/items/16acb36e94cfe3b02aa1" target="_blank" rel="noopener">オブジェクト指向言語としてGolangをやろうとするとハマること</a></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Living <span class="keyword">struct</span> &#123;</span><br><span class="line">  Name <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">  Living</span><br><span class="line">  Age  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Dog <span class="keyword">struct</span> &#123;</span><br><span class="line">  Living</span><br><span class="line">  Age      <span class="keyword">int</span></span><br><span class="line">  FurColor Color</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 共通処理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">PrintName</span><span class="params">(l Living)</span></span> &#123;</span><br><span class="line">  fmt.Println(l.Name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-構造体にメソッドを追加しました。メンバー変数を書き換えようとしても変更されません。なぜでしょうか？"><a href="#Q-構造体にメソッドを追加しました。メンバー変数を書き換えようとしても変更されません。なぜでしょうか？" class="headerlink" title="Q: 構造体にメソッドを追加しました。メンバー変数を書き換えようとしても変更されません。なぜでしょうか？"></a>Q: 構造体にメソッドを追加しました。メンバー変数を書き換えようとしても変更されません。なぜでしょうか？</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> SmallAnimal <span class="keyword">struct</span> &#123;</span><br><span class="line">    name <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s SmallAnimal)</span> <span class="title">SetName</span><span class="params">(name <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">    s.name = name</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p><strong>A: メソッドのレシーバーがポインタでないとメンバーへの変更ができません。</strong></p><p>読み込み専用にしたい場合はポインタを外してインスタンスにします。基本的には最初は全部ポインタをつけておいて、「このメソッド内部では変更しないな」というのが確定する場合だけ外すというのが良いでしょう。メソッドからメソッドを呼ぶ場合がややこしいので、困ったら全部ポインタにしてしまいましょう。</p><h3 id="Q-ある構造体に対する処理を実装する場合は、メソッドにすべきか、それとも構造体を引数に取る関数にすべきか？"><a href="#Q-ある構造体に対する処理を実装する場合は、メソッドにすべきか、それとも構造体を引数に取る関数にすべきか？" class="headerlink" title="Q: ある構造体に対する処理を実装する場合は、メソッドにすべきか、それとも構造体を引数に取る関数にすべきか？"></a>Q: ある構造体に対する処理を実装する場合は、メソッドにすべきか、それとも構造体を引数に取る関数にすべきか？</h3><p>Goには構造体の処理の書き方が2通りあります。どちらが良いですか？</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1: メソッド</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Struct)</span> <span class="title">Method</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// sに対する処理を書く</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2: 関数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Func</span><span class="params">(s *Struct)</span></span> &#123;</span><br><span class="line">    <span class="comment">// sに対する処理を書く</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p><strong>A: 最初にメソッドで実装してしまえばいいんじゃないでしょうか？</strong></p><p>メソッドの方は、使う側からすれば、 <code>s.</code> とドットを打った時点でそれに関連するメソッドが補完されますので、再認でコーディングがしやすいというメリットがあります。また、関数にしても、<code>パッケージ名.関数名</code>となってしまうため、利用するコード上は多少冗長になります。</p><p>ただし、処理対象が1つの構造体ではなく、複数の構造体がくる可能性のあるインタフェースになる場合は、関数の方が1つの実装でたくさんの処理対象に対して利用できるので、数が多くなってきたら関数で良いかと思います。</p><h3 id="Q-エラーの構造体を作っています。そのエラーがタイムアウトかそうじゃないかを機械的にboolで判断できるようにするメソッドを追加したいのですが、どうすれば良いでしょうか？"><a href="#Q-エラーの構造体を作っています。そのエラーがタイムアウトかそうじゃないかを機械的にboolで判断できるようにするメソッドを追加したいのですが、どうすれば良いでしょうか？" class="headerlink" title="Q: エラーの構造体を作っています。そのエラーがタイムアウトかそうじゃないかを機械的にboolで判断できるようにするメソッドを追加したいのですが、どうすれば良いでしょうか？"></a>Q: エラーの構造体を作っています。そのエラーがタイムアウトかそうじゃないかを機械的にboolで判断できるようにするメソッドを追加したいのですが、どうすれば良いでしょうか？</h3><p>標準のエラー構造体は文字列を取り出すError()メソッドしかなく、詳細情報をそこをパースして取り出すのは変更に弱いコードになってしまいます。良い方法はないでしょうか？</p><hr><p><strong>A: errorインタフェースを満たす実装以外に別のインタフェースも提供して、型アサーションで別のインタフェースを取り出す方法があります。</strong></p><p>まず、公開要素のTimeoutErrorインタフェースと、非公開のtimeoutError構造体を作ります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> TimeoutError <span class="keyword">interface</span> &#123;</span><br><span class="line">    timeout()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> timeoutError <span class="keyword">struct</span> &#123;</span><br><span class="line">    error <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// errorインタフェース用のメソッド</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t timeError)</span> <span class="title">Error</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> t.error</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// TimeoutErrorインタフェース用のメソッド（private)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t timeError)</span> <span class="title">timeout</span><span class="params">()</span></span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>何かしらの処理がタイムアウトしたときは、timeoutError構造体のポインタ値を返すようにします。これはerrorインタフェースを満たすので、関数の返り値はerror型でOKです。</p><p>で、この構造体はerror型以外にも、新規で作ったTimeoutErrorインタフェースも満たしますので、インタフェースからインタフェースの型アサーションも成功します。そのため、次のようにキャストすることでerrorインタフェースが持てない情報を別のインタフェースを通じて提供することができます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> _, ok := err.(TimeoutError); ok &#123;</span><br><span class="line">    <span class="comment">// キャストが成功したのでタイムアウトエラーと判定可能</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一定以上の年齢の人にはCOMのqueryInterfaceと言えば伝わるテクニックです。</p><h2 id="エラー処理・例外処理"><a href="#エラー処理・例外処理" class="headerlink" title="エラー処理・例外処理"></a>エラー処理・例外処理</h2><h3 id="Q-エラーの種別はどのようにして区別すれば良いでしょうか？"><a href="#Q-エラーの種別はどのようにして区別すれば良いでしょうか？" class="headerlink" title="Q: エラーの種別はどのようにして区別すれば良いでしょうか？"></a>Q: エラーの種別はどのようにして区別すれば良いでしょうか？</h3><p><code>nil</code>と比較することでエラーの有無の確認はわかったのですが、タイムアウトなのかファイルがないのかを区別するにはどうすれば良いでしょうか？</p><hr><p><strong>A: ここはGo言語の実装者同士の間でも設計がぶれているところですが、基本的には型アサーションで行うことが多いでしょう。</strong></p><p>Go本体のコードを見ても、2種類あります。osパッケージにはエラー種別を区別する関数がいくつか提供されています。IsExists, IsNotExist, IsPermission, IsTimeoutがあります。この方式はコードが一見きれいに見えますが、osパッケージ以外では見ない気がします。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_, err := os.Stats(<span class="string">"file"</span>)</span><br><span class="line"><span class="keyword">if</span> os.IsNotExist(err) &#123;</span><br><span class="line">  <span class="comment">// ファイルが存在しない</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他のケースでは型アサーションがあります。こちらのほうがサードパーティ製ライブラリでは一般的な気がします。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">err := json.Unmarshal(jsonStr, person)</span><br><span class="line"><span class="keyword">if</span> _, ok := err.(*json.InvalidUnmarshalError); ok &#123;</span><br><span class="line">  <span class="comment">// unmarshal errorのとき</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-panicはどのような時に使うのか？"><a href="#Q-panicはどのような時に使うのか？" class="headerlink" title="Q: panicはどのような時に使うのか？"></a>Q: panicはどのような時に使うのか？</h3><p>Goは例外がない言語で、errorを最後の返り値として渡すのが一般的ですが、panicはどうやって使うんでしょうか？</p><hr><p><strong>A: panicとrecoverを使えば例外のようなことができますが、Goでは一般的ではありません。プログラマーの間違いを引っ掛けるのに使う、と考えれば良いでしょう。</strong></p><p>Goでよくpanicを使うのは、入力値が固定値だったり、実行時に変動しないデータを扱う場合です。例えば正規表現、テンプレートなど、入力値が文字列で、内部でコンパイルのようなことを行う関数は、<code>Must</code>で始まる関数も提供しています。この<code>Must</code>な関数は処理が失敗すると<code>panic</code>になります。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> validID *regexp.Regexp</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">   <span class="keyword">var</span> validID = regexp.MustCompile(<span class="string">`^[a-z]+\[[0-9]+\]$`</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Q-log-Fatal-や-os-Exit-ってどのような時に使うのか？"><a href="#Q-log-Fatal-や-os-Exit-ってどのような時に使うのか？" class="headerlink" title="Q: log.Fatal() や os.Exit() ってどのような時に使うのか？"></a>Q: <code>log.Fatal()</code> や <code>os.Exit()</code> ってどのような時に使うのか？</h3><p>これらの関数を使うとプログラムが終了できますが、いろいろ副作用があるようです。どこで使うべきですか？</p><hr><p><code>log.Fatal()</code> は内部では <code>os.Exit(1)</code> を呼んでいるので、 <code>os.Exit()</code> ど同等なので後者に絞って説明します。 <code>os.Exit()</code>を呼ぶと、その次の行が実行されずにプログラムが終了します。問題なのは、 <code>defer</code>で設定した後処理が無視されてしまうので、完了時にネットワーク切断とかもろもろ後片付けをする行儀の良いコードが動作しなくなります。また、そのロジックが有用なコードでも、コマンドラインツールのように一回実行して完了するプログラム以外で使用が不可能になります。</p><p>基本的には、main関数以外ではerrorを上流に返していき、最後の最後、main関数の中で <code>os.Exit</code>を呼んでステータスコードを0以外にする、という使い方以外で使うことはないでしょう。</p><h3 id="Q-並列処理で複数のAPI呼び出しをしています。どこかでエラーがおきた時にまとめて終了させたいときはどうすればいいですか？"><a href="#Q-並列処理で複数のAPI呼び出しをしています。どこかでエラーがおきた時にまとめて終了させたいときはどうすればいいですか？" class="headerlink" title="Q: 並列処理で複数のAPI呼び出しをしています。どこかでエラーがおきた時にまとめて終了させたいときはどうすればいいですか？"></a>Q: 並列処理で複数のAPI呼び出しをしています。どこかでエラーがおきた時にまとめて終了させたいときはどうすればいいですか？</h3><p>それぞれの処理で途中で継続できなくなった時に、他の処理も中断させたいと思います。どのようにすれば良いでしょうか？</p><hr><p><strong>A: <code>context</code>はまさにその用途で使うものです。<code>context</code>は並列処理で使える例外のようなものです。</strong></p><p>JavaやPythonやJavaScriptはエラー処理機構として例外を持っており、Goはそれを持っていないと言われます。しかし、一般的な言語の例外は、呼び出し先から呼び出し元に戻っていきます。その途中で受け取って後片付けを行ったりしますが、呼び出し元と呼び出し先は1:1の関係です。Goのようにgoroutineをカジュアルにたくさん作って処理を行う場合。どこかで復旧不能なエラーが発生したら、並行で実行されている他のタスクもキャンセルしたいですよね？そのような場合に<code>context</code>を使います。</p><p>ただし、<code>context</code>パッケージをそのまま使い、タスクの終了を監視しつつ（<code>sync.WaitGroup</code>)、各ジョブのエラーのレスポンスを監視し、どこかのgoroutineがエラーを返したら<code>context</code>のキャンセルを行うというコードを書くのは結構骨が折れます。非標準パッケージの<code>golang.org/x/sync/errgroup</code>を使うと、1/10ぐらいの行数で実現ができます。</p><p><code>Go()</code>メソッドはerrorを返す関数で、これがerrorを返すと、すべての並列実行タスクを終了します。これは並列じゃなくてもよくて、順次実行されるジョブでも使えます。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"io/ioutil"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"net/http"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"golang.org/x/sync/errgroup"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">eg := errgroup.Group&#123;&#125;</span><br><span class="line"></span><br><span class="line">results := <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="keyword">byte</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">eg.Go(<span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">res, err := http.Get(<span class="string">"http://shs.sh"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> res.Body.Close()</span><br><span class="line">result, _ := ioutil.ReadAll(res.Body)</span><br><span class="line">results &lt;- result</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">eg.Go(<span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">res, err := http.Get(<span class="string">"http://sh.shs"</span>) <span class="comment">// 間違ったドメイン</span></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> res.Body.Close()</span><br><span class="line">result, _ := ioutil.ReadAll(res.Body)</span><br><span class="line">results &lt;- result</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := eg.Wait(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalln(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ロギング"><a href="#ロギング" class="headerlink" title="ロギング"></a>ロギング</h2><h3 id="Q-ログレベルを設定したログ出力はどのように実現するのか？"><a href="#Q-ログレベルを設定したログ出力はどのように実現するのか？" class="headerlink" title="Q: ログレベルを設定したログ出力はどのように実現するのか？"></a>Q: ログレベルを設定したログ出力はどのように実現するのか？</h3><p>JavaのLog4J、Pythonのloggingパッケージではinfo/warnのようなログの出し分けができますが？Goではどのようにすればいいですか？</p><hr><p><strong>A: Goの標準ライブラリではサポートしていません。<a href="https://github.com/sirupsen/logrus" target="_blank" rel="noopener">logrus</a>や<a href="https://github.com/uber-go/zap" target="_blank" rel="noopener">zap</a>などのサードパーティ製のロギングライブラリを使うのが良いでしょう</strong></p><p>以前はlogrusほぼ一強でしたが、ハイパフォーマンスをうたったzapの人気も高まっています。zapは構造化ログに特化していますので用途に応じて選ぶと良いでしょう。zapはサンプリングレートなども設定できるので、本番環境でログが多すぎて困る、というケースでとりあえず対処するのも簡単です。</p><h3 id="Q-ログがChromeに比べて見にくいです"><a href="#Q-ログがChromeに比べて見にくいです" class="headerlink" title="Q: ログがChromeに比べて見にくいです"></a>Q: ログがChromeに比べて見にくいです</h3><hr><p><strong>A: Chromeの開発者コンソールはたいていのプログラミング言語のデバッグ環境よりも圧倒的に良いので諦めましょう。</strong></p><h2 id="データベース"><a href="#データベース" class="headerlink" title="データベース"></a>データベース</h2><h3 id="Q-DBのトランザクション制御はdatabase-sqlのBegin-つかう？"><a href="#Q-DBのトランザクション制御はdatabase-sqlのBegin-つかう？" class="headerlink" title="Q: DBのトランザクション制御はdatabase/sqlのBegin()つかう？"></a>Q: DBのトランザクション制御は<code>database/sql</code>の<code>Begin()</code>つかう？</h3><hr><p>直接間接問わず、最終的にはこのメソッドでトランザクションを制御することになるでしょう。</p><p><a href="https://github.com/jmoiron/sqlx/blob/3a411660be52b3236199fbfe1919f515cfc1ca32/sqlx.go#L343" target="_blank" rel="noopener">sqlxも内部では<code>Begin()</code>を使っています</a>し、<a href="https://github.com/jinzhu/gorm/blob/a6b790ffd00da9beddc60a0d2d5b9e31f03a3ffd/main.go#L535" target="_blank" rel="noopener">gormもsqlパッケージの<code>BeginTx()</code>を使っています</a>。便利ライブラリを使っても最終的には<code>database/sql</code>にたどり着きます。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>何か困ったことはないですか？と自社のチャットやら某コミュニティに投げて飛んで来た質問とか困った事例とかについては一通り回答を書いたりした、というのが今の状況です。コンパイラでエラーになるものはここでは入れてはなくて、文法を学んで、じゃあそれを組み合わせてどう使おう、というものだけにひとまず限定しています。</p><p>もちろん、これをまとめたあとにもいくつか質問が飛んだりしていて、入れたいものはたくさんありますが、ウェブで技術ブログという体裁で出すのは分量的にこれ以上は厳しいかなぁ、という気もしますので、今後どうやってまとめていくかはまた考えたいと思います。</p><h1 id="参考文献とか他のおすすめ"><a href="#参考文献とか他のおすすめ" class="headerlink" title="参考文献とか他のおすすめ"></a>参考文献とか他のおすすめ</h1><ul><li><a href="http://tmrts.com/go-patterns/" target="_blank" rel="noopener">http://tmrts.com/go-patterns/</a></li><li><a href="https://medium.com/eureka-engineering/go-beginner-3bb95e0790da" target="_blank" rel="noopener">https://medium.com/eureka-engineering/go-beginner-3bb95e0790da</a> </li><li><a href="https://qiita.com/shibukawa/items/16acb36e94cfe3b02aa1" target="_blank" rel="noopener">https://qiita.com/shibukawa/items/16acb36e94cfe3b02aa1</a>: 昔書いたオブジェクト指向なプログラミング言語のユーザー観点での記事</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;他の言語になれた人が、初めてGoを書いた時にわかりにくいな、と思った部分はどういうところがあるのか、難しいポイントはどこか、という情報を自分の経験や、会社の内外の人に聞いたりしてまとめてみました。まだまだたくさんあるのですが、多すぎるのでまずはこんなところで。コンテナで開発
      
    
    </summary>
    
      <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
      <category term="Go" scheme="https://future-architect.github.io/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>アルバイト生から見たフューチャーのTIG DXユニット</title>
    <link href="https://future-architect.github.io/articles/20190712/"/>
    <id>https://future-architect.github.io/articles/20190712/</id>
    <published>2019-07-12T00:00:00.000Z</published>
    <updated>2019-07-11T15:20:56.387Z</updated>
    
    <content type="html"><![CDATA[<h2 id="導入"><a href="#導入" class="headerlink" title="導入"></a>導入</h2><p>はじめまして。</p><p>2019/7/1にFutureへ新卒入社した棚井龍之介と申します。</p><p>現在は会社の新人研修に誠意取り組んでおります。</p><p>大学を卒業してから入社するまでの期間、私は Future の TIG DXユニットにアルバイトとして参加しました。</p><blockquote><p>TIG: Technology Innovation Groupの略で、フューチャーの中でも特にIT技術に特化した部隊です。<br>DXユニット: TIGの中にありデジタルトランスフォーメーションに関わる仕事を推進していくチームです。</p></blockquote><p>アルバイトの視点から見た「Future ってこんな会社なんだ」について紹介いたします。</p><h2 id="筆者スキルセット"><a href="#筆者スキルセット" class="headerlink" title="筆者スキルセット"></a>筆者スキルセット</h2><ul><li>TCP/IP の授業を受けて、IT 分野に興味を持ちました</li><li>大学時代の４年から、 AI 系ベンチャー企業で５か月ほど長期アルバイトに参加しました</li><li>長期アルバイト中に触った技術<ul><li>言語<ul><li>Python</li></ul></li><li>インフラ寄り<ul><li>Docker</li><li>AWS</li></ul></li><li>OS<ul><li>MacOS</li></ul></li></ul></li></ul><h2 id="Future-入って分かったこと"><a href="#Future-入って分かったこと" class="headerlink" title="Future 入って分かったこと"></a>Future 入って分かったこと</h2><h3 id="開発に使う技術"><a href="#開発に使う技術" class="headerlink" title="開発に使う技術"></a>開発に使う技術</h3><ul><li>Go や Terraform など、イケイケのweb系企業が使いそうな技術をFutureでも使います</li></ul><p>Future といえども ITコンサル業界の一角を占めるお堅い会社であり、開発言語は「Java」がメインになると思っていました。しかしながら、初めに受けたタスクは「Node.js で記述されたアプリケーションを Go に書き換えて欲しい」というものでした。「ある案件で利用する言語をなるべくGoで統一したい」という方針から生じたタスクだったので、私のみならず、他のアルバイト生もGoで開発していました。</p><p>私はサーバサイト側のタスクとして Go と Terraform を使いましたが、フロントサイド側のアルバイト生は Vue.js を使い画面コンポーネントを作成していました。</p><p>サーバ、フロントへのアサインは完全に「案件ベース」であり、自分の希望する技術とアサイン先で必要な技術がマッチすれば、タイミング次第ですぐに新しい技術へスイッチできます。私の場合、初めはアプリケーション開発がメインでしたが、インフラにも興味があることを上司に伝えたところ、担当タスクが済んだらすぐに Terraform を利用したタスクへと移動できました。</p><p>アルバイト中の経験から、Future-TIGでは、案件とタイミング次第で未経験の分野への挑戦権を得られると実感しました。経験の少ない段階では「どの分野に適性があるか」は予測できないので、「やりたい技術を意思表明すれば挑戦させてくれる文化」は「手を動かすエンジニアになりたい」私にはピッタリでした。</p><h3 id="評価基準について"><a href="#評価基準について" class="headerlink" title="評価基準について"></a>評価基準について</h3><ul><li>Future-TIG では、技術力が高い人が評価されると思います</li></ul><p>Future には、アルバイトとして参加している大学生から40歳手前で転職された方まで、多様なバックグラウンドを持つ技術者がいます。それを反映して、Futureでは「○○さん」と、さん付けで名前を呼ぶ文化があります。年齢を問わずにチームが結成されるので、年下の上司や年上の部下などいくらでもいました。しかしながら、それを気にする社員はいませんでした。</p><p>評価軸となるのは「どんなアウトプットを出したか」という点に絞られるので、「何歳か」「男性か女性か」「出勤しているか<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>」という技術力とは関係しない部分は、評価項目に上がりません。成果物で評価してもらいたい技術者には最適な環境です。その代償として、未経験の分野ではなく、ある程度知見が貯まった技術を使い続けたいという人には、かなりつらい環境になると思います。</p><p>開発の進め方は「ブラウザで検索し、公式ドキュメントを理解して、実装する」の繰り返しであり、このサイクルをいかに早く回せるかにより、本人の技術力が評価されます。この評価方法は、AI系ベンチャー企業と Future のどちらでも全く同じでした。</p><h3 id="キャリア入社について"><a href="#キャリア入社について" class="headerlink" title="キャリア入社について"></a>キャリア入社について</h3><p>Futureでは、自分の観測範囲で半数近くがキャリア入社された方でした。キャリア入社された方々にお話を伺うと、</p><ul><li>ユーザー企業の情シスでITに触り、もっと開発側に近づきたいと思った</li><li>前の企業ではスキルアップに限界を感じ、レベルの高い技術者のいる会社へ入りたいと思った</li></ul><p>という旨の転職理由を話されていました。</p><p>キャリアで入社される方の場合「より高いレベルの環境を目指した結果、その選択肢の1つとして Future があった」というケースの人が、私の周りには多めでした。技術への関心が高い人が自然に集まるという Future の文化は、最先端の技術を次々と実装する社風ともリンクしています。「できる人、もっとできるようになりたい人」がキャリアとして Future にジョインされるので、基本的に意識高めの人が多いと感じました。</p><h2 id="私が担当したタスク"><a href="#私が担当したタスク" class="headerlink" title="私が担当したタスク"></a>私が担当したタスク</h2><ul><li>Go で GCP の Billing 情報を通知するアプリケーションを2タイプ作成(近日 OSS として公開予定)</li><li>設計思想の異なる２つの Terraform スクリプトを１つに統合</li></ul><h3 id="Go-でのアプリケーション開発-×２"><a href="#Go-でのアプリケーション開発-×２" class="headerlink" title="Go でのアプリケーション開発　×２"></a>Go でのアプリケーション開発　×２</h3><p>Web界隈で大人気の Go を使い、GCP の Billing 情報を通知するアプリケーションを作成しました。アルバイトとしてアサインされた段階では Go 言語の経験は一切ありませんでした。しかしながら、公式ドキュメントと試行錯誤をつづけることにより、実際の案件で利用するアプリケーションの完成まで漕ぎつけました。</p><p>アルバイト生である私の書いたコードでもしっかりとレビューして頂き、そのために時間を割いて頂いた社員の方々には感謝の気持ちでいっぱいです。本当にありがとうございました。</p><p>アルバイト生が開発するコードであっても、全て実案件に関わっている（コードを納品するお客様がいる）ので、先輩方は本気でコードレビューしてくれます。したがって、「実案件で通用するレベルまでコード力を向上させたい」という大学生には、Future でのアルバイトを是非ともお勧めしたいです。</p><h3 id="Terraform-スクリプトの統合"><a href="#Terraform-スクリプトの統合" class="headerlink" title="Terraform スクリプトの統合"></a>Terraform スクリプトの統合</h3><p>2つの Terraform スクリプトを１つに統合するタスクを担当しました。</p><p>現実にある１つのインフラは動いているが、それを構成管理する Terraform スクリプトは２つ存在する<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>という恐ろしい状況から、インフラ実態を一切操作せずにスクリプトのみを統合するというタスクを進めました。</p><p>設計の異なる Terraform スクリプトを統合するには、片方のインフラ定義を、現状と矛盾しない形で、もう一方へと「移植する」必要があります。また、同時に移植が問題なく成功したことを「証明する」必要もあります。この「移植」と「成功の証明」を何とか達成したことが、私のアルバイト期間における最大の実績だと思っています。</p><p>Terraform スクリプトの書き方が異なれば、terraform apply コマンドで生成される tfstateファイルの定義も異なった記述になります。したがって、移植を達成するには</p><ol><li>Terraform スクリプトの記述を、片方に矛盾なく移植する</li><li>tfstateファイルの内容を、移植した Terraform スクリプトに完全に沿う形で書き換える</li></ol><p>という２つの壁を同時に乗り越える必要があり、私はこれを突破しました。</p><p>現在の私ならば、Terraformスクリプトの統合と tfstateファイルの書き換え程度ならそれほど難しいタスクではありません。この具体的な方法については技術的な需要があると認識しているので、別な場面でご紹介したいと考えています。</p><h4 id="「未経験でもインフラを希望したら、最先端の技術を利用し、かつ、とても難しいタスクを経験できた」"><a href="#「未経験でもインフラを希望したら、最先端の技術を利用し、かつ、とても難しいタスクを経験できた」" class="headerlink" title="「未経験でもインフラを希望したら、最先端の技術を利用し、かつ、とても難しいタスクを経験できた」"></a><strong>「未経験でもインフラを希望したら、最先端の技術を利用し、かつ、とても難しいタスクを経験できた」</strong></h4><p>技術力を向上させるには「技術的に困難な壁を突破する」経験が必要です。しかし、その分野に対して未経験な人では、なかなか難しいタスクを任せていただけません。しかし、Future でならば、「最先端技術の難しいところ」をアルバイト生であっても担当させて頂けます。むしろ、社員の方々はそれ以上に難しいタスクを次々に解決しています。</p><p>「手を動かすエンジニアとして活躍したい」と考えるエンジニアであれば、Future で働くことはプラス面が多いと感じました。</p><h2 id="まとめる"><a href="#まとめる" class="headerlink" title="まとめる"></a>まとめる</h2><p>アルバイトを通してFuture では…</p><ol><li>イケイケなWeb系企業が使うような最先端の技術を使っている<ul><li>市場価値を高く保てるので、将来的な転職に有利になる</li><li>最先端の難しいタスクを担当することで、技術力が急上昇する</li></ul></li><li>「技術力が高いこと」が評価される<ul><li>自主的に勉強する習慣や、ブログや講演で一般公開することが歓迎される</li><li>仕事と並行して、エンジニア界隈で知名度を上げられる</li></ul></li><li>技術を向上させたい人が社外からも集まってくる<ul><li>「勉強するのが基本」という人が集まってくるので、互いに教えあう文化がある</li><li>社員のバックグラウンドが多様で面白い</li></ul></li></ol><p>という3点の特徴があるのだなと理解できました。</p><p>現在の私は研修中の身ですが、1日も早く現場に復帰できるよう、誠意努力してまいります。</p><p>Future の先輩社員の皆様方、これからもよろしくお願い致します。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">社員補足: 現時点ではリモートフレンドリーではありますが、リモートファーストでは無いので、慣れるまでは出社を推奨しています。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">社員補足: 別のチーム（他社）が管理していたインフラ構築作業を弊社で巻き取ったために発生したイレギュラーな状態でした。</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;導入&quot;&gt;&lt;a href=&quot;#導入&quot; class=&quot;headerlink&quot; title=&quot;導入&quot;&gt;&lt;/a&gt;導入&lt;/h2&gt;&lt;p&gt;はじめまして。&lt;/p&gt;
&lt;p&gt;2019/7/1にFutureへ新卒入社した棚井龍之介と申します。&lt;/p&gt;
&lt;p&gt;現在は会社の新人研修に誠意取
      
    
    </summary>
    
      <category term="Culture" scheme="https://future-architect.github.io/categories/Culture/"/>
    
    
      <category term="アルバイト報告" scheme="https://future-architect.github.io/tags/%E3%82%A2%E3%83%AB%E3%83%90%E3%82%A4%E3%83%88%E5%A0%B1%E5%91%8A/"/>
    
  </entry>
  
  <entry>
    <title>GCPのIAMポリシー周りでドハマりした話</title>
    <link href="https://future-architect.github.io/articles/20190708/"/>
    <id>https://future-architect.github.io/articles/20190708/</id>
    <published>2019-07-07T23:33:22.000Z</published>
    <updated>2019-07-11T14:46:30.337Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは、Technology Innovation GroupのDXユニット所属の<a href="https://twitter.com/famipapamart" target="_blank" rel="noopener">村田</a>と申します！<br>DXユニットとはデジタルトランスフォーメーションに関わる仕事を主に推進していくチームです。<br>私は現在<a href="https://www.future.co.jp/about_us/#tab-iot" target="_blank" rel="noopener">Future IoT</a>プロジェクトに携わっており、最近はもっぱらクラウドインフラに従事しています。</p><p>メインの仕事は複数のGoogle Cloud Platform(以下、GCP)プロジェクトとそれぞれの環境（Production/Staging/Developmentなど）の構築・運用です。<br>この中で個人的にとても面白いと思った知見を得たので「これはぜひブログにしよう！」といま筆を走らせています。</p><h1 id="クラウドインフラの使命"><a href="#クラウドインフラの使命" class="headerlink" title="クラウドインフラの使命"></a>クラウドインフラの使命</h1><p>クラウドインフラと一言で言っても意味する範囲はとても広いですが、私がこのブログで紹介する内容はどちらかというと地味かもしれません。</p><p>私が今日紹介したいのは、GCPの「IAMポリシー管理の重要性」です。</p><h2 id="Infrastructure-as-a-Code-の徹底"><a href="#Infrastructure-as-a-Code-の徹底" class="headerlink" title="Infrastructure as a Code の徹底"></a>Infrastructure as a Code の徹底</h2><p>Infrastructure as a Code というものの概念については昨今多くの方が自分なりの理解を持ち、それを実務に活かすべく実践するフェーズに至っているかと思いますが、私のプロジェクトも例外ではありません。</p><p>たとえば私の現在のプロジェクトではTerraformを利用してGCPリソースを管理しており、その運用や何をどこまでスクリプト化したり自動化するかについて日々メンバーと頭を悩ませています。<br>(Cloud Deployment Managerを使わないの？という声も聞こえてきそうですが、色々な事情がありメインのツールはTerraformを利用しています)</p><p>さて、話を元に戻しますが、この「リソースをスクリプト管理する」ということには大事な前提があります。<br>それはすなわち「スクリプトと実リソースにズレが無い」ということです。</p><p>個人で扱うGCPプロジェクトならまだしも、複数人（しかも複数ベンダー）が同時に扱うプロジェクトともなればズレを無くし整合性を保つのにも一苦労です。</p><p>もちろん、本番環境やステージング環境であればインフラチームとアプリケーション開発チームとの棲み分けをしっかり行うでしょうから、上記のような状態にはならないでしょう。</p><p>しかし、初期の開発環境や負荷テスト環境などは、アプリチーム側でもサンドボックス的にある程度自由にインフラ操作をしたいという要望もあり、ではこの権限を付与して…とついなってしまいがちです。</p><p>クラウドな時代ですし、リソースに変更を加えたいときはコンソールでポチッとやれてしまいます。<br>これはクラウドのメリットであり大きな強みです。<br>ただその一方で、今回推し進めたい Infrastructure as a Code にとっては連絡なしにいつの間にかリソースが増えているといった邪悪な敵にもなり得ます。</p><p>インフラスクリプトを管理するチームと実際にリソースを利用するチームが別で、互いのコミュニケーション不足からスクリプトと実リソースが乖離、どんどんカオス化していく…という状況は想像に難くないはずです。</p><h2 id="IAMポリシー管理の重要性"><a href="#IAMポリシー管理の重要性" class="headerlink" title="IAMポリシー管理の重要性"></a>IAMポリシー管理の重要性</h2><p>カオスな状況を打開するための施策は様々考えられますが、私が今回選択したポリシーは「IAMポリシー管理を徹底する」という至極普通な当たり前のものでした。<br>基本に忠実であることは非常に大事だなと日々感じています</p><p>同時に、初期の開発環境はIAMポリシーを緩め、だれでもインフラ操作を行える反面、この段階ではTerraform運用を行わないという割り切りをしました。<br>その次の開発フェーズからはアプリチームの申請ベースでTerraform化を行いしっかり管理するようなフローを整えました。</p><p>IAMポリシー管理と運用フローの整備を徹底することで予期せぬ変更がそもそも起こりえない状況を作り出し、元々推し進めたかった Infrastructure as a Code の実現に少しずつ近づけていきました。</p><h1 id="今回ハマったポイント-Cloud-Functionとの闘い"><a href="#今回ハマったポイント-Cloud-Functionとの闘い" class="headerlink" title="今回ハマったポイント Cloud Functionとの闘い"></a>今回ハマったポイント <del>Cloud Functionとの闘い</del></h1><p>と、ここまで長い前置きとなりましたが、やっとメインネタです。<br>IAMポリシーの管理うんぬん、みたいな話をしてきましたが、別に「管理が大変なんじゃ」とか「管理ｗカオスｗｗ」とか言いたいわけではないです。笑</p><p>最初に結論を言ってしまうのですが、「GCPにおけるオーナー権限は最強ではない」という知見を得ました。<br>これがこのエントリーで一番伝えたいことで、IAMポリシー周りの仕事を進める中で得た私の一番の知見です。</p><h2 id="Google管理サービスアカウントとは？"><a href="#Google管理サービスアカウントとは？" class="headerlink" title="Google管理サービスアカウントとは？"></a>Google管理サービスアカウントとは？</h2><p>一瞬話は変わりますが、皆さんGCPのGoogle管理サービスアカウントってご存知ですか？<br><img src="/images/20190708/photo_20190708_01.png"><br>↑↑<br>これですね。</p><p><a href="https://cloud.google.com/iam/docs/service-accounts?&_ga=2.185771177.-1847946762.1548816048#google-managed_service_accounts" target="_blank" rel="noopener">公式ページ</a>によると…</p><blockquote><p>Google 管理サービス アカウント<br>ユーザーが管理するサービス アカウントに加えて、プロジェクトの IAM ポリシーまたは GCP Console にいくつかの追加サービス アカウントが表示されることがあります。これらのサービス アカウントは Google が作成し所有しています。これらのアカウントはさまざまな Google サービスを表し、各アカウントには GCP プロジェクトにアクセスするための IAM の役割が自動的に付与されます。</p></blockquote><p>…とあります。<br>書いてある通りですが、GCP側が利用するサービスに応じて自動的に追加してくれるIAMポリシーです。<br>例えば上写真にある<code>Cloud Functions Service Agent</code>とはその名の通りCloud Functionsを利用する際に自動的に追加されます。</p><p>これらのサービスアカウントは各GCPサービスを動作させるために必要なもので、このIAMポリシーがなければアプリケーション動作時に<code>Permission Denied Error</code>等発生してしまいます。</p><h2 id="IAMポリシーって好き勝手消せるんです"><a href="#IAMポリシーって好き勝手消せるんです" class="headerlink" title="IAMポリシーって好き勝手消せるんです"></a>IAMポリシーって好き勝手消せるんです</h2><p>オーナー権限を持っていればIAMポリシーの追加・編集・削除が自由に行えるのは皆さんご存知の通りかと思いますが、これはGoogle管理サービスアカウントも例外ではありません。<br>そうなんです、 <strong>「サービスの動作に必要な自動作成されるアカウント」も自由に編集・削除できてしまう</strong> のです。</p><h2 id="深い沼でした"><a href="#深い沼でした" class="headerlink" title="深い沼でした"></a>深い沼でした</h2><p>深い沼でした（2回目）<br>というのも、このGoogle管理サービスアカウント、新規にプロジェクトを作成して最初に該当サービスを利用する際に作成されますが、その後は自動的に作成されることはありません。<br>一度編集・削除してしまったら最後、元の状態へ復元するためには手動で復旧するしかないのです。</p><p>今回私が引き継いだとあるGCP環境では、IAMポリシー整理と称し様々な「不要と思われる」ポリシーの削除が実施されていました。<br>みなさんもうお気づきかと思いますが、この「不要と思われる」というのが不要ではなかったというオチです。</p><p>その環境のIAMポリシーからはCloud Functions関連のポリシーが一切消失していました。<br>そうとは知らずにCloud Functionsのデプロイを試みた私は深い沼にハマっていきました…</p><p>それもそのはず。</p><p>自動作成されるGoogle管理サービスアカウントは文字通り自動で作成されているのであって、明示的にその存在を意識して作業を行うことはあまり多くありません。<br>（この一件のおかげでいまではGoogle管理サービスアカウントもしっかり気にかけるようになりました）</p><p>Cloud Functionsの実行はエラーに阻まれ成功せず、そこから切り分けがスタートしました。</p><p>余談ですが、この時発生したエラーはシンプルなタイムアウトエラーでした。<br>真因は権限エラーだったのですが、<code>Permission denied</code>というエラーメッセージが出てくれず、切り分けが難航しました…</p><h2 id="オーナー権限は最強ではない"><a href="#オーナー権限は最強ではない" class="headerlink" title="オーナー権限は最強ではない"></a>オーナー権限は最強ではない</h2><p>調査の中で2種類のGoogle管理サービスアカウントが消失していることに気づきました。<br>ひとつは<code>PROJECT_ID@appspot.gserviceaccount.com</code>です。<br><a href="https://cloud.google.com/functions/docs/concepts/iam?hl=ja" target="_blank" rel="noopener">公式ページ</a>では以下のように説明されています。</p><blockquote><p>ランタイム サービス アカウント<br>実行時に、Cloud Functions ではプロジェクトの編集者の役割を持つサービス アカウント <a href="mailto:PROJECT_ID@appspot.gserviceaccount.com" target="_blank" rel="noopener">PROJECT_ID@appspot.gserviceaccount.com</a> を使用します。このサービス アカウントの役割を変更して、実行中の関数に対する権限を制限または拡張することができます。</p></blockquote><p>もう一つは<code>PROJECT_ID@gcf-admin-robot.iam.gserviceaccount.com</code>です。<br>これについては日本語のドキュメントには記載がなく(2019/07/02現在)、<a href="https://cloud.google.com/functions/docs/concepts/iam" target="_blank" rel="noopener">英語版</a>を参照する必要がありました。<br>以下のような記載があります。</p><blockquote><p>Cloud Functions service account<br>For administrative actions on your project during the creation, updating, or deletion of functions, the Cloud Functions service uses the Google Cloud Functions service agent service account (<a href="mailto:service-PROJECT_NUMBER@gcf-admin-robot.iam.gserviceaccount.com" target="_blank" rel="noopener">service-PROJECT_NUMBER@gcf-admin-robot.iam.gserviceaccount.com</a>).</p></blockquote><blockquote><p>By default, this service account has the cloudfunctions.serviceAgent role on your project. Creating, updating, and deleting functions may fail if you change this account’s permissions.</p></blockquote><p>私は手動で上記2つのGoogle管理サービスアカウントの復旧を試みました。<br><code>PROJECT_ID@appspot.gserviceaccount.com</code>は<code>編集者</code>ロールが付与されていればよいのでコンソール画面からIAMポリシーを追加しました。<br>問題はもう一つの方でした。<br><code>PROJECT_ID@gcf-admin-robot.iam.gserviceaccount.com</code>には<code>Cloud Functions Service Agent</code>のロールが付与されている必要があるのですが、このロールがコンソールから選択できなかったのです。</p><p>gcloudコマンド経由で問題なく該当ロールの付与はできるのですが、当時私は切り分けとして「<code>PROJECT_ID@gcf-admin-robot.iam.gserviceaccount.com</code>に<code>オーナー</code>権限を付与する」ということを行いました。</p><p>オーナー権限は最強だろうと思っていたのです。<br>権限周りでハマっているのであればとりあえずオーナー付与しちゃえば突破できるはず、と。</p><p>違いました。<br>Google管理サービスアカウントに付与されるロール群、サービスエージェント達はオーナー権限では持っていない特殊な権限を持っていたのです。</p><p>gcloud コマンドを使って<code>Cloud Functions Service Agent</code>に付与されている権限を見てみます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcloud iam roles describe roles/cloudfunctions.serviceAgent</span><br></pre></td></tr></table></figure><p>下記が結果です。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">description: Gives Cloud Functions service account access to managed resources.</span><br><span class="line">etag: AA==</span><br><span class="line">includedPermissions:</span><br><span class="line">- clientauthconfig.clients.list</span><br><span class="line">- cloudfunctions.functions.invoke</span><br><span class="line">- firebasedatabase.instances.get</span><br><span class="line">- firebasedatabase.instances.update</span><br><span class="line">- iam.serviceAccounts.getAccessToken</span><br><span class="line">- iam.serviceAccounts.signBlob</span><br><span class="line">- pubsub.subscriptions.consume</span><br><span class="line">- pubsub.subscriptions.create</span><br><span class="line">- pubsub.subscriptions.delete</span><br><span class="line">- pubsub.subscriptions.get</span><br><span class="line">- pubsub.subscriptions.getIamPolicy</span><br><span class="line">- pubsub.subscriptions.list</span><br><span class="line">- pubsub.subscriptions.setIamPolicy</span><br><span class="line">- pubsub.subscriptions.update</span><br><span class="line">- pubsub.topics.attachSubscription</span><br><span class="line">- pubsub.topics.create</span><br><span class="line">- pubsub.topics.get</span><br><span class="line">- resourcemanager.projects.get</span><br><span class="line">- resourcemanager.projects.getIamPolicy</span><br><span class="line">- serviceusage.quotas.get</span><br><span class="line">- serviceusage.services.disable</span><br><span class="line">- serviceusage.services.enable</span><br><span class="line">- storage.buckets.get</span><br><span class="line">- storage.buckets.update</span><br><span class="line">name: roles/cloudfunctions.serviceAgent</span><br><span class="line">stage: ALPHA</span><br><span class="line">title: Cloud Functions Service Agent</span><br></pre></td></tr></table></figure><p>これとオーナー権限を比べてみます。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcloud iam roles describe roles/owner</span><br></pre></td></tr></table></figure><p>こっちはあまりにも結果が多いので割愛します。<br>気になった方は調べてみてください。</p><p>diffを取ってみると、<code>Cloud Functions Service Agent</code>にあってオーナー権限では持っていない役割があることがわかりました。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- iam.serviceAccounts.getAccessToken</span><br><span class="line">- iam.serviceAccounts.signBlob</span><br><span class="line">- storage.buckets.get</span><br><span class="line">- storage.buckets.update</span><br></pre></td></tr></table></figure><p>今回のエラーの原因は<code>iam.serviceAccounts.getAccessToken</code>でした。</p><p>(<code>storage.buckets.get</code>あたりがオーナー権限でやれないのはこの記事を書いてて初めて知りました笑)</p><p>私たちの動かそうとしていたCloud FunctuionsのプログラムはBigQueryへのアクセスを行っていました。<br>詰まっていたのはBigQueryへの<a href="https://cloud.google.com/bigquery/docs/authorization?hl=ja" target="_blank" rel="noopener">APIリクエストの承認</a>だったということが判明しました。</p><blockquote><p>このガイドでは、Google BigQuery API にアクセス トークンを提供する方法を説明します。BigQuery クライアント ライブラリを使用している場合は自動的に実行されるため、このガイドに従う必要はありません。</p></blockquote><p>という記載があるのですが、まさにこの<a href="https://cloud.google.com/bigquery/docs/reference/libraries?hl=ja" target="_blank" rel="noopener">BigQueryクライアントライブラリ</a>を利用したプログラムを実装していました。</p><p>BigQueryクライアントライブラリ内で行われているアクセストークンの取得が、<code>iam.serviceAccounts.getAccessToken</code>の欠如により失敗するというのが真の原因でした。</p><h2 id="大切な学び"><a href="#大切な学び" class="headerlink" title="大切な学び"></a>大切な学び</h2><p>私は今回の一件で2つのとても大切な学びを得ました。</p><ul><li>オーナー権限は最強ではない</li><li>Googleサービスによって自動作成されたIAMポリシーは消さない（これは本当に大事）</li></ul><h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>長文読んで頂きありがとうございました！<br>クラウドインフラについての思いの話から始まり、その中で得た超具体的な知見の話に至るまで、伝えたかったことはしっかり言葉にできました。</p><p>何事も実物を見ずに判断してはいけないとよく言いますが、まさに今回の事例がそれだなーと実感しています。<br>GCPにおいて、オーナー権限が最強ではない、というのは覚えておいて損のない知見かと思いますので、頭の片隅に留めておいてもらえるとこの記事自身もそれを書いた私もとても喜びます。</p><p>この記事が少しでも皆さんの役にたてば幸いです。</p><p>では、これからも<a href="https://future-architect.github.io/">Future Tech Blog</a>をよろしくお願いします！！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちは、Technology Innovation GroupのDXユニット所属の&lt;a href=&quot;https://tw
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="GCP" scheme="https://future-architect.github.io/tags/GCP/"/>
    
  </entry>
  
  <entry>
    <title>マネージャーがうれしいRedmineデータのグラフ表示方法を公開します！！（Metabase編） </title>
    <link href="https://future-architect.github.io/articles/20190703/"/>
    <id>https://future-architect.github.io/articles/20190703/</id>
    <published>2019-07-03T00:00:00.000Z</published>
    <updated>2019-07-02T14:16:53.156Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20190703/photo_20190703_01.jpeg"><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは。近藤です。<br>みなさん、Redmineを使っていますか？<br>私は使っています。Redmineはタスクをチケット管理する上で便利ですよね。</p><p>一方で、Redmineにはデータの可視化機能が標準で搭載されていないという課題があります。<br>例えばこれが、標準のサマリ画面。グラフがないから傾向とか分かりづらいんですよね。<br><img src="/images/20190703/photo_20190703_02.png" style="border:solid 1px #000000"><br>参考：<a href="http://www.redmine.org/projects/redmine/issues/report" target="_blank" rel="noopener">http://www.redmine.org/projects/redmine/issues/report</a></p><p>これを何とかしようと、<a href="https://future-architect.github.io/articles/20160920/">以前の投稿</a>では、Kibana+Timelionを使ってRedmineデータをグラフ表示する方法を紹介しました。</p><p>ただ、Kibanaを利用する場合、一度Elasticsearchにデータを登録しないといけないので、手間なのですよね。。</p><p>そこで、本日はOSSのBIツールである<a href="https://metabase.com/" target="_blank" rel="noopener">Metabase</a>を利用して、Redmineのデータをグラフ表示する方法を紹介します。</p><p>例えば、Metabaseを利用すると、チケットの発生件数とクローズ件数の推移を簡単に表示することができます。<br><img src="/images/20190703/photo_20190703_03.png" style="border:solid 1px #000000"></p><p>構築する環境は下記の通り。Kibana+Timelionで構築した環境よりもシンプルですね。<br><img src="/images/20190703/photo_20190703_04.png" style="border:solid 1px #000000" class="img-middle-size"></p><p>では実際にやってみましょう。</p><p>なお、下記を前提としています。</p><ul><li><strong>Windows</strong>環境で構築</li><li><strong>Redmineのデータベース(MySQL)に直接接続</strong>する</li></ul><h2 id="大まかな流れ"><a href="#大まかな流れ" class="headerlink" title="大まかな流れ"></a>大まかな流れ</h2><p>下記の手順でグラフを表示します。</p><ol><li>Javaのインストール</li><li>Metabaseのインストール</li><li>グラフ表示</li></ol><h2 id="1-Javaのインストール"><a href="#1-Javaのインストール" class="headerlink" title="1.Javaのインストール"></a>1.Javaのインストール</h2><p>まず、MetabaseではJavaを利用するため、事前にインストールします。</p><p>お使いの環境にあったインストーラをご利用ください。<br>なお、私の場合は、下記のインストーラを利用しました。</p><p>◆Java SE DevelopmentダウンロードURL<br><a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a><br>の「jdk-8u211-windows-x64.exe」</p><h2 id="2-Metabaseのインストール"><a href="#2-Metabaseのインストール" class="headerlink" title="2. Metabaseのインストール"></a>2. Metabaseのインストール</h2><p>次に、Metabaseをダウンロードします。</p><p>◆MetabaseダウンロードURL<br><a href="https://metabase.com/start/jar.html" target="_blank" rel="noopener">https://metabase.com/start/jar.html</a><br>→「Download Metabase.jar」をクリックします。すると「metabase.jar」がダウンロードされます。</p><p>そして、「c:\metabase」というフォルダを作成し、ダウンロードしたファイルを配置します。</p><p>最終的には下記のようなフォルダ構成になります。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c:\metabase</span><br><span class="line">└ metabase.jar</span><br></pre></td></tr></table></figure><h2 id="3-グラフ表示"><a href="#3-グラフ表示" class="headerlink" title="3. グラフ表示"></a>3. グラフ表示</h2><p>さあ、グラフ表示するにあたり、まずは、Metabaseを起動します。</p><p>コマンドプロンプトで <code>c:\metabase</code> へ移動し、<code>java -jar metabase.jar</code> を実行します。<br><img src="/images/20190703/photo_20190703_05.png"></p><p>しばらくすると、下記のように<code>Metabase Initialization COMPLETE</code>と表示されます。<br><img src="/images/20190703/photo_20190703_06.png" style="border:solid 1px #000000"></p><p>これでMetabaseが起動しました。<br>ブラウザで <code>http://localhost:3000</code> を開きます。</p><p>すると下記のような画面が表示されます。<br><img src="/images/20190703/photo_20190703_07.png" style="border:solid 1px #000000"></p><p>「開始しましょう」をクリックします。<br>すると下記のような画面が表示されます。<br><img src="/images/20190703/photo_20190703_08.png" style="border:solid 1px #000000"></p><p>姓名、メールアドレス、パスワード、組織名を入力します。<br><img src="/images/20190703/photo_20190703_09.png" style="border:solid 1px #000000"></p><p>そして、「次へ」をクリック。<br>すると、下記のような画面が表示されます。<br><img src="/images/20190703/photo_20190703_10.png" style="border:solid 1px #000000"></p><p>「使用するデータベースのタイプを選択する」から、データベースタイプを選択。<br>私の場合は、「MySQL」を選択しました。<br>すると、下記のように表示されるので、<br><img src="/images/20190703/photo_20190703_11.png" style="border:solid 1px #000000"></p><p>データベースの種類、名前、ホスト、ポート、データベース名、ユーザ名、パスワードを入力。<br>私の場合は、名前を「redmine」にしました。<br><img src="/images/20190703/photo_20190703_12.png" style="border:solid 1px #000000"></p><p>そして、「次へ」をクリックします。<br>すると、下記のような画面が表示されます。<br><img src="/images/20190703/photo_20190703_13.png" style="border:solid 1px #000000"></p><p>「次へ」をクリックしましょう。<br>すると、下記のような画面が表示されます。</p><img src="/images/20190703/photo_20190703_14.png" style="border:solid 1px #000000"><p>右上の「照会する」をクリックします。<br><img src="/images/20190703/photo_20190703_15.png" style="border:solid 1px #000000"></p><p>「ネイティブクエリ」をクリック。<br><img src="/images/20190703/photo_20190703_16.png" style="border:solid 1px #000000"></p><p>「データベースを選択する」から、先ほど入力したデータベースを選択しましょう。<br>（私の場合は、「redmine」）<br><img src="/images/20190703/photo_20190703_17.png" style="border:solid 1px #000000"></p><p>次に、チケットの発生件数とクローズ件数を取得する下記のSQLを水色のエリアに貼り付けます。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">is1.created_on ymd</span><br><span class="line">, <span class="string">'open'</span> kbn</span><br><span class="line">, <span class="keyword">sum</span>(is2.id_count) id_count</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="keyword">date_format</span>(created_on, <span class="string">'%Y-%m-%d'</span>) <span class="keyword">as</span> created_on</span><br><span class="line">, <span class="keyword">count</span>(<span class="keyword">id</span>) id_count</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">issues</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line"><span class="keyword">date_format</span>(created_on, <span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">) is1</span><br><span class="line">, (</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="keyword">date_format</span>(created_on, <span class="string">'%Y-%m-%d'</span>) <span class="keyword">as</span> created_on</span><br><span class="line">, <span class="keyword">count</span>(<span class="keyword">id</span>) id_count</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">issues</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line"><span class="keyword">date_format</span>(created_on, <span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">) is2</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">is2.created_on &lt;= is1.created_on</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">is1.created_on</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">is1.closed_on</span><br><span class="line">, <span class="string">'close'</span></span><br><span class="line">, <span class="keyword">sum</span>(is2.id_count) id_count</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="keyword">date_format</span>(closed_on, <span class="string">'%Y-%m-%d'</span>) <span class="keyword">as</span> closed_on</span><br><span class="line">, <span class="keyword">count</span>(<span class="keyword">id</span>) id_count</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">issues</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line"><span class="keyword">date_format</span>(closed_on, <span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">) is1</span><br><span class="line">, (</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="keyword">date_format</span>(closed_on, <span class="string">'%Y-%m-%d'</span>) <span class="keyword">as</span> closed_on</span><br><span class="line">, <span class="keyword">count</span>(<span class="keyword">id</span>) id_count</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">issues</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line"><span class="keyword">date_format</span>(closed_on, <span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">) is2</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">is2.closed_on &lt;= is1.closed_on</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">is1.closed_on</span><br></pre></td></tr></table></figure><p>貼り付けました。<br><img src="/images/20190703/photo_20190703_18.png" style="border:solid 1px #000000"></p><p>そして、「回答を得る」をクリックすると、<br><img src="/images/20190703/photo_20190703_19.png" style="border:solid 1px #000000"></p><p>結果が表示されます。<br>更に、左下の「テーブル」をクリックして、<br><img src="/images/20190703/photo_20190703_20.png" style="border:solid 1px #000000"></p><p>「線」をクリックすると、<br><img src="/images/20190703/photo_20190703_21.png" style="border:solid 1px #000000"></p><p>出ましたね。<br>チケットの発生件数とクローズ件数の推移が表示されています。</p><p>右上の「エディターを非表示にする」をクリックすると<br><img src="/images/20190703/photo_20190703_22.png" style="border:solid 1px #000000"></p><p>グラフが大きくなりましたね。<br>グラフの線にカーソルを当てると、<br><img src="/images/20190703/photo_20190703_23.png" style="border:solid 1px #000000"></p><p>値が表示されますし、右側の「↓」をクリックすると、<br><img src="/images/20190703/photo_20190703_24.png" style="border:solid 1px #000000"><br>データのダウンロードも可能です。<br>便利ですね。</p><h2 id="最後に"><a href="#最後に" class="headerlink" title="最後に"></a>最後に</h2><p>今回は、チケットの発生件数とクローズ件数の推移をグラフで表示しました。<br>それ以外のグラフを簡単に追加することも可能です。<br>詳しくは下記のMetabaseユーザーガイドをご参照ください。</p><p>◆Metabaseユーザーガイド<br><a href="https://metabase.com/docs/latest/users-guide/start.html" target="_blank" rel="noopener">https://metabase.com/docs/latest/users-guide/start.html</a></p><p>いかがでしたでしょうか？RedmineをMetabaseと組み合わせることで、グラフ表示が可能になり、結果的にプロジェクト状況の把握が容易になります。</p><p>本記事が、皆様のプロジェクトマネジメントに役に立てば幸いです。</p><p>なお、今後私がブログを執筆する際は、EVM表示やメール配信、ダッシュボードの構築に関する方法を記載していく予定。</p><p>これらの記事が、みなさまにとって参考になりそうでしたら「いいね！」をクリックして頂けますと幸いです。執筆の励みになります。😃</p><p>今後ともよろしくお願い致します。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/images/20190703/photo_20190703_01.jpeg&quot;&gt;

&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h2&gt;&lt;p&gt;こんにちは。近藤で
      
    
    </summary>
    
      <category term="Management" scheme="https://future-architect.github.io/categories/Management/"/>
    
    
      <category term="Redmine" scheme="https://future-architect.github.io/tags/Redmine/"/>
    
      <category term="Metabase" scheme="https://future-architect.github.io/tags/Metabase/"/>
    
  </entry>
  
  <entry>
    <title>AWS Datalake Hands-on(2019 May)メモ</title>
    <link href="https://future-architect.github.io/articles/20190702/"/>
    <id>https://future-architect.github.io/articles/20190702/</id>
    <published>2019-07-02T00:00:00.000Z</published>
    <updated>2019-07-01T14:32:20.902Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-Datalake-Hands-on-2019-May-メモ"><a href="#AWS-Datalake-Hands-on-2019-May-メモ" class="headerlink" title="AWS Datalake Hands-on(2019 May)メモ"></a>AWS Datalake Hands-on(2019 May)メモ</h1><p>2019/05/29にAWS Japanで行われたDataLakeについてのHands-onメモです。</p><h2 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h2><ul><li><a href="#0-はじめに">0.はじめに</a></li><li><a href="#1-参加の背景">1.参加の背景</a></li><li><a href="#2-手を動かす、その前に">2.手を動かす、その前に</a></li><li><a href="#3-ハンズオンでやったこと">3.ハンズオンでやったこと</a></li><li><a href="#4-まとめ">4.まとめ</a></li></ul><h2 id="0-はじめに"><a href="#0-はじめに" class="headerlink" title="0. はじめに"></a>0. はじめに</h2><h3 id="自己紹介"><a href="#自己紹介" class="headerlink" title="自己紹介"></a>自己紹介</h3><p>はじめまして、Technology Innovation Groupの柳澤です。こちらのブログへ投稿するのは初めてなので、簡単に自己紹介させていただきます。</p><p>2018年の5月にFutureへ中途採用で入社した社会人6年目になります。前職のメーカー系SIerではフロント業務からオンプレのアプライアンスもいじるなんでも屋さんみたいな立ち回りをしていました。</p><p>Future入社後は業務でクラウドを触ったことがなかった状態で、GCPの運用やオンプレ→AWSのリフト案件の推進など、なかなか刺激的な経験を積んでいたらあっという間に1年経ってしまったという今日この頃です。</p><h3 id="DataLake-Hands-onセミナーについて"><a href="#DataLake-Hands-onセミナーについて" class="headerlink" title="DataLake Hands-onセミナーについて"></a>DataLake Hands-onセミナーについて</h3><p>基本的に<strong>ユーザ</strong>を主な対象としているセミナーで、30分程度の簡単な講義のあとに、ひたすら手を動かすハンズオンという二部形式で構成されています</p><p>あとから知ったのですが、昨年から始まった恒例のワークショップのようです。※開催報告の公式ページは<a href="https://aws.amazon.com/jp/blogs/news/20190529-aws-datalake-handson-seminor/" target="_blank" rel="noopener">こちら</a></p><p>また、参加者層としては、後述のハンズオンの進捗を見るにユーザの方が多かったのかなという印象でした。<br>(ハンズオンの分量が多かったものの、ハンズオン終了時時点で分量の半分まで到達できていた人が6割くらいだった印象です)</p><h2 id="1-参加の背景"><a href="#1-参加の背景" class="headerlink" title="1.参加の背景"></a>1.参加の背景</h2><p>あるプロジェクトでデータ分析基盤を開発することになり、その一環として</p><ol><li>データってどうやって集める？</li><li>集めたデータをどう使う？</li><li>集めたデータをどう使える状態にする？</li></ol><p>を知るために参加しました。</p><p>当日の講義の内容としては、以下のような簡単な座学の後に、ハンズオンに移ります。</p><ul><li>実際にハンズオンで手を動かして作るものの構成とその概要についての</li><li>なぜDatalake(DataLakeってなに？という話題も含めて)なのか</li></ul><h2 id="2-手を動かす、その前に"><a href="#2-手を動かす、その前に" class="headerlink" title="2.手を動かす、その前に"></a>2.手を動かす、その前に</h2><p>もともとユーザ向けのセミナーだったこともあり、技術的に複雑な説明などはありませんでした。</p><p>しかし、データレイクについては、その利点などについてしっかりできていなかった部分があったのでそれらを整理する意味でも有意義なものだったと思います。</p><p>説明のあった内容をざっくり要約すると以下の通りです。</p><h3 id="企業の保有するデータについて"><a href="#企業の保有するデータについて" class="headerlink" title="企業の保有するデータについて"></a>企業の保有するデータについて</h3><ul><li>いま現在も企業の保持するデータは増え続けている</li><li>しかもデータの形式や抽出要件も増える一方</li></ul><h3 id="要件が複雑化するデータに対して-RDSの場合"><a href="#要件が複雑化するデータに対して-RDSの場合" class="headerlink" title="要件が複雑化するデータに対して(RDSの場合)"></a>要件が複雑化するデータに対して(RDSの場合)</h3><ul><li>複雑化する要件に合わせてスキーマなどが増加するため、どんどん<strong>サイロ化が進む</strong></li><li>また、リアルタイム分析や<del>最近流行の</del>機械学習などの領域への対応が難しい</li></ul><h3 id="複雑化するデータへの対策としてのデータレイク"><a href="#複雑化するデータへの対策としてのデータレイク" class="headerlink" title="複雑化するデータへの対策としてのデータレイク"></a>複雑化するデータへの対策としてのデータレイク</h3><ul><li>上記の問題への対応策として、データレイクは非常に有効<ul><li>データレイクとは、構造にかかわらずデータをそのままの姿で保存可能な一元化されたリポジトリのこと</li></ul></li><li>データレイクを使用することの利点(例)としては<ul><li>前述の通り、データを保存する段階でスキーマの分割などが発生しないため、サイロ化が発生せず、データの一元管理が可能になる<ul><li>一元管理が可能になることでSSOT(詳しくは<a href="https://en.wikipedia.org/wiki/Single_source_of_truth" target="_blank" rel="noopener">このあたり</a>をご参照ください)として使用することが可能に</li></ul></li><li>データの保存場所に対してinput/outputが独立するため、それぞれ柔軟に手段を選定することができる</li></ul></li></ul><h2 id="3-ハンズオンでやったこと"><a href="#3-ハンズオンでやったこと" class="headerlink" title="3. ハンズオンでやったこと"></a>3. ハンズオンでやったこと</h2><p>座学に続いて、以下黙々と手を動かす時間が続きました。</p><ol><li>はじめの準備</li><li>アプリケーションログをリアルタイムで可視化する</li><li>2に加えてアラームの設定</li><li>アプリケーションログの永続化と長期間データの分析と可視化</li><li>クラウドDWHを使用したデータ分析</li><li>サーバレスでデータのETL処理</li></ol><p>使ったサービスは全部は以下の通りです。</p><table><thead><tr><th align="left">No</th><th align="left">内容</th><th align="left">使用サービス</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">はじめの準備</td><td align="left">VPC, EC2, CloudFormation, IAM</td></tr><tr><td align="left">2</td><td align="left">リアルタイムのアプリケーションログ可視化</td><td align="left">Elasticsearch Service</td></tr><tr><td align="left">3</td><td align="left">アラームの設定</td><td align="left">CloudWatch Lambda, Elasticsearch Service</td></tr><tr><td align="left">4</td><td align="left">アプリケーションログの永続化・長期間データの分析と可視化</td><td align="left">Kinesis Data Firehose, S3, Athena, QuickSight</td></tr><tr><td align="left">5</td><td align="left">クラウドDWHを使用したデータ分析</td><td align="left">Kinesis Data Firehose, S3, Athena, Redshift Spectrum, Quicksight</td></tr><tr><td align="left">6</td><td align="left">サーバレスでデータのETL処理</td><td align="left">Glue, Athena</td></tr></tbody></table><p>上記のサービスを使って最終的には</p><ul><li>バッチレイヤ(バッチ処理、あとからまとめて分析)</li><li>スピードレイヤ(リアルタイム処理、監視のアラートなど)</li></ul><p>の両面から監視・分析を実行できる環境を構築していきます。</p><p>イメージ図はこちら<br><img src="/images/20190702/photo_20190702_01.png"></p><h3 id="3-1-はじめの準備"><a href="#3-1-はじめの準備" class="headerlink" title="3-1. はじめの準備"></a>3-1. はじめの準備</h3><img src="/images/20190702/photo_20190702_02.png"><p>後続のログ分析に使うためのログを生成し続けるEC2インスタンスを作成します。</p><p>このEC2インスタンスおよび周辺の設定(VPCやSecurityGroupなど)はすでにCloudFormationのテンプレートが用意されており、実作業としてはテンプレートをS3に置いて、スタックの作成を実行するだけ、という感じでした。</p><p>ここまでは特筆すべきこともないのでさっくりいきます。</p><h3 id="3-2-リアルタイムのアプリケーションログ可視化"><a href="#3-2-リアルタイムのアプリケーションログ可視化" class="headerlink" title="3-2. リアルタイムのアプリケーションログ可視化"></a>3-2. リアルタイムのアプリケーションログ可視化</h3><img src="/images/20190702/photo_20190702_03.png"><p>続いて、スピードレイヤの構築を開始します。</p><p>前手順で作成したインスタンスで出力したログを</p><ul><li>fluentdでElasticsearch Service(以下、ESとします)へストリーミング</li><li>ESに付属しているKibana(←Kibanaのセットアップしなくていいのは楽！！)でグラフィカルにデータを確認</li></ul><p>することをしました。</p><p>できた画面は↑の画像内のスクリーンショットのような感じです。</p><h3 id="3-3-アラームの設定"><a href="#3-3-アラームの設定" class="headerlink" title="3-3. アラームの設定"></a>3-3. アラームの設定</h3><img src="/images/20190702/photo_20190702_04.png"><p>fluentd→ESの間に、CloudWatchLogs(Alarm)とLambdaを差し込むことで、リアルタイムのログ監視とアラームを設定します。</p><p>ここまでがスピードレイヤの構築です。</p><h3 id="3-4-アプリケーションログの永続化・長期間データの分析と可視化"><a href="#3-4-アプリケーションログの永続化・長期間データの分析と可視化" class="headerlink" title="3-4. アプリケーションログの永続化・長期間データの分析と可視化"></a>3-4. アプリケーションログの永続化・長期間データの分析と可視化</h3><img src="/images/20190702/photo_20190702_05.png"><p>ここからバッチレイヤの構築に入ります。</p><p>fluentdからKinesis Data Firehoseにもストリーミングを行い、保存先としてS3を指定します。</p><p>S3への保存によって長期間のデータ保管を可能にしたうえで、アドホックな分析を行うと同時にBIツールで可視化しました。</p><h3 id="3-5-アプリケーションログの永続化・長期間データの分析と可視化"><a href="#3-5-アプリケーションログの永続化・長期間データの分析と可視化" class="headerlink" title="3-5. アプリケーションログの永続化・長期間データの分析と可視化"></a>3-5. アプリケーションログの永続化・長期間データの分析と可視化</h3><img src="/images/20190702/photo_20190702_06.png"><p>3-4とは異なり、ストリーミングされたログをS3で永続化したうえで、DWHに読み込み分析し、BIツールで可視化しました。</p><h3 id="3-6-サーバレスでデータのETL処理"><a href="#3-6-サーバレスでデータのETL処理" class="headerlink" title="3-6. サーバレスでデータのETL処理"></a>3-6. サーバレスでデータのETL処理</h3><img src="/images/20190702/photo_20190702_07.png"><p>Glueを使い、サーバーレスでデータの加工処理をしました。</p><h2 id="4-まとめ"><a href="#4-まとめ" class="headerlink" title="4.まとめ"></a>4.まとめ</h2><h3 id="4-1-勉強になったこと-もう少し知りたかったこと"><a href="#4-1-勉強になったこと-もう少し知りたかったこと" class="headerlink" title="4-1.勉強になったこと/もう少し知りたかったこと"></a>4-1.勉強になったこと/もう少し知りたかったこと</h3><h4 id="勉強になったこと"><a href="#勉強になったこと" class="headerlink" title="勉強になったこと"></a>勉強になったこと</h4><p>以前かかわったPJでElasticsearchの運用していたこともあり(構築にはさほどかかわっていませんでしたが)、諸々の設定をスキップしてGUIポチポチである程度の構成が出来上がってしまうマネージドサービスの生産性の高さを改めて認識できました。</p><h4 id="もう少し知りたかったこと"><a href="#もう少し知りたかったこと" class="headerlink" title="もう少し知りたかったこと"></a>もう少し知りたかったこと</h4><p>もう少し知りたかった、というよりはもう少し時間が欲しかったという表現が正しいかもしれませんが、セミナーのテキストが400ページ近い超大作だったのに対し、実際に手を動かせる時間が3時間もなかったので、すべてを腹落ちさせて帰るのはちょっと厳しかったかなという印象でした。(そもそもシナリオを選択してかいつまんで構築していく想定だとは思いますが)</p><h3 id="4-2-所感"><a href="#4-2-所感" class="headerlink" title="4-2.所感"></a>4-2.所感</h3><p>私自身、現在AWSを触っていることもあり、セミナーで使用するCloudFormationの扱いやGUI操作については特に詰まるところはありませんでした。</p><p>この点についてはある程度マネジメントコンソールを触ったことのある人であれば特に困ることはないのではないかと思います。</p><p>逆にいえば、従来までログ分析基盤などをがんばって作っていた時間を「集めたログをどうやって使っていくか」などビジネス的視点に立ったタスクにシフトさせていく必要性を強く感じる結果になりました。</p><p>そういった意味では、少し技術的な部分に触れてみたいユーザ企業の方や、さくっとログ分析基盤作ってみたい！というクラウド初心者の方には短時間で方法論を学べるいい機会になるのではないかと思いました。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;AWS-Datalake-Hands-on-2019-May-メモ&quot;&gt;&lt;a href=&quot;#AWS-Datalake-Hands-on-2019-May-メモ&quot; class=&quot;headerlink&quot; title=&quot;AWS Datalake Hands-on(2019
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="AWS" scheme="https://future-architect.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>人工知能学会（JSAI2019） 参加報告</title>
    <link href="https://future-architect.github.io/articles/20190627/"/>
    <id>https://future-architect.github.io/articles/20190627/</id>
    <published>2019-06-26T23:13:03.000Z</published>
    <updated>2019-06-27T01:08:22.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>みなさんこんにちは！SAIG(Strategic AI Group)の水本と明官です！<br>2019年6月4日(火)〜6月7日(金)に開催された<a href="https://www.ai-gakkai.or.jp/jsai2019/" target="_blank" rel="noopener">人工知能学会全国大会（JSAI2019)</a>にSAIGで参加してきましたので報告します。<br>フューチャーは2017年からJSAIのプラチナスポンサーとなっており、今年もスポンサーブースの出展、インダストリアルセッションでの発表を行ないました。また、スポンサーブース出展の合間を縫ってセッション聴講も行なってきました。<br><img src="/images/20190627/1.jpg" width="60%"></p><p>今年のJSAIは新潟県の朱鷺メッセで開催されました。東京からだと新潟駅まで2時間程度、新潟駅から朱鷺メッセまで20分ほどの比較的参加しやすい立地でした。ありきたりですが、おいしい日本酒とお米が印象的でした（下の写真は参加者交流会で出た日本酒の<strong>ほんの</strong>一部）。<br><img src="/images/20190627/2.jpg" width="60%"></p><h1 id="人工知能学会全国大会とは"><a href="#人工知能学会全国大会とは" class="headerlink" title="人工知能学会全国大会とは"></a>人工知能学会全国大会とは</h1><p>今年で33回目の開催で人工知能 (AI)の研究発表を行う学会で、機械学習から人工知能の応用の話まで幅広く発表があります。一般口頭発表、インタラクティブセッション（ポスター発表）、テーマに沿った発表を行うオーガナイズドセッションや企画セッション、企業の方が事例紹介などを行うインダストリアルセッションなどがあります。一方で発表会場も15会場程度あり、どの発表を聞きに行くか決めるのも大変なセッション数になっています。SAIGの貞光/水本はこの全国大会の運営委員もやっており、学会中にそちらの仕事も行っておりました。</p><p>人工知能学会全国大会はここ数年でさらに規模が拡大してきており、2017年には2,561人であった来場者数は、2018年には2,611人、今回の2019年には2,897人と順調に増加しており発表申し込み件数も750件程あったそうです。スポンサー数も、2017年から55社、68社、90社と増加しました。また、学会としては、量から質への転換を目指しており、査読付きの国際セッションを開催するなど、新しい取り組みに積極的な様子でした。</p><h1 id="ブースの紹介"><a href="#ブースの紹介" class="headerlink" title="ブースの紹介"></a>ブースの紹介</h1><p>企業ブースでは、FutureでのAI案件実績を展示し、学生さんや企業の方との議論が大変盛り上がりました！<br>ノベルティとして配布したFutureオリジナルの歯ブラシも大好評でした。<br><img src="/images/20190627/3.jpg" width="60%"></p><h1 id="セッション聴講"><a href="#セッション聴講" class="headerlink" title="セッション聴講"></a>セッション聴講</h1><p>スポンサーブース出展の合間を縫って聴講した口頭発表、インタラクティブセッション（ポスター発表）から独断と偏見でおもしろいと思ったものを紹介します。</p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/3Rin2-40/public/pdf?type=in" target="_blank" rel="noopener">[3Rin2-40] 潜在的な旅行者への宿泊施設の提案­­（丸山ら）</a><br>この研究では、宿泊施設の提案のためにユーザの路線検索の履歴を使います。具体的には路線検索で100km以上の移動がある検索を行なったユーザに対してホテルも情報をメールすると言った本当に単純な方法です。検証では、移動距離が長く、かつ路線検索の指定日時が遠いほどメールによってホテルの予約をするユーザが多くなるといった結果が得られていました。一見当たり前のようですが、様々なサービスを一社で扱っている強みとも言え大変興味深かったです。また、応用的にはホテルだけでなくレストランの提案などとも相互に情報を使うこともできそうなため今後に期待したい発表でした。</p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/2H4-E-2-03/public/pdf?type=in" target="_blank" rel="noopener">[2H4-E-2-03] 潜在的な談話構造を捉えたレビュー文書の教師なしヘッドライン生成（磯沼ら）</a><br>今年のJSAIから始まった国際セッションで発表されたものです。教師ありのヘッドライン生成が主流ですが、教師ありでやるにはデータ量も必要でかつドメインも揃えないと難しいといった問題があります。その問題を解決する手段としてこの論文ではヘッドライン生成を教師なしで行う手法を提案しています。談話構造を考えた時に、子の文は親の文に関する追加情報が書かれている、ルートというのは良いサマリーになっているという仮定をおいた手法になっています。つまり、子の文を使って親の文を生成するように学習することで要約になる文を生成しようというアイデアになります。実験の結果、全体の性能では教師あり手法に及ばない結果になっていますが、レビューに含まれる文が多い場合は教師あり手法と同じ程度もしくは上回る性能となっており大変興味深い結果となっています。実際の出力例を見ると、教師あり学習では名詞句のようになっているのですが、教師なしの方ではちゃんとした文になっているのが特徴的です(ヘッドラインとして文になっている必要があるかはわかりませんが)。モチベーションにあるように、ドメインの違うデータで学習した場合の教師ありの結果と比較したらどうなのかというのも気になるところです。この研究は自然言語処理のトップ国際会議でもあるACLに採択されているようなので、そちらも要チェックです。</p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/2L5-J-9-02/public/pdf?type=in" target="_blank" rel="noopener">[2L5-J-9-02] 物語世界間のつながりが一部明示されたメタファー写像セットの構築（松吉ら）</a><br>物語文章の自動生成にシミュレーションとメタファー写像を使うといったおもしろい研究です。自動生成のフレームワーク自体は著者らの先行研究<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>で提案されたもので、この研究はその自動生成のフレームワークを使ってデータ（メタファー写像セット）を拡張した話になります。ここでシミュレーションは迷路探索であったり、チェスであったりをシミュレートするものです。その状態遷移に基づきメタファー写像にある対応する事象を使って文を生成します。例えば、「チェスで相手のコマを取る」様子を「部屋の物を片付ける」イベントに写像するといった具合です。部屋の片付けだけでなく、チェスや迷路探索を様々なイベントに対応することでいろいろな物語を自動生成可能になります。また、チェスや迷路探索などを組みわせることもでき、フレームワーク自体は簡単ですが、より複雑な物語も生成できます。この研究では、物語を生成する核となるメタファー写像セットの構築をし、チェスと迷路探索によるメタファー写像をそれぞれ100個ずつ作成しました。また、物語世界の呼び出しを行うようなものも実際に作成しました。</p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/2L5-J-9-03/public/pdf?type=in" target="_blank" rel="noopener">[2L5-J-9-03] 機械翻訳における訳語一貫性評価用データセットの構築（阿部ら）</a><br>NMTの登場によって流暢な翻訳を生成可能になってきましたが、これまでの機械翻訳の研究では一文単位での翻訳を対象にしていました。そのため文章単位での翻訳を考えた場合に、文脈に応じた訳語選択、代名詞補完、訳語の一貫性といった観点から見ると機械翻訳には課題が残っています。最近になり文脈を使った機械翻訳の研究は行なわれるようになってきましたが、訳語の一貫性といった観点で取り組んでいる研究はありませんでした。そのため一貫性を評価するためのデータセットや適切な評価指標が存在していません。この研究では、機械翻訳による訳語一貫性を評価するための日英/英日翻訳データセット作成に取り組みました。また、実際に実験も行なっており、制約付きデコーディングを使うことで訳語の一貫性の正解率が高くなることを示しました。</p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/3N4-J-10-03/public/pdf?type=in" target="_blank" rel="noopener">[3N4-J-10-03] 深層学習を用いた不動産間取り図のグラフ化と物件検索への応用（山田ら）</a><br>不動産の間取り図で類似したものを検索するために、グラフ構造を利用した研究です。先行研究では部屋の物理的近さを用いてグラフを構築していたため、実際に行き来できない部屋同士にもエッジが張られるという問題がありました。そこでこの研究ではドアの位置の情報を使うことで先行研究の問題を解決しました。具体的には、まずドアの位置をルールベースで同定し、ドアで繋がっている部屋（ノード）間にエッジを張るところを限定しグラフを生成します。この手法を使って実際の物件検索に応用した例の成功したものは人が見ても似ていると思えるものでありおもしろいと思いました。</p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/2Q3-J-2-04/public/pdf?type=in" target="_blank" rel="noopener">[2Q3-J-2-04] 特徴パターンを用いた機械学習の説明手法（浅野ら）</a><br>LIMEは個々の特徴の重要性を測ることはできますが重要な特徴の組み合わせを特定することはできないため、予測に影響を与えた特徴の組み合わせに着目したMP-LIME（Minimal-Patterns-LIME）を提案しています。極小パターンの探索方法としては、特徴の組み合わせ特徴（A,B,C）に対して（A,B),(B,C),(A,C)と特徴数を減らしたパターンを作り、それぞれの特徴パターンを使った分類結果と元の分類結果が変わるまで探索します。特徴数を減らしていき、異なる分類結果になった一つ前の特徴パターンを極小パターンとし、この極小パターンをMP-LIMEにおける判断根拠とします。結果は、recallは若干下がりましたが、Precisionがかなり向上し、実際に予測に用いられた特徴の割合も多くなるという結果でした。LIMEにより判断根拠として出力された画像を再度CNNにかけると、もとの分類結果にならないという問題がありましたが、MP-LIMEだとそれも解消されていました。判断根拠特定手法はかなり多くの方々から注目されており、我々もチャレンジしている分野だったため非常に興味深い発表でした。　<br><img src="/images/20190627/4.jpg" style="border:solid 1px #000000" class="img-middle-size"></p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/1P2-J-13-05/public/pdf?type=in" target="_blank" rel="noopener">[1P2-J-13-05] 新聞記事からの因果関係を考慮したアナリストレポートの自動要約文生成（高嶺ら）</a><br>新聞記事からのテキストマイニングによる因果関係を考慮したアナリストレポートの要約文生成手法の研究です。アナリストレポートとは、証券分析の専門家が企業の経営状態や収益力などを分析・調査し、まとめたレポートのことです。アナリストレポートには、アナリストの予想を示す文とその根拠を示す文があり、これら二種類の文と類似する文を新聞記事中からマイニングします。類似度の算出方法として、LDAとSkip-gramにより得られた2種類の分散表現の類似度と金融極性辞書を用いた極性の一致度をそれぞれコサイン類似度を用いて算出しています。評価方法として、文章内で因果関係を抽出できたレポートの件数に対するアナリストの予想の根拠情報の抽出ができたレポートの件数の割合を用いており、この割合が80%を超えていることから提案手法が有用であることを示しました。<br><img src="/images/20190627/5.jpg" style="border:solid 1px #000000" class="img-middle-size"></p><p><a href="https://confit.atlas.jp/guide/event-img/jsai2019/1H4-J-13-03/public/pdf?type=in" target="_blank" rel="noopener">[1H4-J-13-03] 長期短期記憶と心拍変動に基づく睡眠時無呼吸症候群のスクリーニング（岩崎ら）</a><br>睡眠時無呼吸症候群(SAS)は、睡眠中に呼吸の停止あるいは呼吸量の減少が頻繁に起こる疾患であり、日中の眠気などの症状を引き起こすほか、心血管系の合併症のリスクを高めます。一方で自覚症状に乏しいケースも存在するため治療に至っていない患者が多いと考えらえています。SASの診断には終夜睡眠ポリグラフ検査 (PSG) が用いられますが、PSGを実施できる施設が少ないことや高額であることが問題でした。そこで本研究では、心拍変動解析とLSTMを組み合わせたスクリーニング手法を提案しており、SAS患者および健常者のデータに対して提案法を適用したところ、感度100%、特異度100%（感度：SASの人のなかで、陽性と判断された割合、特異度：SASではない人のなかで、陰性と判断された割合）でSASのスクリーニングが可能であることが明らかとなりました。適用された手法としては新規性はありませんが、このような医学領域での活用は新鮮でわかりやすく面白い発表でした。</p><p><a href="https://confit。atlas。jp/guide/event-img/jsai2019/1L3-J-11-01/public/pdf?type=in" target="_blank" rel="noopener">[1L3-J-11-01] HVGH: 高次元時系列データの深層圧縮と教師なし分節化（長野ら）</a><br>この研究では教師なしで高次元の時系列データから特徴抽出すると同時に、分節・分類が可能なHierarchical Dirichlet Processes-Variational Autoencoder-Gaussian Process-Hidden Semi-Markov Model (HVGH)を提案しています。HVGHは、HDP-GP-HSMMにVariational Autoencoder（VAE）を導入したモデルであり、VAEにより高次元データを低次元の潜在変数へと圧縮し、その潜在変数の遷移をガウス過程を用いて表現することで、高次元の複雑な時系列データの分節化を可能としています。実験ではCMU Graphics Lab Motion Capture Databaseのモーションキャプチャデータ（チキンダンスと体操動作 1）を入力として分節化を行った結果、複雑な動作も高い精度で分節化が可能であることを示しました。<br><img src="/images/20190627/6.jpg" style="border:solid 1px #000000" class="img-middle-size"></p><h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>いかがでしたでしょか？👦<br>二人ともFutureに入って初めての学会でしたが、様々な研究成果を見ることができ良い刺激を受けました。<br>SAIGでは、週に一回、Future Study Group という勉強会を開催しているので、JSAI2019の研究発表も共有しようと思います！</p><p>現在SAIGでは意欲あるメンバーを募集しています。<br>下記URLから応募できますので、興味のある方は是非！<br><a href="https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=365" target="_blank" rel="noopener">https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=365</a><br><a href="https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=363" target="_blank" rel="noopener">https://progres12.jposting.net/pgfuture/u/job.phtml?job_code=363</a></p><img src="/images/20190627/7.jpg" width="60%"><p>▲会場（朱鷺メッセ）から見える景色</p><p>以上、水本・明官でした！</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">松吉 俊, 内海 彰：メタファー写像に基づく物語文の自動生成, 言語処理学会第 24 回年次大会発表論文集, pp. 1288–1291 (2018)</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;みなさんこんにちは！SAIG(Strategic AI Group)の水本と明官です！&lt;br&gt;2019年6月4日(火)〜6月
      
    
    </summary>
    
      <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
      <category term="MachineLearning" scheme="https://future-architect.github.io/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>Amazon Redshiftの仕様を調べてみた</title>
    <link href="https://future-architect.github.io/articles/20190625/"/>
    <id>https://future-architect.github.io/articles/20190625/</id>
    <published>2019-06-25T00:00:00.000Z</published>
    <updated>2019-06-24T13:28:23.204Z</updated>
    
    <content type="html"><![CDATA[<p>クラウド環境におけるDWHの選択肢として、Redshiftはもはや珍しいものではなくなりましたが、弊社内の採用実績はそれほど多くはありませんでした。<br>本記事は元々そのような社内向けに、Redshiftの基本的な仕様をなるべく網羅的に理解できるようまとめたものです。</p><h1 id="筆者について"><a href="#筆者について" class="headerlink" title="筆者について"></a>筆者について</h1><p>新卒でフューチャーに入社し、今年で8年目になります。<br>入社後は一貫して技術畑、オンプレミスのインフラに始まり、直近ではアプリケーションまで含めたプロジェクトの技術統括を担当しています。</p><p>私もかつては社内有数のAWSエンジニアを自負していましたが、最近は別の仕事のため少し遠ざかっており、クラウドの世界は日進月歩なこともあり知識をアップデートする必要を感じています。<br>※この記事の準備中にもElastic Resizeがリリースされました。</p><p>本記事は私のリハビリも兼ね、ドキュメントのまとめだけでなく、実際に手を動かして振る舞いを確認した箇所も含んでいます。</p><h1 id="Amazon-Redshift"><a href="#Amazon-Redshift" class="headerlink" title="Amazon Redshift"></a>Amazon Redshift</h1><p>RedshiftはカラムナーストレージとMPP(Massively Parallel Processing)に基づくDWH向けデータベースサービスです。<br>次の順番でそれぞれまとめていきます。</p><ol><li>ノード構成</li><li>ネットワーク</li><li>メンテナンス</li><li>パラメータグループ</li><li>ワークロード管理</li><li>ユーザーとグループ</li><li>監査ログ</li><li>テーブル設計</li><li>データのロードとアンロード・バキューム</li><li>ラッシュパフォーマンス</li><li>Redshift Spectrum</li><li>参考資料</li></ol><h2 id="1-ノード構成"><a href="#1-ノード構成" class="headerlink" title="1. ノード構成"></a>1. ノード構成</h2><h3 id="1-1-概要"><a href="#1-1-概要" class="headerlink" title="1-1. 概要"></a>1-1. 概要</h3><p>Amazon Redshiftクラスターは1つの<strong>リーダーノード</strong>と、複数の<strong>コンピューティングノード</strong>から構成されます。<br>それぞれの役割の概要を次にまとめます。</p><ul><li>リーダーノード<ul><li>クライアントアプリケーションからクエリを受け取ってクエリを解析し、クエリ実行プランを作成する</li><li>コンピューティングノードに対するこれらのプランの並列実行を調整し、コンピューティングノードから得た中間結果を集計してから、最終的にクライアントアプリケーションに結果を返す</li></ul></li><li>コンピューティングノード<ul><li>クエリ実行プランを実行し、これらのクエリを処理するためにデータをコンピューティングノード間で伝送する(再分散)</li><li>集計の中間結果は、クライアントアプリケーションに送り返される前にリーダーノードに送り返される</li></ul></li></ul><h3 id="1-2-選べるノードタイプ"><a href="#1-2-選べるノードタイプ" class="headerlink" title="1-2. 選べるノードタイプ"></a>1-2. 選べるノードタイプ</h3><p><a href="https://aws.amazon.com/jp/redshift/pricing/" target="_blank" rel="noopener">ノードタイプと料金</a>はこちら。</p><ul><li>リーダーノードは無料<ul><li>コンピューティングノードを一つにした場合、リーダーノード=コンピューティングノードのシングルノード構成となる</li><li>通常運用する場合は、コンピューティングノードを複数にするが、この場合リーダーノードが別に1ノード作成される。課金対象となるのはコンピューティングノードのみである</li></ul></li><li><a href="http://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/purchase-reserved-node-instance.html" target="_blank" rel="noopener">リザーブドインスタンス</a>が購入できる</li></ul><h3 id="1-3-リージョンとアベイラビリティ"><a href="#1-3-リージョンとアベイラビリティ" class="headerlink" title="1-3. リージョンとアベイラビリティ"></a>1-3. リージョンとアベイラビリティ</h3><p>すべてのクラスターノードが同じAZにプロビジョニングされ、<strong>Multi-AZ構成は選択不可能</strong> です。</p><blockquote><p>Amazon Redshift ではデータウェアハウスクラスター内の障害ノードが自動的に検知され、障害ノードの交換が行われます。データウェアハウスクラスターは代替ノードがプロビジョニングされてデータベースに追加されるまで、クエリと更新を行うことはできません。Amazon Redshift では代替ノードが即座に利用可能となり、まず最も高い頻度でアクセスされるデータが S3 からロードされます。こうすることで、可能な限り速やかにクエリの実行が再開できるようになります。単一ノードのクラスターは、データのレプリケーションをサポートしません。ドライブに障害が発生した場合、S3 のスナップショットからクラスターを復元する必要があります。実稼働には少なくとも 2 つのノードを使用することをお勧めします。<br><a href="https://aws.amazon.com/jp/redshift/faqs/" target="_blank" rel="noopener">https://aws.amazon.com/jp/redshift/faqs/</a></p></blockquote><p>実際にどれくらいの時間で復旧するのかは未調査です。</p><h2 id="2-ネットワーク"><a href="#2-ネットワーク" class="headerlink" title="2. ネットワーク"></a>2. ネットワーク</h2><h3 id="2-1-クラスターサブネットグループ"><a href="#2-1-クラスターサブネットグループ" class="headerlink" title="2-1. クラスターサブネットグループ"></a>2-1. クラスターサブネットグループ</h3><p>RDSのデータベースサブネットグループと同じようなもので、別途作成する必要があります。</p><h3 id="2-2-拡張されたVPCのルーティング-Enhanced-VPC-Routing"><a href="#2-2-拡張されたVPCのルーティング-Enhanced-VPC-Routing" class="headerlink" title="2-2. 拡張されたVPCのルーティング(Enhanced VPC Routing)"></a>2-2. 拡張されたVPCのルーティング(Enhanced VPC Routing)</h3><p>拡張されたVPCのルーティングを有効にすると、Amazon Redshiftはクラスターとデータリポジトリ間のすべてのCOPYとUNLOADトラフィックがAmazon VPCを通るよう強制します。</p><ul><li>S3との通信はVPC Endpointを作ればOK。ただしRedshift SpectrumはGlueカタログを利用するため、インターネット経由でGlueにアクセスできる必要があり、NATゲートウェイ等の利用が必要となる。※PoCでは確認できていない</li><li>DynamoDBは未検証だが、おそらくVPC Endpoint経由であれば問題ないはずである</li><li>EMRクラスターは未検証だが、VPC内で通信できれば支障はないはずである</li></ul><p>拡張されたVPCルーティングが有効でない場合、Amazon RedshiftはAWSネットワークにおけるその他のサービスへのトラフィックを含むトラフィックをインターネット経由でルーティングします。</p><h2 id="3-メンテナンス"><a href="#3-メンテナンス" class="headerlink" title="3. メンテナンス"></a>3. メンテナンス</h2><h3 id="3-1-リサイズ"><a href="#3-1-リサイズ" class="headerlink" title="3-1. リサイズ"></a>3-1. リサイズ</h3><p>リサイズは以下1~4のプロセスで実行され、気軽に実行できるものではないです。</p><ol><li>新しいクラスターを作成する</li><li>ソースクラスターを読み取り専用モードで再起動する。既存のコネクションは全て切断され、実行中のトランザクションはロールバックされる</li><li>ソースクラスターから新しいクラスターへデータをコピーする</li><li>エンドポイントを新しいクラスターへ変更する</li></ol><p>クラスターの<strong>サイズ変更にかかる時間</strong>は、各ノードのデータ量に依存します。</p><ul><li>通常、サイズ変更処理には数時間から1日かかる</li><li>データ量が多いクラスターではさらに時間がかかることもある</li></ul><p>Amazon Redshiftは<strong>サイズ変更の操作中、テーブルをソートしません</strong>。</p><ul><li>クラスターのサイズを変更すると、Amazon Redshiftは分散方式に基づいてデータベースのテーブルを新しいコンピューティングノードに分散し、ANALYZEを実行して統計を更新する</li><li>削除のマークが付いた行は転送されないため、テーブルを再ソートする必要がある場合のみVACUUMを実行する必要がある</li></ul><p>リサイズ後の<strong>IPアドレス</strong>について以下の特徴があります。</p><ul><li>クラスターがパブリックであり、VPC 内に存在する場合、サイズ変更後もリーダーノードの elastic IP アドレス（EIP）は変更されない</li><li>クラスターがプライベートであり、VPC 内に存在する場合、サイズ変更後もリーダーノードのプライベート IP アドレスは変更されない</li><li>クラスターがVPC内に存在しない場合、サイズ変更オペレーションの一部として、新しいパブリック IP アドレスがリーダーノードに割り当てられる</li></ul><h3 id="3-2-Elastic-Resize"><a href="#3-2-Elastic-Resize" class="headerlink" title="3-2. Elastic Resize"></a>3-2. Elastic Resize</h3><p><a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/rs-resize-tutorial.html" target="_blank" rel="noopener">伸縮自在なサイズ変更</a>がサポートされました。</p><p>既存のクラスターにあるノードを追加または削除し、自動的にデータを新しいノードに再分散する。以下1~4のイベントが記録されます。</p><ol><li>リサイズリクエスト受付</li><li>リサイズ開始</li><li>リサイズ完了</li><li>再分散完了</li></ol><p>Elastic Resizeは新しいクラスターを作成しないため、伸縮自在なサイズ変更オペレーションは通常のリサイズに比べて素早く完了します。実測したところ、確かに速かった(～5分以内)です。</p><p>ちなみに、「<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/rs-resize-tutorial.html#elastic-resize" target="_blank" rel="noopener">バックグラウンドでデータが再分配されているとき、一部のクエリの実行時間がわずかに増加するのに気付くかも知れません。</a>」とありますが、差を確認することはできなかったです。</p><p>その他、留意したほうが良さそうな点をまとめました。</p><ul><li>一時的に使用不可な時間が発生するが、セッションは切断されず、クエリはキューに溜まる<ul><li>2ノードから4ノードへの変更時に40秒程度クエリが発行できない時間が発生した</li><li>その後、クエリの実行時間が大きく増大する時間が60秒程度発生した<ul><li>2ノードで600msec程度のクエリに4sec～13sec</li></ul></li></ul></li><li>ノード数を2倍にするか、半分にするかのどちらかしか選べない。また、一度ノード数を増やしてしまうとスライス数が増えるため、2倍にしてから半分にする(元に戻す)とスライス数が過剰になってしまう</li></ul><h3 id="3-3-スナップショット"><a href="#3-3-スナップショット" class="headerlink" title="3-3. スナップショット"></a>3-3. スナップショット</h3><p>スナップショットは<strong>自動</strong>または<strong>手動</strong>を選択できます。</p><ul><li>自動スナップショット<ul><li>自動スナップショットは、クラスターを作成するときデフォルトで有効になる</li><li>通常は、8時間ごとまたはノードあたり5GBのデータ変更ごと (あるいはそのいずれか早い方) に作成される</li></ul></li><li>手動スナップショット<ul><li>手動スナップショットはいつでも取得できる</li><li>デフォルトでは、手動スナップショットは、クラスターを削除した後も、無限に保持される。手動スナップショットを作成するときに保持期間を指定できる</li></ul></li></ul><p>また、次のような特徴があります。</p><ul><li>テーブル定義に<code>BACKUP NO</code>を加えると、バックアップ対象外になる</li><li>クラスター全体を復元する代わりに、スナップショットから単一のテーブルを復元できる</li><li>別アカウントへ共有可能。※RDSと同様</li><li>復元する際に(コンソールから実行する限りは)監査設定とIAMロールが外れるので注意が必要。ユーザー側で再設定する必要がある</li></ul><h3 id="3-4-メンテナンスウィンドウ"><a href="#3-4-メンテナンスウィンドウ" class="headerlink" title="3-4. メンテナンスウィンドウ"></a>3-4. メンテナンスウィンドウ</h3><p>Amazon Redshiftは定期的にメンテナンスを実行して、クラスターにアップグレードを適用します。更新中は Amazon Redshiftクラスターで通常の操作を実行することはできません。</p><p>また、特に抑えておきたい内容に以下のような項目があります。</p><ul><li>メンテナンスウィンドウは30分以上、24時間以内で指定可能<ul><li>クラスター作成時は指定できず、自動で設定される。※コンソール使用時</li></ul></li><li>メンテナンスがスケジュールされた場合、最長45日までは延期可能。</li></ul><h2 id="4-パラメータグループ"><a href="#4-パラメータグループ" class="headerlink" title="4. パラメータグループ"></a>4. パラメータグループ</h2><p>使用できるパラメータのリストは、パラメータグループが属しているパラメータグループファミリーによって異なります。</p><p>これはRedshiftのエンジンバージョン毎に異なるパラメータのリストが使われる(新しいバージョンでないと設定できないパラメータやサポートされないパラメータがある)ということですが、2019年5月時点ではエンジンバージョンは一つ(<code>redshift-1.0</code>)しかないので現時点では気にしなくても良さそうです。</p><p>反映する場合は <strong>再起動が必要</strong>です。ただしWLM(後述)のうち一部のパラメータは動的変更可能です。</p><p>パラメータ一覧</p><table><thead><tr><th>Item</th><th>Note</th></tr></thead><tbody><tr><td>auto_analyze</td><td>自動ANALYZEを有効にするか。データ更新がバッチのみなら手動ANALYZEのみにした方が制御しやすい</td></tr><tr><td>datestyle</td><td>‘ISO, YMD’が無難</td></tr><tr><td>enable_user_activity_logging</td><td>データベースで実行される前に各クエリを記録する</td></tr><tr><td>extra_float_digits</td><td>浮動小数点値 (float4 と float8 を含みます) の表示桁数を設定する</td></tr><tr><td>max_concurrency_scaling_clusters</td><td>同時実行スケーリングで起動されるクラスター数上限を設定する</td></tr><tr><td>max_cursor_result_set_size</td><td>設定は可能だが、廃止されている</td></tr><tr><td>query_group</td><td>ワークロード管理で利用するが、パラメータグループで設定することはまずないと思われる</td></tr><tr><td>require_ssl</td><td>tls接続を使用する</td></tr><tr><td>use_fips_ssl</td><td>FIPS 準拠の SSL モードを有効にする</td></tr><tr><td>search_path</td><td>検索パス(PostgreSQLと同じもの)</td></tr><tr><td>statement_timeout</td><td>指定されたミリ秒数以上かかっているステートメントを中止する。0に設定すれば制限なし</td></tr></tbody></table><p>セッション内でのみ変更可能なパラメータもあります。</p><table><thead><tr><th>Item</th><th>Note</th></tr></thead><tbody><tr><td><code>analyze_threshold_percent</code></td><td><code>ANALYZE</code>を実行する際のしきい値を設定する。<code>analyze_threshold_percent</code>の指定よりも変更された行の割合が低いテーブルの分析は省略される。デフォルトは10(パーセント)</td></tr><tr><td><code>describe_field_name_in_uppercase</code></td><td><code>SELECT</code>で返却される列名を大文字にする。デフォルトはオフ</td></tr><tr><td><code>timezone</code></td><td>セッションのタイムゾーンを設定する。デフォルトはUTC。パラメータグループでは設定できない。デフォルト設定した場合はユーザーのデフォルトセッションパラメータに設定する</td></tr><tr><td><code>wlm_query_slot_count</code></td><td><a href="#WLM設定">WLM設定</a>参照</td></tr></tbody></table><h2 id="5-ワークロード管理"><a href="#5-ワークロード管理" class="headerlink" title="5. ワークロード管理"></a>5. ワークロード管理</h2><p>Amazon Redshift では、<strong>ワークロード管理(WLM)</strong>を使用して、使用可能なクエリキューの数と、処理するためにクエリをそれらのキューにルーティングする方法を定義します。</p><p>デフォルトのWLM設定には、<strong>最大5つのクエリを同時に実行できる1つのキュー</strong>が含まれ、<strong>最大で8個のキューを定義</strong>できます。</p><h3 id="5-1-スーパーユーザーキュー"><a href="#5-1-スーパーユーザーキュー" class="headerlink" title="5.1 スーパーユーザーキュー"></a>5.1 スーパーユーザーキュー</h3><p>スーパーユーザーキューは、スーパーユーザー専用に予約されており、設定することはできません。</p><p>このキューは、システムに影響を与えるクエリを実行する必要があるときや、トラブルシューティング目的でのみ使用することが想定されています。</p><p>スーパーユーザーキューでクエリを実行するには、ユーザーはスーパーユーザーとしてログインし、事前定義された <code>superuser</code>クエリグループを使用してクエリを実行する必要があります。</p><h3 id="5-2-WLM設定"><a href="#5-2-WLM設定" class="headerlink" title="5.2 WLM設定"></a>5.2 WLM設定</h3><p>WLMは<code>wlm_json_configuration</code>パラメータで制御すします。<code>wlm_json_configuration</code>はJSON(キューに対応するオブジェクトの配列)として定義します。キューに名前を付けられないのでわかりにくいですね。</p><p>プロパティは動的/静的があります。動的はクラスターを再起動することなく適用でき、静的プロパティはクラスターの再起動が必要です。</p><table><thead><tr><th>名称</th><th>種別</th><th>説明</th><th>備考</th></tr></thead><tbody><tr><td><code>query_concurrency</code></td><td>動的</td><td>キューの同時実行クエリ数。キューが同時実行レベルに達すると、後続のクエリを処理するリソースが利用可能になるまでそれらのクエリはキューで待機する。</td><td>定義可能な範囲は1～50だが、全てのキューを合計して15までが推奨値</td></tr><tr><td><code>max_execution_time</code></td><td>動的</td><td>クエリが実行されて始めてからキャンセルされるまでの最大時間（ミリ秒単位）。COPY ステートメントと、ANALYZE や VACUUM などのメンテナンスオペレーションは、WLM タイムアウトの対象にはならない</td><td></td></tr><tr><td><code>memory_percent_to_use</code></td><td>動的</td><td>キューに割り当てるメモリの割合。すべてのキューに割り当てられたメモリの合計が100パーセントを下回る場合、未割り当てのメモリはサービスによって管理され、処理用に追加メモリをリクエストするキューに一時的に付与できる。クエリスロットに割り当てられるメモリ量は、キューに割り当てられたメモリをスロットカウントで割った割合と同じ。</td><td>デフォルトは各ユーザー定義キューへ均等に割り当て。100%になるような割り当てが無難。<code>Superuser</code>キューは独自に割り当てられているメモリがあるため変更負荷</td></tr><tr><td><code>user_group</code></td><td>静的</td><td>ユーザーグループ名のカンマ区切りリスト。ユーザーグループのメンバーがデータベースでクエリを実行すると、そのメンバーのクエリはユーザーグループに関連付けられたキューにルーティングされる</td><td></td></tr><tr><td><code>user_group_wild_card</code></td><td>静的</td><td>ユーザーグループでワイルドカードを有効にするかどうかを示すブール値。ワイルドカードが有効な場合、「+」または「?」を使用し、クエリを実行するときに複数のユーザーグループを指定できる</td><td>0:無効 1:有効</td></tr><tr><td><code>query_group</code></td><td>静的</td><td>クエリグループのカンマ区切りリスト。クエリグループのメンバーがデータベースでクエリを実行すると、そのメンバーのクエリはクエリグループに関連付けられたキューにルーティングされる</td><td></td></tr><tr><td><code>query_group_wild_card</code></td><td>静的</td><td>クエリグループでワイルドカードを有効にするかどうかを示すブール値。ワイルドカードが有効な場合、「+」または「?」を使用し、クエリを実行するときに複数のクエリグループを指定できる</td><td>0:無効 1:有効</td></tr></tbody></table><p>以下、キューとルーティングについて追記します。</p><ul><li>ルーティングについて<ul><li><code>query group</code>を使ってルーティングする場合<ul><li>ユーザーのデフォルトセッションパラメータで<code>query_group</code>を定義することも出来るので、変えたい時だけ<code>SET</code>する運用が可能である</li><li>ex. <code>set query_group to &#39;priority-high&#39;; xxx; reset query_group;</code></li></ul></li><li><code>user_group</code>をつかってルーティングする場合<ul><li>アプリケーションによってワークロードが変わる場合は、アプリケーションごとにユーザーを作成することで、異なるキューを割り当てることができる</li></ul></li></ul></li><li>キュー割り当てルール<ol><li>user = <code>Superuser</code> and Query Group = <code>superuser</code>, then <code>Superuser queue</code></li><li>Matching user group, then user group</li><li>Matching query group, then query group</li><li>default queue</li></ol></li><li>VACUUMのルーティング<ul><li>VACUUMのルーティングはテーブルの所有者権限(またはスーパーユーザー権限)を持っていないと実行できないため、所有者が含まれる<code>user_group</code>でキュー定義していると<code>VACUUM</code>がそのキューに行ってしまう。<code>user_group</code>ではなく<code>query_group</code>でルーティングするようにした方が良い</li><li>例えばテーブルAの所有者ユーザーAがグループAに所属していた場合、グループAに対して定義されたキューがあると、ユーザーAが発行する<code>SELECT</code>と<code>VACUUM</code>がどちらの同じキューへルーティングされる</li></ul></li><li>キューの分割パターン<ul><li>スループット重視で並列度を管理可能な夜間バッチ<ul><li>実行されるクエリが予測できるので、タイムアウトはさせない</li><li>夜間バッチ前後にWLM設定を変更し、日中クエリにメモリを明け渡すことも検討する</li></ul></li><li>リクエスト数が多いが、定型的でキャッシュヒットしやすいクエリ(ダッシュボード等)<ul><li>実行されるクエリが予測できるので、タイムアウトはさせない</li><li>同時実行スケーリングを有効にする</li></ul></li><li>実行されるクエリが予め予測できないアドホッククエリ<ul><li>メモリを使いすぎないように、メモリ上限を少なめにしておく</li><li>タイムアウトを設定する</li><li><a href="クエリモニタリング">クエリモニタリング</a>を設定する</li></ul></li></ul></li></ul><h4 id="キューの確認方法"><a href="#キューの確認方法" class="headerlink" title="キューの確認方法"></a>キューの確認方法</h4><p><code>service_class</code>がわかりにくいですが…</p><ul><li>1, 2, 3, 4はシステム用</li><li>5がスーパーユーザーキュー</li><li>6～13までユーザー定義キュー</li><li>14が <a href="#short-query-acceleration">SQA</a> 用のキュー</li></ul><figure class="highlight sql"><figcaption><span>キューの確認方法</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> service_class, num_query_tasks, query_working_mem, <span class="keyword">name</span> <span class="keyword">from</span> stv_wlm_service_class_config;</span><br></pre></td></tr></table></figure><p>キューとクエリのマッピング方法</p><figure class="highlight sql"><figcaption><span>キュートクエリのマッピング</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    wq.queue_start_time</span><br><span class="line">,   wq.service_class</span><br><span class="line">,   wq.total_exec_time</span><br><span class="line">,   q.label</span><br><span class="line">,   q.concurrency_scaling_status</span><br><span class="line">,   <span class="keyword">trim</span>(q.querytxt) <span class="keyword">as</span> query_text</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    stl_wlm_query wq</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span></span><br><span class="line">    stl_query q</span><br><span class="line"><span class="keyword">on</span>  wq.query = q.query</span><br><span class="line"><span class="keyword">where</span> <span class="number">1</span>=<span class="number">1</span></span><br><span class="line"><span class="keyword">and</span> wq.service_class &gt; <span class="number">5</span></span><br><span class="line"><span class="keyword">and</span> wq.final_state = <span class="string">'Completed'</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    q.query <span class="keyword">desc</span></span><br><span class="line"><span class="keyword">limit</span> <span class="number">20</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure><h3 id="5-3-クエリモニタリング"><a href="#5-3-クエリモニタリング" class="headerlink" title="5.3 クエリモニタリング"></a>5.3 クエリモニタリング</h3><p>リソース消費が激しいクエリや、検索件数が多すぎるクエリなど、滅茶苦茶なクエリを監視することができます。</p><p>また、基準に抵触した場合に、<strong>ログ</strong>・<strong>ホップ</strong>・<strong>キャンセル</strong>を選ぶことができます。</p><ul><li>ログ: ログ出力するのみ</li><li>ホップ: 実行状態を保ったままキューを移動させる</li><li>キャンセル: クエリをキャンセルする</li></ul><h3 id="5-4-クエリホッピング"><a href="#5-4-クエリホッピング" class="headerlink" title="5.4 クエリホッピング"></a>5.4 クエリホッピング</h3><p>WLMタイムアウトした場合・クエリモニタリングでホップした場合、次の有効なキューに移されます。この場合は一度キャンセルされるわけではなく、実行状態を保ったままキューを移動します。</p><p>これにより低レイテンシ用のキューで予期せず長時間かかるクエリが実行された場合に、長時間クエリ用のキューへ移動することが可能になります。</p><h2 id="6-ユーザー・グループ"><a href="#6-ユーザー・グループ" class="headerlink" title="6. ユーザー・グループ"></a>6. ユーザー・グループ</h2><p>現在のPostgreSQLではRoleに統合されているが、Redshiftでは分かれています。<br>わかりにくいのでユーザーとグループで同じ名前を使わないようにすべきでしょう。</p><ul><li>グループの使い道<ul><li>権限設定</li><li>WLMキューの振り分け</li></ul></li><li>全てのユーザーが暗黙的に<code>PUBLIC</code>グループに所属しています。<ul><li><code>PUBLIC</code>グループに対して<code>public</code>スキーマの<code>CREATE</code>と<code>USAGE</code>が付与されているので、<code>public</code>スキーマを使用しない場合は<code>REVOKE</code>しておくか、<code>search_path</code>を設定しておくと良いでしょう。</li></ul></li><li>通常のデータベースユーザーも<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/generating-user-credentials.html" target="_blank" rel="noopener">IAM認証</a>も可能です。</li><li>ユーザーのパスワードを無効にするには<code>DISABLE</code>を指定します。パスワードを無効にしてもIAM認証は可能です。</li><li><code>CREATEUSER</code>オプションを使用すると、<code>CREATE USER</code>を含め、データベースに関するすべての権限を持つスーパーユーザーが作成されます。</li><li><code>SYSLOG ACCESS UNRESTRICTED</code>を指定すると、別のユーザーによって生成された行を含む、ユーザーが表示可能なシステムテーブルとビューのすべての行を表示できます。ただし、スーパーユーザーのみが表示可能なテーブルへのアクセス権は与えられません。デフォルトは<code>RESTRICTED</code>です。なお、STV_RECENTS および SVV_TRANSACTIONS のすべての行は、すべてのユーザーに表示されます。</li><li><code>CONNECTION LIMIT</code>を指定すると、ユーザーが同時に開けるデータベース接続の最大数を指定できます。デフォルトは<code>UNLIMITED</code>であり、クラスターの同時接続制限数は500です。</li><li><code>ALTER USER username SET parameter TO value</code>でセッションパラメータのデフォルト値を設定できます。<ul><li>ユーザーレベルで設定するのは<code>search_path</code>と<code>statement_timeout</code>くらいでしょうか。</li></ul></li></ul><p>ユーザーとグループのマッピング確認は以下の通りです。</p><figure class="highlight sql"><figcaption><span>ユーザとグループのマッピング確認</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    grp.groname</span><br><span class="line">,   usr.usename</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    pg_group grp</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span></span><br><span class="line">    pg_user usr</span><br><span class="line"><span class="keyword">on</span> usr.usesysid = <span class="keyword">ANY</span>(grp.grolist)</span><br><span class="line"><span class="keyword">where</span> <span class="number">1</span>=<span class="number">1</span></span><br><span class="line"><span class="comment">--    pg_group.groname='&lt;YOUR_GROUP_NAME&gt;'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure><h2 id="7-監査ログ"><a href="#7-監査ログ" class="headerlink" title="7. 監査ログ"></a>7. 監査ログ</h2><p><strong>接続ログ</strong>・<strong>ユーザーログ</strong>・<strong>ユーザーアクティビティログ</strong>が収集可能です。</p><ul><li>接続ログ<ul><li>認証の試みと、接続および切断を記録する</li><li>自動でシステムテーブル(STL_CONNECTION_LOG）に出力されるが、S3に出力することも可能</li></ul></li><li>ユーザーログ<ul><li>データベースのユーザー定義への変更に関する情報を記録する</li><li>自動でシステムテーブル(STL_USERLOG）に出力されるが、S3に出力することも可能</li></ul></li><li>ユーザーアクティビティログ<ul><li>データベースで実行される前に各クエリを記録する</li><li>S3へのログ出力を有効化したうえでパラメータ <code>enable_user_activity_logging</code> の設定が必要</li></ul></li></ul><p>ただし、S3出力時には権限設定が必要で、ELBと同様にRedshiftがS3に書き込めるよう特定のアカウントIDからのアクセス許可（<code>s3:GetBucketAcl</code>, <code>s3:PutObject</code>）を付与します。<br>検証したところ、有効にしてからログが配信されるまで1時間くらいかかりました。</p><h2 id="8-テーブル設計"><a href="#8-テーブル設計" class="headerlink" title="8. テーブル設計"></a>8. テーブル設計</h2><h3 id="8-1-実行計画"><a href="#8-1-実行計画" class="headerlink" title="8-1. 実行計画"></a>8-1. 実行計画</h3><h4 id="テーブル結合"><a href="#テーブル結合" class="headerlink" title="テーブル結合"></a>テーブル結合</h4><p>性能観点では、<strong>Merge Join</strong>が最適で、次点が<strong>Hash Join</strong>で<strong>Nested Loop</strong>の順。</p><p>しかし、Merge Joinが選択されるためには、分散キー/ソートキーで結合される必要があります。分散キーとソートキーは同じカラムでないといけないので、ファクトとディメンジョンの結合ではまずならないです。また。ソートキーは<a href="#ソートキー"><code>compound sort key</code></a>である必要があります。[分散スタイル](#8-2. 分散スタイル)は両テーブルとも<code>KEY</code>である必要があります。<code>ALL</code>では(必要なデータはローカルにあるはずだが)Merge Joinが選択されません。</p><p>上記の制約もありMerge Joinが使えるケースは希少だと思うので、基本的にHash Joinを使うように考えた方が良さそうです。高速化する場合は分割並列化し、分割キーで(可能なら)ソートキーを作る、あるいは複合キーに加えます。</p><p>また、Nested Loopを選ばないためには、結合は等価結合でないとダメです。</p><p>【参考】<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_EXPLAIN.html" target="_blank" rel="noopener">ステップ概要</a>・<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c_data_redistribution.html" target="_blank" rel="noopener">クエリプランの評価</a></p><h4 id="クエリの実行"><a href="#クエリの実行" class="headerlink" title="クエリの実行"></a>クエリの実行</h4><p>開発者ガイドの<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-query-planning.html" target="_blank" rel="noopener">クエリプランと実行ワークフロー</a>によると、実際にはSQLがそのまま実行されるのではなく、C++コードに変換された後コンパイルされて実行されます。</p><p>コンパイルに秒単位の時間がかかるため、初回の検索に時間がかかりますが、実行計画が同じクエリであればコンパイル結果が再利用されます。</p><h4 id="設計方針"><a href="#設計方針" class="headerlink" title="設計方針"></a>設計方針</h4><ul><li>最終的にはERではなくクエリパタンに基づき実行計画を設計して、分散スタイルとソートキーを設定する</li><li>とはいえ、ERがないとクエリが設計できないので、下記のガイドに従って仮決めする。</li><li>大雑把に言えばレイテンシーに影響があるのはソートキーと圧縮で、スループットに影響があるのは圧縮キー<ul><li>それでもレイテンシーが足りなければデータマートやサマリテーブルを検討する</li></ul></li></ul><h3 id="8-2-分散スタイル"><a href="#8-2-分散スタイル" class="headerlink" title="8-2. 分散スタイル"></a>8-2. 分散スタイル</h3><p>テーブルを作成する場合は<code>EVEN</code>/<code>ALL</code>/<code>KEY</code>/<code>AUTO</code>(デフォルト)のいずれかの分散スタイルを指定します。</p><ul><li><code>EVEN</code>: ラウンドロビン方式で各スライスへ行を分散する</li><li><code>ALL</code>: テーブル全体のコピーが全てのノードに分散される<ul><li>サイズが小さいテーブルに適しているようにも思えるが、更新コストが増える割に再分散コストが低いため、大きなメリットは得られない。また、結合しない場合は各スライスの検索結果をUNIONすることになるため、むしろ遅くなる。</li><li>更新頻度が低く、更新範囲が広くないテーブルに適している</li><li>結合する際に内部表となる場合に有効。実行計画が<code>DS_DIST_ALL_NONE</code>となる</li></ul></li><li><code>KEY</code>: 特定の列に含まれている値に従って、複数の一致する値を同じノードスライスに配置する<ul><li>指定できる分散キーは一つだけ。複合キーにはできない</li><li>where句で指定されるカラムは不向き。クエリが分散しなくなってしまうため。ただし、分散キーをソートに指定することも出来る</li></ul></li><li><code>AUTO</code>: テーブルサイズに応じて<code>EVEN</code>か<code>ALL</code>か自動的に判定する</li></ul><p><a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-distribution-styles-and-distribution-keys.html" target="_blank" rel="noopener">Amazon Redshift テーブル設計詳細ガイド:Part 2 分散スタイルと分散キー</a>に最適な分散スタイルと分散キーを選ぶ方法論が紹介されています。以下に簡単にまとめます。</p><ul><li>適切なDistKeyの特定<ul><li>列のデータが均一に分散しているか？<ul><li>DistKeyの値を同じくするレコード数がどれも同じくらいか？</li></ul></li><li>列のカーディナリティが高いか？<ul><li>スライス数を大きく上回る(10倍以上)のユニーク値を持つか？</li><li>少ないとスライスごとにデータサイズがばらつく</li></ul></li><li>クエリは選択的フィルターを実行するか？<ul><li>実行しないのであれば、分散キーの有力候補</li><li>実行するのであれば、まず第一ソートキーになり得るか確認する<ul><li>加えて同じキーで分散・ソートが設定してあるテーブルと結合するならMerge Joinになるので、分散キーの有力候補</li></ul></li></ul></li></ul></li><li>分散スタイルの選択<ul><li>結合しないテーブルの場合<ul><li>適切なDistKeyがあればKey分散を選択する</li><li>なければEVEN分散になる。ALL分散は採用しない</li></ul></li><li>結合するテーブルの場合、まずALL分散を検討する<ul><li>以下の条件を全て満たせばALL分散を採用する<ul><li>小さいテーブルである。全ノードへコピーするためストレージ使用量が増えてしまう</li><li>更新頻度の低いテーブルである。全ノードで重複データを持つため、全ノードにレプリケートされるまで書き込みが終わらなくなる</li><li>駆動表にならない。駆動表となった場合に、全ノードで同一データをスキャンするため非効率</li><li>適切な分散キーが見つからない</li></ul></li><li>採用できない場合、結合しないテーブルにおける検討に従ってKey分散ないしEVEN分散とする</li></ul></li></ul></li></ul><h3 id="8-3-ソートキー"><a href="#8-3-ソートキー" class="headerlink" title="8-3. ソートキー"></a>8-3. ソートキー</h3><ul><li>ソートキーを指定することでスキャン範囲を制限することができる。<ul><li>index scanというよりも、パーティションプルーニングに近い。</li></ul></li><li>なるべくprefixのついていない文字列を選ぶ(先頭8バイトしかソートに使われない)</li><li>where句で指定されるカラム(indexと同じ使い方)か、結合キーになるカラムを指定する<ul><li>分散キー・ソートキーで結合する場合にMerge Joinが選択され、Redshiftでは最適な結合プランになる。結合キーだからソートキーにするのではなく、Merge Joinを狙う場合に指定する</li></ul></li><li>ソートキーの種類(<a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-compound-and-interleaved-sort-keys.html" target="_blank" rel="noopener">Compound and Interleaved Sort Keys</a>)<ul><li>compoundは複数のソートキーを指定した場合に、指定順にソートされる。interleavedは多次元のゾーンマップが構成されるので指定順に関係なし</li><li>Merge Joinを狙うか？YESならcompound<ul><li>Merge Joinとなる条件は結合条件に分散キーとソートキーが含まれること<ul><li>Key分散しているテーブル同士でないとMege Joinにはならない。ソートキーが一致していてもKey分散とALL分散ではMerge Joinが選択されない</li></ul></li><li>Hash Joinの方が速いケースもある。結合よりも抽出を高速にした方が良い場合は抽出条件をソートキーにした方が良い</li></ul></li><li>ソートはゾーンマップを改善するか？クエリはゾーンマップを利用するか？<ul><li>ゾーンマップは、1MBブロック毎に、ブロック内の最小値と最大値をメモリー内にメタデータとして保存します<ul><li>各スライス事にゾーンマップを管理する。最低限、カラムデータサイズがスライス数x1MBを超えないと意味がない</li></ul></li><li>FunctionやCAST(暗黙CASTも含むので注意)では利用されない。PostgreSQLのパーティションキーと同じ</li><li>抽出条件指定でcompoundかinterleavedか選択する<ul><li>compoundの場合、第一ソートキーが指定されないと無意味</li><li>とはいえ、vacuum reindexのコストが高いため、interleavedは選びにくい。マート専用か</li></ul></li></ul></li><li>ソートは実行時のソート処理を削減するか？YESならcompound<ul><li>ORDER BY、GROUP BY,　Window関数内のPARTITION BY, ORDER BYなど</li><li>ソートを高速化したいケースでは大概ゾーンマップを利用したくなるはずなので、これだけを理由とするケースはあまり想像できない</li><li><code>where col_a = &#39;a&#39; group by col_b</code>のようなケースでソートキー<code>col_a, col_b</code>が有効かどうか</li></ul></li><li>どれもNOならソートキーにしない</li></ul></li><li>メンテナンス<ul><li>compound<ul><li><code>vacuum delete only</code>はバックグラウンドで実行されるため、バッチの中で<code>vacuum sort only</code>を実行するのは有用かも</li><li>未ソート領域が大きい場合はVACUUMよりもディープコピーを行う</li></ul></li><li>interleaved<ul><li>COPYまたはCTASを使用して空テーブルにロードすると、自動的にインデックスが作成される。INSERTを使用してロードした場合はVACUUM REINDEXの実行が必要</li><li>VACUUM REINDEXのコストが高い。まるごとCTASで作り直す設計にし、VACUUM REINDEXを実行しないことを第一に考えるべき<ul><li>ただしCTASだと圧縮エンコーディングが指定できず、自動設定される</li></ul></li></ul></li></ul></li><li>compound sortkeyの状態確認</li></ul><figure class="highlight sql"><figcaption><span>compound sortkeyの状態確認</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    sti.schema</span><br><span class="line">,   stp.name</span><br><span class="line">,   stp.sorted_rows</span><br><span class="line">,   stp.rows</span><br><span class="line">,   <span class="keyword">round</span>(<span class="number">100.0</span> * stp.sorted_rows / (stp.rows + <span class="number">0.0000001</span>), <span class="number">2</span>) <span class="keyword">as</span> sort_percentage</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        <span class="keyword">id</span></span><br><span class="line">    ,   <span class="keyword">name</span></span><br><span class="line">    ,   <span class="keyword">sum</span>(sorted_rows) <span class="keyword">as</span> sorted_rows</span><br><span class="line">    ,   <span class="keyword">sum</span>(<span class="keyword">rows</span>) <span class="keyword">as</span> <span class="keyword">rows</span></span><br><span class="line">    <span class="keyword">from</span></span><br><span class="line">        stv_tbl_perm</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">        <span class="keyword">id</span>, <span class="keyword">name</span></span><br><span class="line">    ) stp</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> svv_table_info sti</span><br><span class="line">    <span class="keyword">on</span> stp.id = sti.table_id</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    sti.sortkey_num &gt; <span class="number">0</span></span><br><span class="line"><span class="keyword">and</span> stp.rows &gt; <span class="number">0</span></span><br><span class="line"><span class="keyword">and</span> stp.sorted_rows &lt;&gt; stp.rows</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    sort_percentage</span><br><span class="line">;</span><br></pre></td></tr></table></figure><ul><li>interleaved sortkeyの状態確認</li></ul><figure class="highlight sql"><figcaption><span>interleaved sortkeyの状態確認</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    tbl <span class="keyword">as</span> tbl_id</span><br><span class="line">,   stv_tbl_perm.name <span class="keyword">as</span> table_name</span><br><span class="line">,   <span class="keyword">col</span></span><br><span class="line">,   interleaved_skew</span><br><span class="line">,   last_reindex</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    svv_interleaved_columns</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> stv_tbl_perm</span><br><span class="line">    <span class="keyword">on</span>  svv_interleaved_columns.tbl = stv_tbl_perm.id</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="8-4-キー"><a href="#8-4-キー" class="headerlink" title="8-4. キー"></a>8-4. キー</h3><p><code>UNIQUE</code>・<code>PRIMARY KEY</code>・<code>References</code>・<code>FOREIGN KEY</code>はプランナが利用するものの、システムに強制されない(制約にならない)です。</p><h3 id="8-5-データ型"><a href="#8-5-データ型" class="headerlink" title="8-5. データ型"></a>8-5. データ型</h3><ul><li>数値<ul><li>数値データ型には、整数型、10 進数型、および浮動小数点数型などがあります。</li></ul></li></ul><table><thead><tr><th>型</th><th>備考</th></tr></thead><tbody><tr><td><code>SMALLINT</code>/<code>INT2</code></td><td>符号付き2バイト整数</td></tr><tr><td><code>INTEGER</code>/<code>INT</code>/<code>INT4</code></td><td>符号付き4バイト整数</td></tr><tr><td><code>BIGINT</code>/<code>INT8</code></td><td>符号付き8バイト整数</td></tr><tr><td><code>DECIMAL</code>/<code>NUMERIC</code></td><td>任意精度</td></tr><tr><td><code>REAL</code>/<code>FLOAT4</code></td><td>単精度浮動小数点数</td></tr><tr><td><code>DOUBLE PRECISION</code>/<code>FLOAT</code>/<code>FLOAT8</code></td><td>倍精度浮動小数点数</td></tr></tbody></table><ul><li>文字列<ul><li><code>CHAR</code>/<code>VARCHAR</code>は最大長を宣言する代わりに<code>MAX</code>キーワードが使用可能です。</li></ul></li></ul><table><thead><tr><th>型</th><th>備考</th></tr></thead><tbody><tr><td><code>CHAR</code></td><td><strong>バイトセマンティクス</strong>で4096バイト。シングルバイト文字のみ</td></tr><tr><td><code>VARCHAR</code></td><td><strong>バイトセマンティクス</strong>で65535バイト。マルチバイト文字がサポートされており、対応している文字コードはUTF-8、1～4バイト文字まで利用可</td></tr><tr><td><code>TEXT</code></td><td><code>VARCHAR(256)</code>の別名</td></tr></tbody></table><ul><li>日付と時刻<ul><li>日付は<code>DATE</code>、日付時刻には<code>TIMESTAMP</code>と<code>TIMESTAMPTZ</code>がある</li><li>クラスタのタイムゾーンはUTC固定だが、セッションパラメータを変更することは可能</li></ul></li><li>真偽値<ul><li>論理ブール演算型 (true/false)として<code>BOOLEAN</code>/<code>BOOL</code>がある</li></ul></li><li>その他<ul><li>配列・JSONはサポートされていない</li></ul></li></ul><h3 id="8-6-圧縮エンコード"><a href="#8-6-圧縮エンコード" class="headerlink" title="8-6. 圧縮エンコード"></a>8-6. 圧縮エンコード</h3><ul><li><code>ANALYZE COMPRESSION</code>を実行して圧縮率を評価できる<ul><li><code>ANALYZE COMPRESSION</code>は排他的テーブルロックを取得し、テーブルに対する同時読み取り書き込みがブロックされる。<code>ANALYZE COMPRESSION</code>コマンドは、テーブルがアイドル状態になっている場合にのみ実行する。</li></ul></li><li>圧縮エンコードの選択。基本的にはデータドメインで定まる。以下に記載のないエンコーディングは有効なユースケースが不明なので、<code>ANALYZE COMPRESSION</code>で提示されたら検討すると良いと思います。<ul><li>ソートキーカラムは非圧縮(<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c_Raw_encoding.html" target="_blank" rel="noopener"><code>RAW</code></a>)にする</li><li>区分値はバイトディクショナリエンコード(<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c_Byte_dictionary_encoding.html" target="_blank" rel="noopener"><code>BYTEDICT</code></a>)<ul><li>ディクショナリサイズ: 1MB</li><li>キーサイズ: 1バイト. 最大256個</li><li>列のデータドメインが一意の値 256 個未満である場合に最適</li></ul></li><li>汎用で使われるエンコードは<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/lzo-encoding.html" target="_blank" rel="noopener"><code>LZO</code></a>と<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/zstd-encoding.html" target="_blank" rel="noopener"><code>ZSTD</code></a>。<code>ZSTD</code>の方が優れているが、後発であるためか圧縮エンコードを指定しない場合のデフォルトは<code>LZO</code>になる<ul><li>LZO(<code>LZO</code>)<ul><li><code>LZO</code>エンコードは、非常に長い文字列を格納する<code>CHAR</code>および<code>VARCHAR</code>列、特に製品説明、ユーザーコメント、JSON文字列などの自由形式テキストに適している</li><li><code>LZO</code>は、ソートキー、および<code>BOOLEAN</code>、<code>REAL</code>、または<code>DOUBLE PRECISION</code>データ型として定義された列として指定された列以外のエンコードのデフォルトとされている</li></ul></li><li>Zstandard(<code>ZSTD</code>)<ul><li>Zstandard (<code>ZSTD</code>) エンコーディングは、多様なデータセット間で非常にパフォーマンスのいい高圧縮比率を提供します。<code>ZSTD</code> は、製品説明、ユーザーのコメント、ログ、JSON 文字列など、長さがさまざまな文字列を保存する<code>CHAR</code>および<code>VARCHAR</code>列に対して、特に効果を発揮します</li><li>ZSTD では、Amazon Redshift のすべてのデータ型がサポートされています</li></ul></li></ul></li><li>ランレングスエンコード(<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c_Runlength_encoding.html" target="_blank" rel="noopener"><code>RUNLENGTH</code></a>)<ul><li>連続して繰り返される値を、値と連続発生数 (実行の長さ) から成るトークンに置き換えます</li><li>ソートキーに関係従属するカラムに使えるかと思いましたが、実測したところ<code>ZSTD</code>の方が高圧縮でした。</li></ul></li></ul></li></ul><p>カラム毎に使用しているブロック数は以下のSQLで確認できます。圧縮の効果が確認できます。</p><figure class="highlight sql"><figcaption><span>利用ブロック数の確認</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    t.schema</span><br><span class="line">,   t.table</span><br><span class="line">,   c.column_name</span><br><span class="line">,   <span class="keyword">max</span>(b.blocknum)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    stv_blocklist b</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span></span><br><span class="line">    svv_table_info t</span><br><span class="line">        <span class="keyword">on</span> b.tbl = t.table_id</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span></span><br><span class="line">    svv_columns c</span><br><span class="line">        <span class="keyword">on</span> t.schema = c.table_schema</span><br><span class="line">        <span class="keyword">and</span> t.table = c.table_name</span><br><span class="line">        <span class="keyword">and</span> b.col = c.ordinal_position <span class="number">-1</span></span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    t.table = <span class="string">'xxx'</span></span><br><span class="line"><span class="keyword">and</span> c.column_name = <span class="string">'yyy'</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span></span><br></pre></td></tr></table></figure><h2 id="9-データのロードとアンロード・バキューム"><a href="#9-データのロードとアンロード・バキューム" class="headerlink" title="9. データのロードとアンロード・バキューム"></a>9. データのロードとアンロード・バキューム</h2><h3 id="9-1-データロード"><a href="#9-1-データロード" class="headerlink" title="9-1. データロード"></a>9-1. データロード</h3><ul><li><a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_COPY.html" target="_blank" rel="noopener">COPY</a>コマンドを使用して、Amazon S3 バケット、Amazon EMR クラスター、リモート ホスト (SSH 接続を使用)、または Amazon DynamoDB テーブルからデータをロードできる</li><li><a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/copy-usage_notes-access-permissions.html#copy-usage_notes-iam-permissions" target="_blank" rel="noopener">COPY、UNLOAD、CREATE LIBRARY のための IAM のアクセス許可</a></li><li>データソース<ul><li>Amazon S3 からの COPY<ul><li>オブジェクトプリフィックス(<code>/</code>終わりでなくても良い)</li><li>マニフェストファイルパス</li></ul></li><li>Amazon EMR からの COPY</li><li>リモートホスト (SSH) からの COPY</li><li>Amazon DynamoDB からの COPY</li></ul></li><li>データ形式<ul><li><code>CSV [ QUOTE [AS] &#39;quote_character&#39; ] [DELIMITER [AS] &#39;delimiter_char&#39;]</code><ul><li>デフォルトの引用文字は二重引用符 ( “ ) だが、<code>QUOTE</code>オプションを使用して別の引用文字を指定できる</li><li>デフォルトの区切り記号はカンマ (,) だが、<code>DELIMITER</code>パラメータを使用して別の区切り記号を指定できる</li></ul></li><li><code>DATE</code>列と<code>TIMESTAMP</code>列をロードする場合、日付の場合は <code>YYYY-MM-DD</code>で、タイムスタンプの場合は<code>YYYY-MM-DD HH:MI:SS</code>がデフォルトの形式となる。デードデータでデフォルトの形式が使用されていない場合、<code>DATEFORMAT</code>と<code>TIMEFORMAT</code>を使用して形式を指定できる</li></ul></li><li>ファイル圧縮<ul><li><code>BZIP2</code>/<code>GZIP</code>/<code>LZOP</code>/<code>ZSTD</code></li><li><code>LZOP</code>形式では<code>UNLOAD</code>できない。<code>BZIP2</code>は時間がかかるので、<code>GZIP</code>が無難</li><li><code>ZSTD</code>はAmazon S3からCOPYを使用する場合のみサポートされる</li></ul></li><li>その他パラメータ(通常は<code>STATUPDATE ON</code>だけ指定する運用で良いと思われる)<ul><li><code>COMPROWS numrows</code>: 圧縮分析のサンプルサイズ(スライス合計)として使用される行数を指定する。<code>COMPROWS</code>を指定しない場合、サンプルサイズはデフォルトでスライスごとに100,000になる。<code>COMPROWS</code>の値がスライスごとに100,000行のデフォルト値より小さい場合、自動的にデフォルト値にアップグレードされる。ただし、ロードされるデータの量が有意のサンプルとしては不十分な場合、自動圧縮は実行されない</li><li><code>COMPUPDATE [ { ON | TRUE } | { OFF | FALSE } ]</code>: <code>COMPUPDATE</code>を省略した場合、ターゲットテーブルが空であり、テーブルのすべての列に<code>RAW</code>エンコードがあるかまったくエンコードがないときにのみ、<code>COPY</code>は自動圧縮を適用する。<code>COMPUPDATE ON</code>(または<code>TRUE</code>)の場合、テーブル列に<code>RAW</code>以外のエンコードがある場合も、テーブルが空であれば<code>COPY</code>は自動圧縮を適用します。<code>COMPUPDATE OFF</code>(または<code>FALSE</code>)の場合、自動圧縮は無効になる。</li><li><code>MAXERROR AS error_count</code>: ロードのエラー数が<em>error_count</em>以上である場合、ロードは失敗する。ロードのエラーがそれより少ない場合、処理は続行される(正常データのみロードされる)</li><li><code>NOLOAD</code>: データを実際にロードせずにデータファイルの有効性をチェックする</li><li><code>STATUPDATE [ { ON | TRUE } | { OFF | FALSE } ]</code>: <code>ON</code>(または<code>TRUE</code>)の場合、テーブルが最初に空であるかどうかに関係なく、統計は自動的に更新される。<code>STATUPDATE</code>パラメータを使用しない場合、テーブルが最初は空ならば、統計は自動的に更新される</li></ul></li><li><code>ALTER TABLE RENAME</code>はトランザクション内で実行できるので、TMPにロード-&gt; TAB RENAME TO BK-&gt;TMP RENAME TABのような入れかえができる</li></ul><h3 id="9-2-データアンロード"><a href="#9-2-データアンロード" class="headerlink" title="9-2. データアンロード"></a>9-2. データアンロード</h3><p>参考: <a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_UNLOAD.html" target="_blank" rel="noopener">UNLOAD</a></p><ul><li>出力可能な形式<ul><li>固定長(<code>FIXWIDTH</code>)</li><li>Character Separated Values(<code>DELIMITER</code>)<ul><li>基本的に<code>ESCAPE</code>オプションを付けておいた方が無難<ul><li>エスケープ文字は<code>\</code></li><li>ラインフィード・キャリッジリターン・区切り文字・エスケープ文字・引用符(<code>ADDQUOTES</code>を指定した場合)がエスケープされる</li></ul></li></ul></li></ul></li><li>クエリで<code>ORDER BY</code>句を指定してソート順にデータをアンロードしておくと、データの再ロード時にデータをソートするために必要な時間を節約できる<ul><li><code>TOP</code>は <code>SELECT</code>句ではサポートされていない。代わりに<code>LIMIT</code>を使用する</li><li><code>SELECT</code>クエリは、外部の<code>SELECT</code>で<code>LIMIT</code>句を使用することはできない<ul><li>ネストするか、別テーブルにデータを移してからUNLOADする</li><li><code>select ... limit 10</code>はダメで、<code>select ... from (select ... limit 10)</code>はOKということ</li></ul></li></ul></li><li>クエリの中に引用符 (たとえば、リテラル値を囲むため) またはバックスラッシュ (<code>\</code>) がある場合は、クエリテキスト内でバックスラッシュでエスケープする必要がある</li><li>書き込み先にマニフェストファイルを指定する場合(<code>MANIFEST</code>オプションを指定する場合)、「manifest」サフィックスが自動的に付与されるため、<code>name_prefix</code>には含めない</li><li>マニフェストファイルを指定しない場合の出力フォーマットは<code>&lt;object-path&gt;/&lt;name-prefix&gt;&lt;slice-number&gt;_part_&lt;part-number&gt;</code></li><li>ヘッダー出力する場合は<code>HEADER</code>オプション。固定長では出力できない</li><li>圧縮する場合は<code>BZIP2</code>オプションか<code>GZIP</code>オプションを付与する</li><li>デフォルトでは既存ファイルの上書きは行わない。上書きする場合は<code>ALLOWOVERWRITE</code>オプションを付与する</li><li>デフォルトではスライス数に応じて複数ファイルに並列書き込みを行う。オフにする場合は<code>PARALLEL OFF</code></li><li>ファイルサイズ上限を指定すると1ファイルあたりのサイズ上限が指定できる。デフォルトでは6.2GB.</li></ul><h3 id="9-3-VACUUM"><a href="#9-3-VACUUM" class="headerlink" title="9-3. VACUUM"></a>9-3. VACUUM</h3><p>参考: <a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_VACUUM_command.html" target="_blank" rel="noopener">VACUUM</a></p><ul><li>テーブルの所有者またはスーパーユーザーのみがテーブルにバキューム処理を実行できる</li><li><code>VACUUM</code>にはサブコマンドで指定される以下のモードがある<ul><li><code>SORT ONLY</code>: ソートのみ。<code>Compound Sort Key</code>のメンテナンス<ul><li>デフォルトではテーブルの行の95パーセント以上がすでにソートされているテーブルのソートフェーズをスキップする。実行時に<code>TO threshold PERCENT</code>オプションを指定することでしきい値を変更できる</li></ul></li><li><code>DELETE ONLY</code>: 削除のみ。バックグラウンドで自動的にDELETE ONLY Vacuumを実行するため、手動実行する必要は通常ない<ul><li>デフォルトでは残りの行の少なくとも95パーセントが削除対象としてマークされていない領域を再利用する。実行時に<code>TO threshold PERCENT</code>オプションを指定することでしきい値を変更できる</li><li>ユーザーが<code>ALTER TABLE</code>などのデータ定義言語 (DDL) 操作を実行すると、自動バキューム操作は一時停止する</li></ul></li><li><code>FULL</code>(デフォルト): ソート＋削除。<code>TO threshold PERCENT</code>オプションを指定すると、ソートと削除の両方にしきい値が適用される</li><li><code>REINDEX</code>: <code>Interleaved Sort Key</code>のメンテナンス。<code>VACUUM FULL</code>よりも大幅に実行時間が長くなる</li></ul></li><li>排他制御<ul><li>トランザクションブロック内で<code>VACUUM</code>は実行できない</li><li><code>VACUUM</code>開始時にテーブルへの一時的な排他アクセスが必要になる</li><li>ユーザーは、バキューム処理中のテーブルにアクセスできる。バキューム処理中のテーブルにクエリおよび書き込み操作を実行できるが、データ操作言語 (DML) コマンドおよびバキュームを同時に実行すると両方の処理時間が長くなる可能性がある。バキューム処理中に<code>UPDATE</code>および<code>DELETE</code>ステートメントを実行する場合は、システムのパフォーマンスが低減する場合がある。<code>VACUUM DELETE</code>は、更新操作と削除操作を一時的にブロックする</li></ul></li><li>一度にクラスターで実行できる<code>VACUUM</code>コマンドは1つだけ<ul><li>vacuum専用のキューを作るのが簡単か</li></ul></li><li><code>VACUUM</code>では<code>ANALYZE</code>はされない</li></ul><h2 id="10-ラッシュパフォーマンス"><a href="#10-ラッシュパフォーマンス" class="headerlink" title="10. ラッシュパフォーマンス"></a>10. ラッシュパフォーマンス</h2><p>RedshiftのWLMにおける推奨同時クエリ実行数は15です。<br>これまでこの点を根拠として大量の参照クエリを受け付けるワークロードには不向きと考えられてきました。<br>しかしながら最近の機能アップデートにより、大量の参照クエリを処理する仕組みがRedshiftにも備わっています。</p><h3 id="10-1-Result-Caching"><a href="#10-1-Result-Caching" class="headerlink" title="10-1. Result Caching"></a>10-1. Result Caching</h3><ul><li>リーダーノード内のメモリにクエリ結果をキャッシュする。受け付けたクエリに対応する結果がキャッシュに含まれている場合、コンピュートノード上での処理を伴わずに結果が返却される</li><li><code>select limit 1000</code>でキャッシュされた結果は<code>limit 100</code>でも有効</li><li>コメントが違うだけのSQLであればキャッシュが使われる</li><li>JDBCでPreparedStatementを使用した場合、ログ上は同じSQLのように見えるが、バインド値が同じでないとキャッシュヒットしないし、同じあればヒットする</li><li>セッションレベルでは<code>enable_result_cache_for_session = off</code>で無効化できる</li></ul><p>キャッシュヒットしたクエリの確認</p><figure class="highlight sql"><figcaption><span>キャッシュヒットしたクエリ</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    userid</span><br><span class="line">,   <span class="keyword">query</span></span><br><span class="line">,   starttime</span><br><span class="line">,   endtime</span><br><span class="line">,   elapsed</span><br><span class="line">,   <span class="keyword">substring</span></span><br><span class="line">,   source_query</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    svl_qlog</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    source_query <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">null</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>キャッシュヒット率の確認</p><figure class="highlight sql"><figcaption><span>キャッシュヒット率確認</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="keyword">count</span>(<span class="number">1</span>)</span><br><span class="line">,   <span class="keyword">count</span>(source_query)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    svl_qlog q</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    q.userid = <span class="number">103</span></span><br><span class="line"><span class="keyword">and</span> q.starttime &gt; <span class="string">'2019-04-12 9:07:00'</span></span><br><span class="line"><span class="keyword">and</span> q.endtime &lt; <span class="string">'2019-04-12 9:08:00'</span></span><br></pre></td></tr></table></figure><h3 id="10-2-Short-Query-Acceleration"><a href="#10-2-Short-Query-Acceleration" class="headerlink" title="10-2. Short Query Acceleration"></a>10-2. Short Query Acceleration</h3><ul><li>実行時間が短いと判定された一部のクエリを、実行時間が長いクエリよりも優先する</li><li>SQAでは実行時間が短いクエリを専用領域で実行する。SQA用のWLMキューを事前定義する必要はない</li><li>SQAは実行時間が短く、ユーザー定義のキュー内にあるクエリのみを優先する。デフォルトキューでは無効</li><li>クエリのパターンをSQAが学習するため、時間が経つほど予測精度は向上する</li><li>対象クエリは<code>CTAS</code>と<code>SELECT</code>(正確には読み取り専用クエリ)</li></ul><p>サービスクエリ別クエリ統計。SQAクエリはサービスクラス14を使用する。</p><figure class="highlight sql"><figcaption><span>サービスクエリ別クエリ統計</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> final_state, service_class, <span class="keyword">count</span>(*), <span class="keyword">avg</span>(total_exec_time),</span><br><span class="line"><span class="keyword">percentile_cont</span>(<span class="number">0.9</span>) <span class="keyword">within</span> <span class="keyword">group</span> (<span class="keyword">order</span> <span class="keyword">by</span> total_queue_time), <span class="keyword">avg</span>(total_queue_time)</span><br><span class="line"><span class="keyword">from</span> stl_wlm_query <span class="keyword">where</span> userid &gt;= <span class="number">100</span> <span class="keyword">group</span> <span class="keyword">by</span> <span class="number">1</span>,<span class="number">2</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">2</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>SQA によって選択され正常に完了したクエリの特定</p><figure class="highlight sql"><figcaption><span>SQAによって選択され正常に完了したクエリの特定</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.queue_start_time, a.total_exec_time, label, <span class="keyword">trim</span>(querytxt)</span><br><span class="line"><span class="keyword">from</span> stl_wlm_query a, stl_query b</span><br><span class="line"><span class="keyword">where</span> a.query = b.query <span class="keyword">and</span> a.service_class = <span class="number">14</span> <span class="keyword">and</span> a.final_state = <span class="string">'Completed'</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> b.query <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure><p>SQA で選択されたがタイムアウトしたクエリの特定</p><figure class="highlight sql"><figcaption><span>SQAで選択されたがタイムアウトしたクエリの特定</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.queue_start_time, a.total_exec_time, label, <span class="keyword">trim</span>(querytxt)</span><br><span class="line"><span class="keyword">from</span> stl_wlm_query a, stl_query b</span><br><span class="line"><span class="keyword">where</span> a.query = b.query <span class="keyword">and</span> a.service_class = <span class="number">14</span> <span class="keyword">and</span> a.final_state = <span class="string">'Evicted'</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> b.query <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure><h3 id="10-3-同時実行スケーリング"><a href="#10-3-同時実行スケーリング" class="headerlink" title="10-3. 同時実行スケーリング"></a>10-3. 同時実行スケーリング</h3><ul><li>詳しくは<a href="https://www.slideshare.net/AmazonWebServices/modern-cloud-data-warehousing-ft-intuit-optimize-analytics-practices-ant202r1-aws-reinvent-2018" target="_blank" rel="noopener">Modern Cloud Data Warehousing ft. Intuit: Optimize Analytics Practices (ANT202-R1) - AWS re:Invent 2018</a></li><li>参照系クエリ専用のノードが自動的に起動される<ul><li><code>Concurrency Scaling Mode</code>を<code>auto</code>に設定したキューで滞留が発生すると起動される<ul><li>ただし、短時間(3秒未満くらい)のクエリが滞留しても起動されなかった。仕様なのか不明</li><li>WLMキューを増やしても起動されなくなった。ある程度さばけていると判定されると起動しないのか</li><li>滞留だけでなくスループット等もトリガーにしていると思われるが、不明</li></ul></li><li>実測してみると負荷投入後、速ければ数秒遅くとも数十秒程度のラグで起動した</li><li>滞留しないように必要なだけのクラスタが<code>max_concurrency_scaling_clusters</code>の範囲内で起動される。クラスタ一つあたりの並列度を指定することはできなかった</li></ul></li><li>24時間毎に1時間分のクレジットが最大30時間まで与えられる</li><li>利用できるクエリは以下の制約を満たす必要がある<ul><li>Read Only</li><li>interleaved sort keyを設定したテーブルを参照しない</li><li>Redshift Spectrumを参照しない</li><li>テンポラリテーブルを参照しない</li></ul></li></ul><p>メインクラスターと同時実行クラスターとで実行されたクエリの統計</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> w.service_class <span class="keyword">AS</span> queue</span><br><span class="line">     , q.concurrency_scaling_status</span><br><span class="line">     , <span class="keyword">COUNT</span>( * ) <span class="keyword">AS</span> queries</span><br><span class="line">     , <span class="keyword">SUM</span>( q.aborted )  <span class="keyword">AS</span> aborted</span><br><span class="line">     , <span class="keyword">SUM</span>( <span class="keyword">ROUND</span>( total_queue_time::<span class="built_in">NUMERIC</span> / <span class="number">1000000</span>,<span class="number">2</span> ) ) <span class="keyword">AS</span> queue_secs</span><br><span class="line">     , <span class="keyword">SUM</span>( <span class="keyword">ROUND</span>( total_exec_time::<span class="built_in">NUMERIC</span> / <span class="number">1000000</span>,<span class="number">2</span> ) )  <span class="keyword">AS</span> exec_secs</span><br><span class="line"><span class="keyword">FROM</span> stl_query q</span><br><span class="line">     <span class="keyword">JOIN</span> stl_wlm_query w</span><br><span class="line">          <span class="keyword">USING</span> (userid,<span class="keyword">query</span>)</span><br><span class="line"><span class="keyword">WHERE</span> q.userid = <span class="number">103</span></span><br><span class="line"><span class="keyword">AND</span> q.starttime &gt; <span class="string">'2019-04-12 7:20:00'</span></span><br><span class="line"><span class="keyword">AND</span> q.endtime &lt; <span class="string">'2019-04-12 7:45:00'</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="number">1</span>,<span class="number">2</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="number">1</span>,<span class="number">2</span>;</span><br></pre></td></tr></table></figure><h2 id="11-Redshift-Spectrum"><a href="#11-Redshift-Spectrum" class="headerlink" title="11. Redshift Spectrum"></a>11. Redshift Spectrum</h2><h3 id="11-1-料金"><a href="#11-1-料金" class="headerlink" title="11-1. 料金"></a>11-1. 料金</h3><p>Redshiftそれ自体と異なり、スキャンされたデータ1TBにつき5USDの課金となります。<br>クエリ単位で10MB以下のスキャンは切り上げられます。</p><h3 id="11-2-準備"><a href="#11-2-準備" class="headerlink" title="11-2. 準備"></a>11-2. 準備</h3><p><a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-iam-policies.html" target="_blank" rel="noopener">Amazon Redshift Spectrum 用の IAM ポリシー</a> が必要です。</p><h3 id="11-3-ファイルフォーマット"><a href="#11-3-ファイルフォーマット" class="headerlink" title="11-3. ファイルフォーマット"></a>11-3. ファイルフォーマット</h3><p>多くの形式(PARQUESTかORCが無難.AWSのドキュメントではORCよりもParquestを推奨しているように見受けられます)に対応しています。</p><ul><li>AVRO</li><li>PARQUET</li><li>TEXTFILE</li><li>SEQUENCEFILE</li><li>RCFILE</li><li>RegexSerDe</li><li>ORC</li><li>Grok</li><li>OpenCSV</li><li>Ion</li><li>JSON</li></ul><p>圧縮(PARQUEST/ORCは圧縮込みのフォーマット)は以下に対応しています。</p><ul><li>gzip: 普通</li><li>Snappy: 高速</li><li>bzip2: 高圧縮</li></ul><p>ファイルは64MB以上で均等に分割されます。</p><h3 id="11-4-パーティション"><a href="#11-4-パーティション" class="headerlink" title="11-4. パーティション"></a>11-4. パーティション</h3><p>パーティション表に追加できる数(<a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/mgmt/amazon-redshift-limits.html" target="_blank" rel="noopener">Amazon Redshift における制限</a>)があります。</p><ul><li>テーブルあたりのパーティション数の上限: 1,000,000</li><li>アカウントあたりのパーティション数の上限: 10,000,000</li></ul><p>参考: <a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html#c-spectrum-external-tables-partitioning" target="_blank" rel="noopener">Redshift Spectrum 外部テーブルのパーティション化</a></p><h3 id="11-5-注意"><a href="#11-5-注意" class="headerlink" title="11-5. 注意"></a>11-5. 注意</h3><p>統計情報の設定(<code>TABLE PROPERTIES (numRows&#39;=&#39;row_count&#39;)</code>)は必須です。設定されていないとプランが崩れます。</p><h3 id="11-6-使いどころ"><a href="#11-6-使いどころ" class="headerlink" title="11-6. 使いどころ"></a>11-6. 使いどころ</h3><ul><li>スキャンや集約インテンシブなワークロードを並行で実行するようなユースケース<ul><li>S3に対する検索はユーザーが予約しているリーダーノード・コンピュートノードとは別のリソースが使われるため、Redshift Spectrumだけを利用するのであれば、コンピュートノードには負荷がかかりません</li><li>フィルタ(<code>where</code>)や集約(<code>group by</code>)はRedshift Spectrum層で処理されます</li><li>結果的に同時実行性能が大きく向上します</li></ul></li><li>結合する際はRedshiftにデータをもった方が有利です。結合する場合はRedshift Spectrumの検索結果がコンピュートノードへ分散される。例えばRedshift Spectrumのファクトを抽出・集約してデータ量を減らしてから、Redshiftのディメンジョンと結合するようなクエリは有効に作用すると期待されます</li><li>古いデータはS3に追い出して、ビュー(<code>create view with no schema binding</code>)でRedshiftのテーブルと連結(<code>union all</code>)することで、ビューに対して検索すると、RedshiftのテーブルとRedshift Spectrumの両方を透過的に検索できます<ul><li>上記のような使い方を考えたくなるのですが、別テーブルと結合した際の実行計画がまったく最適化されないので、基本的に結合するような使い方はダメなようなです<ul><li>(A UNION ALL B) JOIN CのようなケースでA JOIN C とB JOIN Cに分解されないため、分散スタイルが有効に使えません。</li></ul></li><li>フィルタや集約はRedshift Spectrum層で処理されるため、有効です。</li></ul></li></ul><h2 id="12-参考資料"><a href="#12-参考資料" class="headerlink" title="12. 参考資料"></a>12. 参考資料</h2><h3 id="12-1-AWS公式"><a href="#12-1-AWS公式" class="headerlink" title="12-1. AWS公式"></a>12-1. AWS公式</h3><ul><li><a href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c_loading-data-best-practices.html" target="_blank" rel="noopener">Amazon Redshift のデータロードのベストプラクティス</a></li><li><a href="https://www.slideshare.net/AmazonWebServicesJapan/amazon-redshiftamazon-quicksightdwh" target="_blank" rel="noopener">Amazon RedshiftとAmazon QuickSightで実現する、長く使えるDWH作り</a></li><li><a href="https://aws.typepad.com/sajp/2015/12/top-10-performance-tuning-techniques-for-amazon-redshift.html" target="_blank" rel="noopener">Amazon Redshiftのパフォーマンスチューニングテクニック Top 10</a></li><li><a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-preamble-prerequisites-and-prioritization.html" target="_blank" rel="noopener">Amazon Redshift テーブル設計詳細ガイド:Part 1 序文、事前準備、優先順位付け</a></li><li><a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-distribution-styles-and-distribution-keys.html" target="_blank" rel="noopener">Amazon Redshift テーブル設計詳細ガイド:Part 2 分散スタイルと分散キー</a></li><li><a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-compound-and-interleaved-sort-keys.html" target="_blank" rel="noopener">Amazon Redshift テーブル設計詳細ガイド:Part 3 Compound and Interleaved Sort Keys（Compound と Interleaved ソートキー）</a></li><li><a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-compression-encodings.html" target="_blank" rel="noopener">Amazon Redshift テーブル設計詳細ガイド:Part 4 圧縮エンコーディング</a></li><li><a href="https://aws.typepad.com/sajp/2016/12/amazon-redshift-engineerings-advanced-table-design-playbook-table-data-durability.html" target="_blank" rel="noopener">Amazon Redshift テーブル設計詳細ガイド:Part 5 テーブルデータの永続性</a></li><li><a href="https://aws.amazon.com/jp/blogs/big-data/10-best-practices-for-amazon-redshift-spectrum/" target="_blank" rel="noopener">Twelve Best Practices for Amazon Redshift Spectrum</a><ul><li>和訳が<a href="https://aws.amazon.com/jp/blogs/news/10-best-practices-for-amazon-redshift-spectrum/" target="_blank" rel="noopener">Amazon Redshift Spectrum 10 のベストプラクティス</a>にありますが、内容が少し異なるようです。</li></ul></li><li><a href="https://www.slideshare.net/AmazonWebServicesJapan/20190122-aws-black-belt-online-seminar-amazon-redshift-update" target="_blank" rel="noopener">20190122 AWS Black Belt Online Seminar Amazon Redshift Update</a></li></ul><h3 id="12-2-他社事例"><a href="#12-2-他社事例" class="headerlink" title="12-2. 他社事例"></a>12-2. 他社事例</h3><ul><li><a href="http://www.slideshare.net/mineroaoki/at-aws-summit-tokyo-2014" target="_blank" rel="noopener">Amazon Redshiftによるリアルタイム分析サービスの構築</a></li><li><a href="https://hack.nikkei.com/blog/hundred_users_redshift/" target="_blank" rel="noopener">Redshiftを数百人で使うためのコツ（クラスター構成編）</a></li></ul><h3 id="12-3-要素技術"><a href="#12-3-要素技術" class="headerlink" title="12-3. 要素技術"></a>12-3. 要素技術</h3><ul><li><a href="https://qiita.com/nishemon/items/818cc64dc2f8577edd87" target="_blank" rel="noopener">2016年のOSS圧縮ツール選択カタログ</a></li><li><a href="https://engineer.retty.me/entry/columnar-storage-format" target="_blank" rel="noopener">カラムナフォーマットのきほん 〜データウェアハウスを支える技術〜</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;クラウド環境におけるDWHの選択肢として、Redshiftはもはや珍しいものではなくなりましたが、弊社内の採用実績はそれほど多くはありませんでした。&lt;br&gt;本記事は元々そのような社内向けに、Redshiftの基本的な仕様をなるべく網羅的に理解できるようまとめたものです。&lt;/
      
    
    </summary>
    
      <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
      <category term="AWS" scheme="https://future-architect.github.io/tags/AWS/"/>
    
  </entry>
  
</feed>
